# Unit07 æ©¢åœ“åŒ…çµ¡ (Elliptic Envelope)

## èª²ç¨‹ç›®æ¨™

æœ¬å–®å…ƒå°‡æ·±å…¥ä»‹ç´¹æ©¢åœ“åŒ…çµ¡ (Elliptic Envelope) ç•°å¸¸æª¢æ¸¬æ¼”ç®—æ³•ï¼Œé€™æ˜¯ä¸€ç¨®åŸºæ–¼é«˜æ–¯åˆ†å¸ƒå‡è¨­çš„ç•°å¸¸æª¢æ¸¬æ–¹æ³•ï¼Œç‰¹åˆ¥é©åˆè™•ç†æœå¾æˆ–æ¥è¿‘å¤šè®Šé‡å¸¸æ…‹åˆ†å¸ƒçš„æ•¸æ“šã€‚é€éæœ¬å–®å…ƒçš„å­¸ç¿’ï¼Œæ‚¨å°‡èƒ½å¤ ï¼š

- ç†è§£æ©¢åœ“åŒ…çµ¡æ¼”ç®—æ³•çš„æ ¸å¿ƒåŸç†èˆ‡æ•¸å­¸åŸºç¤
- æŒæ¡é¦¬æ°è·é›¢ (Mahalanobis Distance) èˆ‡å…±è®Šç•°æ•¸çŸ©é™£çš„æ¦‚å¿µ
- å­¸æœƒä½¿ç”¨ scikit-learn å¯¦ä½œæ©¢åœ“åŒ…çµ¡æ¨¡å‹
- äº†è§£å¦‚ä½•è¨­å®šé—œéµè¶…åƒæ•¸ (contamination, support_fraction)
- å­¸æœƒè©•ä¼°ç•°å¸¸æª¢æ¸¬æ¨¡å‹çš„æ•ˆèƒ½
- èªè­˜æ©¢åœ“åŒ…çµ¡çš„å„ªç¼ºé»èˆ‡é©ç”¨å ´æ™¯
- æ‡‰ç”¨æ©¢åœ“åŒ…çµ¡æ–¼åŒ–å·¥é ˜åŸŸçš„å“è³ªæ§åˆ¶èˆ‡è£½ç¨‹ç›£æ§

> **ğŸ’¡ åŸ·è¡Œçµæœèªªæ˜**ï¼š
> 
> æœ¬è¬›ç¾©æ•´åˆäº† `Unit07_Elliptic_Envelope.ipynb` çš„å®Œæ•´åŸ·è¡Œçµæœï¼ŒåŒ…å«ï¼š
> - **Section 5.6**ï¼šå¯¦éš›æ•¸æ“šç”Ÿæˆã€æ¨¡å‹è¨“ç·´ã€è¶…åƒæ•¸å„ªåŒ–ã€æ··æ·†çŸ©é™£ã€ROC æ›²ç·šã€é¦¬æ°è·é›¢åˆ†æ
> - **Section 6.4**ï¼šç©©å¥æ€§è©•ä¼°å¯¦é©—çµæœ
> - **Section 6.5**ï¼šæ©¢åœ“åŒ…çµ¡ vs å…¶ä»–æ–¹æ³•çš„ç®—æ³•å°æ¯”
> - **7 å¼µé«˜å“è³ªåœ–è¡¨** (300 DPI)ï¼šæ•¸æ“šå¯è¦–åŒ–ã€è¶…åƒæ•¸èª¿æ•´ã€æ··æ·†çŸ©é™£ã€ROC æ›²ç·šã€é¦¬æ°è·é›¢åˆ†æã€ç©©å¥æ€§è©•ä¼°ã€ç®—æ³•å°æ¯”
> - **è©³ç´°æ€§èƒ½åˆ†æ**ï¼šPrecisionã€Recallã€F1-Scoreã€AUC ç­‰æŒ‡æ¨™
> 
> æ‰€æœ‰åŸ·è¡Œçµæœå‡å·²æ¨™è¨»åœ¨ç›¸æ‡‰ç†è«–ç« ç¯€å¾Œï¼Œä¾¿æ–¼ç†è«–èˆ‡å¯¦è¸å°ç…§å­¸ç¿’ã€‚

---

## 1. æ©¢åœ“åŒ…çµ¡æ¼”ç®—æ³•ç°¡ä»‹

### 1.1 ä»€éº¼æ˜¯æ©¢åœ“åŒ…çµ¡ï¼Ÿ

æ©¢åœ“åŒ…çµ¡ (Elliptic Envelope) æ˜¯ä¸€ç¨®åŸºæ–¼é«˜æ–¯åˆ†å¸ƒå‡è¨­çš„ç•°å¸¸æª¢æ¸¬æ¼”ç®—æ³•ã€‚å…¶æ ¸å¿ƒç†å¿µæ˜¯ï¼š**å‡è¨­æ­£å¸¸æ•¸æ“šæœå¾å¤šè®Šé‡é«˜æ–¯åˆ†å¸ƒï¼Œç•°å¸¸é»å‰‡æ˜¯é é›¢åˆ†å¸ƒä¸­å¿ƒçš„é›¢ç¾¤å€¼**ã€‚

æ¼”ç®—æ³•é€éä¼°è¨ˆæ•¸æ“šçš„å…±è®Šç•°æ•¸çŸ©é™£ï¼Œæ§‹å»ºä¸€å€‹åŒ…å«å¤§å¤šæ•¸æ­£å¸¸æ•¸æ“šçš„æ©¢åœ“é‚Šç•Œï¼Œè½åœ¨æ©¢åœ“å¤–éƒ¨çš„é»å‰‡è¢«è¦–ç‚ºç•°å¸¸ã€‚

### 1.2 æ ¸å¿ƒç†å¿µï¼šç‚ºä»€éº¼ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒï¼Ÿ

åœ¨è¨±å¤šåŒ–å·¥è£½ç¨‹ä¸­ï¼Œæ­£å¸¸æ“ä½œæ¢ä»¶ä¸‹çš„æ•¸æ“šå¾€å¾€æœå¾æˆ–æ¥è¿‘å¤šè®Šé‡å¸¸æ…‹åˆ†å¸ƒï¼š

- **è£½ç¨‹ç©©å®šæ€§**ï¼šè‰¯å¥½æ§åˆ¶çš„è£½ç¨‹è®Šæ•¸åœç¹è¨­å®šé»æ³¢å‹•
- **æ¸¬é‡èª¤å·®**ï¼šæ„Ÿæ¸¬å™¨èª¤å·®é€šå¸¸æœå¾å¸¸æ…‹åˆ†å¸ƒ
- **è‡ªç„¶è®Šç•°**ï¼šåŸç‰©æ–™ç‰¹æ€§ã€ç’°å¢ƒæ¢ä»¶ç­‰å› ç´ çš„éš¨æ©Ÿè®Šç•°
- **ä¸­å¤®æ¥µé™å®šç†**ï¼šå¤šå€‹ç¨ç«‹å› ç´ å…±åŒä½œç”¨çš„çµæœè¶¨å‘å¸¸æ…‹åˆ†å¸ƒ

**æ©¢åœ“åŒ…çµ¡çš„æ ¸å¿ƒå‡è¨­**ï¼š
1. æ­£å¸¸æ•¸æ“šæœå¾æˆ–æ¥è¿‘å¤šè®Šé‡é«˜æ–¯åˆ†å¸ƒ
2. ç•°å¸¸é»çš„é¦¬æ°è·é›¢æ˜é¡¯å¤§æ–¼æ­£å¸¸é»
3. å¯ä»¥é€éç©©å¥ä¼°è¨ˆæ–¹æ³•è™•ç†å°‘é‡æ±¡æŸ“æ•¸æ“š
4. æ©¢åœ“é‚Šç•Œèƒ½æœ‰æ•ˆå€åˆ†æ­£å¸¸èˆ‡ç•°å¸¸å€åŸŸ

### 1.3 åŒ–å·¥é ˜åŸŸæ‡‰ç”¨æ¡ˆä¾‹

æ©¢åœ“åŒ…çµ¡åœ¨åŒ–å·¥é ˜åŸŸç‰¹åˆ¥é©åˆä»¥ä¸‹å ´æ™¯ï¼š

1. **ç”¢å“å“è³ªæ§åˆ¶**ï¼š
   - å¤šå€‹å“è³ªæŒ‡æ¨™çš„è¯åˆç›£æ§ï¼ˆå¦‚ç´”åº¦ã€è‰²åº¦ã€é»åº¦ï¼‰
   - è­˜åˆ¥å“è³ªæŒ‡æ¨™ç•°å¸¸çµ„åˆ
   - å»ºç«‹å¤šç¶­å“è³ªè¦æ ¼ç•Œé™
   - æ¸›å°‘å‡é™½æ€§è­¦å ±

2. **ç©©æ…‹è£½ç¨‹ç›£æ§**ï¼š
   - é€£çºŒè£½ç¨‹çš„æ­£å¸¸æ“ä½œå€åŸŸå®šç¾©
   - å¤šå€‹è£½ç¨‹è®Šæ•¸çš„å”åŒç›£æ§
   - è€ƒæ…®è®Šæ•¸é–“ç›¸é—œæ€§çš„ç•°å¸¸æª¢æ¸¬
   - æ—©æœŸç•°å¸¸è¶¨å‹¢è­˜åˆ¥

3. **æ„Ÿæ¸¬å™¨æ•…éšœè¨ºæ–·**ï¼š
   - è­˜åˆ¥æ„Ÿæ¸¬å™¨è®€æ•¸ç•°å¸¸åç§»
   - å¤šå€‹æ„Ÿæ¸¬å™¨çš„è¯åˆé©—è­‰
   - å€åˆ†çœŸå¯¦è£½ç¨‹ç•°å¸¸èˆ‡æ„Ÿæ¸¬å™¨æ•…éšœ
   - æé«˜ç›£æ§ç³»çµ±å¯é æ€§

4. **æ‰¹æ¬¡ä¸€è‡´æ€§æª¢é©—**ï¼š
   - æª¢é©—æ–°æ‰¹æ¬¡æ˜¯å¦ç¬¦åˆæ­·å²æ­£å¸¸ç¯„åœ
   - å¤šå€‹æ‰¹æ¬¡ç‰¹æ€§çš„è¯åˆè©•ä¼°
   - è­˜åˆ¥æ‰¹æ¬¡é–“ç•°å¸¸è®Šç•°
   - ç¢ºä¿ç”¢å“æ‰¹æ¬¡ä¸€è‡´æ€§

5. **å¯¦é©—è¨­è¨ˆèˆ‡æ•¸æ“šé©—è­‰**ï¼š
   - è­˜åˆ¥å¯¦é©—æ•¸æ“šä¸­çš„ç•°å¸¸é»
   - é©—è­‰æ•¸æ“šæ˜¯å¦ç¬¦åˆé æœŸåˆ†å¸ƒ
   - æ”¯æ´çµ±è¨ˆåˆ†æå‰çš„æ•¸æ“šæ¸…ç†
   - æé«˜å¯¦é©—çµæœå¯é æ€§

---

## 2. æ©¢åœ“åŒ…çµ¡æ¼”ç®—æ³•åŸç†

### 2.1 æ ¸å¿ƒæ¦‚å¿µä¸€ï¼šé¦¬æ°è·é›¢ (Mahalanobis Distance)

**å®šç¾©**ï¼šå°æ–¼æ•¸æ“šé» $\mathbf{x}$ ï¼Œå…¶é¦¬æ°è·é›¢å®šç¾©ç‚ºï¼š

$$
D_M(\mathbf{x}) = \sqrt{(\mathbf{x} - \boldsymbol{\mu})^T \mathbf{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu})}
$$

å…¶ä¸­ï¼š
- $\mathbf{x}$ ï¼šæ•¸æ“šé»çš„ç‰¹å¾µå‘é‡
- $\boldsymbol{\mu}$ ï¼šæ•¸æ“šçš„å‡å€¼å‘é‡
- $\mathbf{\Sigma}$ ï¼šæ•¸æ“šçš„å…±è®Šç•°æ•¸çŸ©é™£
- $\mathbf{\Sigma}^{-1}$ ï¼šå…±è®Šç•°æ•¸çŸ©é™£çš„é€†çŸ©é™£

**æ„ç¾©**ï¼š
- é¦¬æ°è·é›¢è¡¡é‡é» $\mathbf{x}$ èˆ‡åˆ†å¸ƒä¸­å¿ƒçš„è·é›¢
- è€ƒæ…®äº†è®Šæ•¸é–“çš„ç›¸é—œæ€§èˆ‡å„è®Šæ•¸çš„è®Šç•°ç¨‹åº¦
- å°æ–¼å¤šè®Šé‡é«˜æ–¯åˆ†å¸ƒï¼Œé¦¬æ°è·é›¢å¹³æ–¹æœå¾å¡æ–¹åˆ†å¸ƒ
- ç›¸è¼ƒæ–¼æ­æ°è·é›¢ï¼Œé¦¬æ°è·é›¢æ›´é©åˆè™•ç†ç›¸é—œè®Šæ•¸

**ç¯„ä¾‹ï¼šåŒ–å·¥åæ‡‰å™¨ç›£æ§**

å‡è¨­æˆ‘å€‘ç›£æ§åæ‡‰å™¨çš„æº«åº¦ $T$ å’Œå£“åŠ› $P$ ï¼š

- **æ­æ°è·é›¢å•é¡Œ**ï¼šå¦‚æœæº«åº¦å’Œå£“åŠ›çš„é‡ç¶±èˆ‡è®Šç•°ç¨‹åº¦ä¸åŒï¼Œæ­æ°è·é›¢æœƒè¢«è¼ƒå¤§è®Šç•°çš„è®Šæ•¸ä¸»å°
- **é¦¬æ°è·é›¢å„ªå‹¢**ï¼šè‡ªå‹•æ¨™æº–åŒ–å„è®Šæ•¸ï¼Œä¸¦è€ƒæ…®æº«åº¦èˆ‡å£“åŠ›çš„ç›¸é—œæ€§
- **å¯¦éš›æ‡‰ç”¨**ï¼šç•¶æº«åº¦å‡é«˜æ™‚å£“åŠ›é€šå¸¸ä¹Ÿå‡é«˜ï¼Œé¦¬æ°è·é›¢èƒ½è­˜åˆ¥ã€Œæº«åº¦æ­£å¸¸ä½†å£“åŠ›ç•°å¸¸ä½ã€é€™é¡ç•°å¸¸æ¨¡å¼

### 2.2 æ ¸å¿ƒæ¦‚å¿µäºŒï¼šå…±è®Šç•°æ•¸çŸ©é™£ (Covariance Matrix)

**å®šç¾©**ï¼šå°æ–¼ $d$ ç¶­æ•¸æ“šï¼Œå…±è®Šç•°æ•¸çŸ©é™£ $\mathbf{\Sigma}$ æ˜¯ $d \times d$ å°ç¨±çŸ©é™£ï¼š

$$
\mathbf{\Sigma} = \begin{bmatrix}
\sigma_1^2 & \sigma_{12} & \cdots & \sigma_{1d} \\
\sigma_{21} & \sigma_2^2 & \cdots & \sigma_{2d} \\
\vdots & \vdots & \ddots & \vdots \\
\sigma_{d1} & \sigma_{d2} & \cdots & \sigma_d^2
\end{bmatrix}
$$

å…¶ä¸­ï¼š
- $\sigma_i^2$ ï¼šç¬¬ $i$ å€‹è®Šæ•¸çš„è®Šç•°æ•¸
- $\sigma_{ij}$ ï¼šç¬¬ $i$ å’Œç¬¬ $j$ å€‹è®Šæ•¸çš„å…±è®Šç•°æ•¸

**å‚³çµ±ä¼°è¨ˆæ–¹æ³•ï¼ˆç¶“é©—å…±è®Šç•°æ•¸ï¼‰**ï¼š

$$
\mathbf{\Sigma} = \frac{1}{n-1} \sum_{i=1}^{n} (\mathbf{x}_i - \boldsymbol{\mu})(\mathbf{x}_i - \boldsymbol{\mu})^T
$$

$$
\boldsymbol{\mu} = \frac{1}{n} \sum_{i=1}^{n} \mathbf{x}_i
$$

**å•é¡Œ**ï¼šå°é›¢ç¾¤å€¼æ•æ„Ÿï¼Œå°‘é‡ç•°å¸¸é»æœƒåš´é‡å½±éŸ¿ä¼°è¨ˆçµæœã€‚

### 2.3 æ ¸å¿ƒæ¦‚å¿µä¸‰ï¼šæœ€å°å…±è®Šç•°æ•¸è¡Œåˆ—å¼ (Minimum Covariance Determinant, MCD)

ç”±æ–¼å‚³çµ±å…±è®Šç•°æ•¸ä¼°è¨ˆå°é›¢ç¾¤å€¼æ•æ„Ÿï¼Œæ©¢åœ“åŒ…çµ¡ä½¿ç”¨**æœ€å°å…±è®Šç•°æ•¸è¡Œåˆ—å¼ (MCD)** æ–¹æ³•é€²è¡Œç©©å¥ä¼°è¨ˆã€‚

**MCD æ ¸å¿ƒæ€æƒ³**ï¼š

æ‰¾åˆ°ä¸€å€‹åŒ…å« $h$ å€‹æ•¸æ“šé»çš„å­é›† $\mathcal{H}$ ï¼Œä½¿å¾—é€™å€‹å­é›†çš„å…±è®Šç•°æ•¸çŸ©é™£è¡Œåˆ—å¼æœ€å°ï¼š

$$
\min_{\mathcal{H}, |\mathcal{H}|=h} \det(\mathbf{\Sigma}_{\mathcal{H}})
$$

å…¶ä¸­ï¼š
- $h = \lfloor n \times \text{support\_fraction} \rfloor$ ï¼šå­é›†å¤§å°
- $\mathbf{\Sigma}_{\mathcal{H}}$ ï¼šå­é›† $\mathcal{H}$ çš„å…±è®Šç•°æ•¸çŸ©é™£
- $\det(\cdot)$ ï¼šè¡Œåˆ—å¼

**æ­¥é©Ÿ**ï¼š
1. å¾ $n$ å€‹æ•¸æ“šé»ä¸­é¸å– $h$ å€‹é»çš„å­é›†
2. è¨ˆç®—å­é›†çš„å‡å€¼ $\boldsymbol{\mu}_{\mathcal{H}}$ å’Œå…±è®Šç•°æ•¸çŸ©é™£ $\mathbf{\Sigma}_{\mathcal{H}}$
3. å°‹æ‰¾ä½¿è¡Œåˆ—å¼ $\det(\mathbf{\Sigma}_{\mathcal{H}})$ æœ€å°çš„å­é›†
4. ä½¿ç”¨è©²å­é›†çš„çµ±è¨ˆé‡ä½œç‚ºç©©å¥ä¼°è¨ˆ

**æ„ç¾©**ï¼š
- è‡ªå‹•è­˜åˆ¥ä¸¦æ’é™¤é›¢ç¾¤å€¼
- åŸºæ–¼"æœ€ç·Šå¯†"çš„æ•¸æ“šå­é›†ä¼°è¨ˆåˆ†å¸ƒ
- æé«˜å°æ±¡æŸ“æ•¸æ“šçš„æŠµæŠ—èƒ½åŠ›
- é©åˆåŠç›£ç£ç•°å¸¸æª¢æ¸¬å ´æ™¯

### 2.4 æ¼”ç®—æ³•æµç¨‹

**è¼¸å…¥**ï¼š
- è¨“ç·´æ•¸æ“š $\mathbf{X} = \{\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n\}$
- é æœŸæ±¡æŸ“æ¯”ä¾‹ `contamination`
- æ”¯æ´å­é›†æ¯”ä¾‹ `support_fraction` ï¼ˆé è¨­ç‚º Noneï¼Œè‡ªå‹•è¨ˆç®—ï¼‰

**è¨“ç·´éšæ®µ**ï¼š

1. **å­é›†é¸æ“‡**ï¼š
   - è¨ˆç®— $h = \lfloor n \times (1 - \text{contamination}) \rfloor$
   - å¦‚æœ `support_fraction` æœªæŒ‡å®šï¼Œä½¿ç”¨ $h = \lfloor n \times 0.5 \times (n + d + 1) / n \rfloor$

2. **MCD ä¼°è¨ˆ**ï¼š
   - ä½¿ç”¨ FastMCD æ¼”ç®—æ³•å°‹æ‰¾æœ€å°å…±è®Šç•°æ•¸è¡Œåˆ—å¼å­é›†
   - è¨ˆç®—ç©©å¥å‡å€¼ $\hat{\boldsymbol{\mu}}$ å’Œç©©å¥å…±è®Šç•°æ•¸ $\hat{\mathbf{\Sigma}}$

3. **æ ¡æ­£å› å­**ï¼š
   - æ‡‰ç”¨æ ¡æ­£å› å­ç¢ºä¿ä¸€è‡´æ€§ä¼°è¨ˆ
   - èª¿æ•´å…±è®Šç•°æ•¸çŸ©é™£ä½¿å…¶åœ¨å¤§æ¨£æœ¬ä¸‹ç„¡å

4. **æ±ºç­–é‚Šç•Œ**ï¼š
   - è¨ˆç®—æ‰€æœ‰è¨“ç·´é»çš„é¦¬æ°è·é›¢
   - åŸºæ–¼å¡æ–¹åˆ†å¸ƒç¢ºå®šç•°å¸¸é–¾å€¼

**é æ¸¬éšæ®µ**ï¼š

1. **è¨ˆç®—é¦¬æ°è·é›¢**ï¼š
   
$$
D_M(\mathbf{x}) = \sqrt{(\mathbf{x} - \hat{\boldsymbol{\mu}})^T \hat{\mathbf{\Sigma}}^{-1} (\mathbf{x} - \hat{\boldsymbol{\mu}})}
$$

2. **ç•°å¸¸åˆ¤å®š**ï¼š
   
$$
\text{label}(\mathbf{x}) = \begin{cases}
+1 & \text{if } D_M(\mathbf{x}) \leq \text{threshold (æ­£å¸¸)} \\
-1 & \text{if } D_M(\mathbf{x}) > \text{threshold (ç•°å¸¸)}
\end{cases}
$$

---

## 3. æ•¸å­¸ç†è«–æ·±å…¥

### 3.1 å¤šè®Šé‡é«˜æ–¯åˆ†å¸ƒ

**æ©Ÿç‡å¯†åº¦å‡½æ•¸**ï¼š

$$
f(\mathbf{x}) = \frac{1}{(2\pi)^{d/2}|\mathbf{\Sigma}|^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^T\mathbf{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right)
$$

å…¶ä¸­ï¼š
- $d$ ï¼šç¶­åº¦
- $|\mathbf{\Sigma}|$ ï¼šå…±è®Šç•°æ•¸çŸ©é™£çš„è¡Œåˆ—å¼
- æŒ‡æ•¸é …ä¸­çš„äºŒæ¬¡å‹å³ç‚ºé¦¬æ°è·é›¢å¹³æ–¹

**ç­‰å¯†åº¦æ›²ç·š**ï¼š

å°æ–¼å›ºå®šçš„æ©Ÿç‡å¯†åº¦ $c$ ï¼Œç­‰å¯†åº¦æ›²ç·šå®šç¾©ç‚ºï¼š

$$
(\mathbf{x}-\boldsymbol{\mu})^T\mathbf{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu}) = k^2
$$

é€™æ˜¯ä¸€å€‹æ©¢åœ“ï¼ˆæˆ–é«˜ç¶­æ©¢çƒï¼‰ï¼Œæ©¢åœ“åŒ…çµ¡å³æ˜¯åŸºæ–¼æ­¤æ§‹å»ºé‚Šç•Œã€‚

### 3.2 é¦¬æ°è·é›¢å¹³æ–¹çš„åˆ†å¸ƒ

å°æ–¼å¤šè®Šé‡é«˜æ–¯åˆ†å¸ƒ $\mathbf{x} \sim \mathcal{N}(\boldsymbol{\mu}, \mathbf{\Sigma})$ ï¼Œé¦¬æ°è·é›¢å¹³æ–¹æœå¾å¡æ–¹åˆ†å¸ƒï¼š

$$
D_M^2(\mathbf{x}) \sim \chi^2_d
$$

å…¶ä¸­ $d$ æ˜¯è‡ªç”±åº¦ï¼ˆç¶­åº¦ï¼‰ã€‚

**ç•°å¸¸é–¾å€¼è¨­å®š**ï¼š

åŸºæ–¼å¡æ–¹åˆ†å¸ƒï¼Œå¯ä»¥è¨­å®šé–¾å€¼ä½¿å¾—æ­£å¸¸æ•¸æ“šçš„è¦†è“‹ç‡é”åˆ° $(1-\text{contamination})$ ï¼š

$$
\text{threshold} = \sqrt{\chi^2_{d, 1-\alpha}}
$$

å…¶ä¸­ $\alpha = \text{contamination}$ æ˜¯é æœŸçš„ç•°å¸¸æ¯”ä¾‹ã€‚

### 3.3 æ©¢åœ“çš„å¹¾ä½•ç‰¹æ€§

**æ©¢åœ“æ–¹ç¨‹**ï¼š

$$
(\mathbf{x}-\boldsymbol{\mu})^T\mathbf{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu}) = c^2
$$

**ä¸»è»¸æ–¹å‘**ï¼šç”± $\mathbf{\Sigma}$ çš„ç‰¹å¾µå‘é‡æ±ºå®š

**ä¸»è»¸é•·åº¦**ï¼šèˆ‡ $\mathbf{\Sigma}$ çš„ç‰¹å¾µå€¼å¹³æ–¹æ ¹æˆæ­£æ¯”

$$
\text{åŠè»¸é•·åº¦}_i = c \cdot \sqrt{\lambda_i}
$$

å…¶ä¸­ $\lambda_i$ æ˜¯ $\mathbf{\Sigma}$ çš„ç¬¬ $i$ å€‹ç‰¹å¾µå€¼ã€‚

**åŒ–å·¥æ„ç¾©**ï¼š
- æ©¢åœ“ä¸»è»¸åæ˜ è£½ç¨‹è®Šæ•¸çš„ä¸»è¦è®Šç•°æ–¹å‘
- ä¸»è»¸é•·åº¦åæ˜ å„æ–¹å‘çš„å…è¨±è®Šç•°ç¯„åœ
- æ©¢åœ“å‚¾æ–œè§’åº¦åæ˜ è®Šæ•¸é–“çš„ç›¸é—œæ€§

---

## 4. æ©¢åœ“åŒ…çµ¡çš„å„ªç¼ºé»

### 4.1 å„ªé»

1. **æ•¸å­¸åŸºç¤ç´®å¯¦**ï¼š
   - åŸºæ–¼å¤šè®Šé‡é«˜æ–¯åˆ†å¸ƒç†è«–
   - æœ‰æ˜ç¢ºçš„çµ±è¨ˆæ¨è«–åŸºç¤
   - å¯è§£é‡‹æ€§å¼·

2. **è€ƒæ…®è®Šæ•¸ç›¸é—œæ€§**ï¼š
   - é¦¬æ°è·é›¢è‡ªç„¶è€ƒæ…®è®Šæ•¸é–“ç›¸é—œæ€§
   - é©åˆå¤šå€‹ç›¸é—œè£½ç¨‹è®Šæ•¸çš„è¯åˆç›£æ§
   - é¿å…ç¨ç«‹ç›£æ§çš„èª¤å ±

3. **ç©©å¥æ€§**ï¼š
   - MCD æ–¹æ³•å°å°‘é‡é›¢ç¾¤å€¼æœ‰æŠµæŠ—åŠ›
   - èƒ½åœ¨å«æ±¡æŸ“æ•¸æ“šä¸­æº–ç¢ºä¼°è¨ˆåˆ†å¸ƒ
   - é©åˆåŠç›£ç£ç•°å¸¸æª¢æ¸¬

4. **è¨ˆç®—æ•ˆç‡é«˜**ï¼š
   - FastMCD æ¼”ç®—æ³•è¨ˆç®—è¤‡é›œåº¦ä½
   - é©åˆä¸­ç­‰è¦æ¨¡æ•¸æ“š
   - é æ¸¬éšæ®µåƒ…éœ€è¨ˆç®—é¦¬æ°è·é›¢

5. **å¯è¦–åŒ–å‹å–„**ï¼š
   - æ©¢åœ“é‚Šç•Œæ˜“æ–¼äºŒç¶­/ä¸‰ç¶­å¯è¦–åŒ–
   - ä¾¿æ–¼å‘é ˜åŸŸå°ˆå®¶è§£é‡‹
   - æ”¯æ´è£½ç¨‹æ“ä½œè¦–çª—çš„å¯è¦–åŒ–å®šç¾©

### 4.2 ç¼ºé»

1. **é«˜æ–¯åˆ†å¸ƒå‡è¨­**ï¼š
   - è¦æ±‚æ•¸æ“šæœå¾æˆ–æ¥è¿‘å¤šè®Šé‡å¸¸æ…‹åˆ†å¸ƒ
   - å°åš´é‡åæ…‹æˆ–å¤šå³°åˆ†å¸ƒæ•ˆæœä¸ä½³
   - ç„¡æ³•è™•ç†ä»»æ„å½¢ç‹€çš„åˆ†å¸ƒ

2. **å°é«˜ç¶­æ•¸æ“šæ•æ„Ÿ**ï¼š
   - ç¶­åº¦è©›å’’ï¼šé«˜ç¶­åº¦ä¸‹å…±è®Šç•°æ•¸çŸ©é™£ä¼°è¨ˆå›°é›£
   - éœ€è¦è¶³å¤ çš„æ¨£æœ¬æ•¸ï¼ˆ $n \gg d$ ï¼‰
   - é«˜ç¶­åº¦ä¸‹æ©¢åœ“é‚Šç•Œå¯èƒ½ä¸æº–ç¢º

3. **åƒ…é©åˆå–®å³°åˆ†å¸ƒ**ï¼š
   - ç„¡æ³•è™•ç†å¤šæ¨¡æ…‹æ•¸æ“š
   - å¤šæ“ä½œæ¨¡å¼çš„è£½ç¨‹éœ€è¦åˆ†åˆ¥å»ºæ¨¡
   - ä¸é©åˆè¤‡é›œçš„éç·šæ€§é‚Šç•Œ

4. **åƒæ•¸æ•æ„Ÿæ€§**ï¼š
   - `contamination` åƒæ•¸éœ€è¦é å…ˆè¨­å®š
   - `support_fraction` çš„é¸æ“‡å½±éŸ¿ç©©å¥æ€§
   - åƒæ•¸è¨­å®šä¸ç•¶æœƒå½±éŸ¿æ•ˆèƒ½

5. **å°æ¥µç«¯é›¢ç¾¤å€¼çš„æ•æ„Ÿæ€§**ï¼š
   - é›–ç„¶ MCD æä¾›ç©©å¥æ€§ï¼Œä½†æ¥µç«¯é›¢ç¾¤å€¼ä»å¯èƒ½å½±éŸ¿ä¼°è¨ˆ
   - éœ€è¦é©ç•¶çš„æ•¸æ“šé è™•ç†
   - ç•°å¸¸æ¯”ä¾‹éé«˜æ™‚æ•ˆæœä¸‹é™

### 4.3 èˆ‡å…¶ä»–æ–¹æ³•çš„æ¯”è¼ƒ

| ç‰¹æ€§ | æ©¢åœ“åŒ…çµ¡ | Isolation Forest | One-Class SVM | LOF |
|------|----------|------------------|---------------|-----|
| **åˆ†å¸ƒå‡è¨­** | é«˜æ–¯åˆ†å¸ƒ | ç„¡ | ç„¡ | ç„¡ |
| **é©åˆé«˜ç¶­** | âŒ | âœ… | âš ï¸ | âŒ |
| **å¤šæ¨¡æ…‹** | âŒ | âœ… | âš ï¸ | âœ… |
| **è¨ˆç®—è¤‡é›œåº¦** | ä½ | ä½ | é«˜ | ä¸­ |
| **å¯è§£é‡‹æ€§** | âœ… | âš ï¸ | âŒ | âš ï¸ |
| **ç©©å¥æ€§** | âœ… | âœ… | âš ï¸ | âš ï¸ |
| **åƒæ•¸æ•æ„Ÿæ€§** | ä¸­ | ä½ | é«˜ | é«˜ |

---

## 5. Python å¯¦ä½œï¼šæ©¢åœ“åŒ…çµ¡

### 5.1 åŸºæœ¬ä½¿ç”¨

```python
from sklearn.covariance import EllipticEnvelope
import numpy as np

# ç”Ÿæˆè¨“ç·´æ•¸æ“šï¼ˆæ­£å¸¸æ•¸æ“šï¼‰
np.random.seed(42)
X_train = np.random.randn(200, 2) * [2, 1] + [5, 3]

# å»ºç«‹æ©¢åœ“åŒ…çµ¡æ¨¡å‹
model = EllipticEnvelope(
    contamination=0.1,      # é æœŸç•°å¸¸æ¯”ä¾‹ 10%
    support_fraction=None,  # è‡ªå‹•è¨ˆç®—ï¼ˆæ¨è–¦ï¼‰
    random_state=42
)

# è¨“ç·´æ¨¡å‹
model.fit(X_train)

# é æ¸¬æ–°æ•¸æ“š
X_test = np.array([[5, 3], [10, 10]])  # [æ­£å¸¸é», ç•°å¸¸é»]
predictions = model.predict(X_test)
# è¼¸å‡ºï¼š[1, -1]ï¼Œ1 ä»£è¡¨æ­£å¸¸ï¼Œ-1 ä»£è¡¨ç•°å¸¸

# è¨ˆç®—é¦¬æ°è·é›¢ï¼ˆè² å€¼è¡¨ç¤ºæ±ºç­–å‡½æ•¸å€¼ï¼‰
distances = model.decision_function(X_test)
# è·é›¢è¶Šè² ï¼Œè¶Šå¯èƒ½æ˜¯ç•°å¸¸
```

### 5.2 é—œéµåƒæ•¸èªªæ˜

#### 5.2.1 `contamination`ï¼ˆæ±¡æŸ“æ¯”ä¾‹ï¼‰

**å®šç¾©**ï¼šé æœŸè¨“ç·´æ•¸æ“šä¸­ç•°å¸¸é»çš„æ¯”ä¾‹ã€‚

**ç¯„åœ**ï¼š$(0, 0.5)$ ï¼Œé è¨­å€¼ç‚º $0.1$

**å½±éŸ¿**ï¼š
- æ±ºå®šæ©¢åœ“é‚Šç•Œçš„å¤§å°
- å€¼è¶Šå¤§ï¼Œæ©¢åœ“é‚Šç•Œè¶Šå¯¬é¬†ï¼Œæ›´å¤šé»è¢«è¦–ç‚ºæ­£å¸¸
- å€¼è¶Šå°ï¼Œæ©¢åœ“é‚Šç•Œè¶Šç·Šï¼Œæ›´å¤šé»è¢«è¦–ç‚ºç•°å¸¸

**è¨­å®šå»ºè­°**ï¼š
```python
# å“è³ªæ§åˆ¶å ´æ™¯ï¼ˆåš´æ ¼æ¨™æº–ï¼‰
model = EllipticEnvelope(contamination=0.05)  # 5% ç•°å¸¸å®¹å¿

# è£½ç¨‹ç›£æ§å ´æ™¯ï¼ˆä¸€èˆ¬æ¨™æº–ï¼‰
model = EllipticEnvelope(contamination=0.1)   # 10% ç•°å¸¸å®¹å¿

# æ¢ç´¢æ€§åˆ†æï¼ˆå¯¬é¬†æ¨™æº–ï¼‰
model = EllipticEnvelope(contamination=0.2)   # 20% ç•°å¸¸å®¹å¿
```

#### 5.2.2 `support_fraction`ï¼ˆæ”¯æ´å­é›†æ¯”ä¾‹ï¼‰

**å®šç¾©**ï¼šMCD æ¼”ç®—æ³•ä½¿ç”¨çš„å­é›†æ¯”ä¾‹ã€‚

**ç¯„åœ**ï¼š$(0, 1)$ ï¼Œé è¨­å€¼ç‚º `None`ï¼ˆè‡ªå‹•è¨ˆç®—ï¼‰

**è‡ªå‹•è¨ˆç®—å…¬å¼**ï¼š

$$
\text{support\_fraction} = \frac{n + d + 1}{2n}
$$

å…¶ä¸­ $n$ æ˜¯æ¨£æœ¬æ•¸ï¼Œ $d$ æ˜¯ç¶­åº¦ã€‚

**å½±éŸ¿**ï¼š
- æ±ºå®š MCD ä¼°è¨ˆçš„ç©©å¥æ€§
- å€¼è¶Šå°ï¼Œå°é›¢ç¾¤å€¼çš„æŠµæŠ—åŠ›è¶Šå¼·ï¼Œä½†å¯èƒ½çŠ§ç‰²æ•ˆç‡
- å€¼è¶Šå¤§ï¼Œä½¿ç”¨æ›´å¤šæ•¸æ“šï¼Œä½†å°é›¢ç¾¤å€¼æ›´æ•æ„Ÿ

**è¨­å®šå»ºè­°**ï¼š
```python
# é«˜æ±¡æŸ“å ´æ™¯ï¼ˆä½¿ç”¨è¼ƒå°å­é›†ï¼‰
model = EllipticEnvelope(support_fraction=0.6)

# ä½æ±¡æŸ“å ´æ™¯ï¼ˆä½¿ç”¨é è¨­å€¼ï¼‰
model = EllipticEnvelope(support_fraction=None)

# æ¸…æ½”æ•¸æ“šï¼ˆå¯ä½¿ç”¨è¼ƒå¤§å­é›†ï¼‰
model = EllipticEnvelope(support_fraction=0.9)
```

#### 5.2.3 `random_state`ï¼ˆéš¨æ©Ÿç¨®å­ï¼‰

**å®šç¾©**ï¼šMCD æ¼”ç®—æ³•çš„éš¨æ©Ÿç¨®å­ã€‚

**å½±éŸ¿**ï¼šç¢ºä¿çµæœå¯é‡ç¾æ€§ã€‚

**å»ºè­°**ï¼šå¯¦é©—éšæ®µè¨­å®šå›ºå®šå€¼ï¼Œç”Ÿç”¢ç’°å¢ƒå¯è€ƒæ…®ä¸è¨­å®šã€‚

### 5.3 æ¨¡å‹å±¬æ€§

è¨“ç·´å¾Œçš„æ¨¡å‹æä¾›ä»¥ä¸‹å±¬æ€§ï¼š

```python
# ç©©å¥ä¼°è¨ˆçš„å‡å€¼
mu = model.location_
print(f"å‡å€¼å‘é‡: {mu}")

# ç©©å¥ä¼°è¨ˆçš„å…±è®Šç•°æ•¸çŸ©é™£
Sigma = model.covariance_
print(f"å…±è®Šç•°æ•¸çŸ©é™£:\n{Sigma}")

# ç²¾åº¦çŸ©é™£ï¼ˆå…±è®Šç•°æ•¸çŸ©é™£çš„é€†ï¼‰
precision = model.precision_
print(f"ç²¾åº¦çŸ©é™£:\n{precision}")

# æ”¯æ´å‘é‡ï¼ˆç”¨æ–¼ MCD ä¼°è¨ˆçš„æ•¸æ“šé»ç´¢å¼•ï¼‰
support = model.support_
print(f"æ”¯æ´é»æ•¸é‡: {len(support)}")

# é¦¬æ°è·é›¢é–¾å€¼
threshold = model.threshold_
print(f"ç•°å¸¸é–¾å€¼: {threshold}")
```

### 5.4 å®Œæ•´å·¥ä½œæµç¨‹

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import EllipticEnvelope
from sklearn.metrics import classification_report, confusion_matrix

# ========================================
# 1. æ•¸æ“šç”Ÿæˆ
# ========================================
np.random.seed(42)

# æ­£å¸¸æ•¸æ“šï¼ˆå¤šè®Šé‡é«˜æ–¯åˆ†å¸ƒï¼‰
n_normal = 300
mean = [5, 3]
cov = [[4, 2], [2, 2]]  # æœ‰ç›¸é—œæ€§çš„å…±è®Šç•°æ•¸çŸ©é™£
X_normal = np.random.multivariate_normal(mean, cov, n_normal)

# ç•°å¸¸æ•¸æ“šï¼ˆé é›¢æ­£å¸¸åˆ†å¸ƒï¼‰
n_outliers = 30
X_outliers = np.random.uniform(low=-5, high=15, size=(n_outliers, 2))

# åˆä½µæ•¸æ“š
X = np.vstack([X_normal, X_outliers])
y_true = np.array([1] * n_normal + [-1] * n_outliers)

# ========================================
# 2. æ¨¡å‹è¨“ç·´
# ========================================
model = EllipticEnvelope(
    contamination=0.1,
    support_fraction=None,
    random_state=42
)
model.fit(X)

# ========================================
# 3. é æ¸¬èˆ‡è©•ä¼°
# ========================================
y_pred = model.predict(X)

print("åˆ†é¡å ±å‘Š:")
print(classification_report(y_true, y_pred, 
                          target_names=['ç•°å¸¸', 'æ­£å¸¸']))

print("\næ··æ·†çŸ©é™£:")
print(confusion_matrix(y_true, y_pred))

# ========================================
# 4. å¯è¦–åŒ–
# ========================================
# è¨ˆç®—é¦¬æ°è·é›¢
mahal_dist = model.mahalanobis(X)

# å»ºç«‹ç¶²æ ¼ç”¨æ–¼ç¹ªè£½æ±ºç­–é‚Šç•Œ
xx, yy = np.meshgrid(
    np.linspace(X[:, 0].min()-2, X[:, 0].max()+2, 100),
    np.linspace(X[:, 1].min()-2, X[:, 1].max()+2, 100)
)
Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# ç¹ªåœ–
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# å·¦åœ–ï¼šæ±ºç­–é‚Šç•Œèˆ‡åˆ†é¡çµæœ
ax1 = axes[0]
ax1.contourf(xx, yy, Z, levels=[-10, 0, 10], 
             colors=['#ffcccc', '#ccffcc'], alpha=0.3)
ax1.contour(xx, yy, Z, levels=[0], colors='black', linewidths=2)
scatter1 = ax1.scatter(X[:, 0], X[:, 1], c=y_pred, 
                       cmap='RdYlGn', edgecolors='k', s=50)
ax1.set_xlabel('Feature 1')
ax1.set_ylabel('Feature 2')
ax1.set_title('Elliptic Envelope Decision Boundary')
plt.colorbar(scatter1, ax=ax1, label='Prediction (-1: Outlier, 1: Normal)')

# å³åœ–ï¼šé¦¬æ°è·é›¢åˆ†å¸ƒ
ax2 = axes[1]
scatter2 = ax2.scatter(X[:, 0], X[:, 1], c=mahal_dist, 
                       cmap='coolwarm', edgecolors='k', s=50)
ax2.set_xlabel('Feature 1')
ax2.set_ylabel('Feature 2')
ax2.set_title('Mahalanobis Distance')
plt.colorbar(scatter2, ax=ax2, label='Mahalanobis Distance')

plt.tight_layout()
plt.show()
```

### 5.5 åŒ–å·¥æ‡‰ç”¨ï¼šåæ‡‰å™¨å“è³ªç›£æ§

**å ´æ™¯**ï¼šç›£æ§æ‰¹æ¬¡åæ‡‰å™¨çš„æº«åº¦å’Œå£“åŠ›ï¼Œè­˜åˆ¥ç•°å¸¸æ‰¹æ¬¡ã€‚

```python
import numpy as np
from sklearn.covariance import EllipticEnvelope
import pandas as pd

# ========================================
# æ¨¡æ“¬æ‰¹æ¬¡åæ‡‰å™¨æ•¸æ“š
# ========================================
np.random.seed(42)

# æ­£å¸¸æ‰¹æ¬¡ï¼ˆæº«åº¦å’Œå£“åŠ›æ­£ç›¸é—œï¼‰
n_batches = 200
temp_normal = np.random.normal(180, 5, n_batches)  # æº«åº¦ (Â°C)
pressure_normal = 2.0 + 0.01 * temp_normal + np.random.normal(0, 0.3, n_batches)  # å£“åŠ› (bar)

# ç•°å¸¸æ‰¹æ¬¡
n_outliers = 20
temp_outliers = np.random.uniform(150, 210, n_outliers)
pressure_outliers = np.random.uniform(1.0, 4.0, n_outliers)

# åˆä½µæ•¸æ“š
temperature = np.concatenate([temp_normal, temp_outliers])
pressure = np.concatenate([pressure_normal, pressure_outliers])
batch_id = np.arange(1, n_batches + n_outliers + 1)

# å»ºç«‹ DataFrame
df = pd.DataFrame({
    'Batch_ID': batch_id,
    'Temperature': temperature,
    'Pressure': pressure
})

# ========================================
# æ©¢åœ“åŒ…çµ¡ç•°å¸¸æª¢æ¸¬
# ========================================
X = df[['Temperature', 'Pressure']].values

model = EllipticEnvelope(
    contamination=0.1,  # é æœŸ 10% ç•°å¸¸æ‰¹æ¬¡
    random_state=42
)
model.fit(X)

# é æ¸¬
df['Prediction'] = model.predict(X)
df['Mahalanobis_Distance'] = model.mahalanobis(X)
df['Is_Outlier'] = df['Prediction'] == -1

# ========================================
# çµæœåˆ†æ
# ========================================
print("æª¢æ¸¬åˆ°çš„ç•°å¸¸æ‰¹æ¬¡:")
outlier_batches = df[df['Is_Outlier']]
print(outlier_batches[['Batch_ID', 'Temperature', 'Pressure', 'Mahalanobis_Distance']])

print(f"\nç¸½æ‰¹æ¬¡æ•¸: {len(df)}")
print(f"ç•°å¸¸æ‰¹æ¬¡æ•¸: {outlier_batches.shape[0]}")
print(f"ç•°å¸¸æ¯”ä¾‹: {outlier_batches.shape[0] / len(df):.2%}")

# çµ±è¨ˆåˆ†æ
print("\næ­£å¸¸æ‰¹æ¬¡çµ±è¨ˆ:")
normal_df = df[~df['Is_Outlier']]
print(normal_df[['Temperature', 'Pressure']].describe())

print("\nç•°å¸¸æ‰¹æ¬¡çµ±è¨ˆ:")
print(outlier_batches[['Temperature', 'Pressure']].describe())
```

### 5.6 é€²éšæŠ€å·§ï¼šå¤šçµ„æ©¢åœ“åŒ…çµ¡

å°æ–¼å¤šæ¨¡æ…‹æ•¸æ“šï¼ˆå¦‚å¤šå€‹æ“ä½œæ¨¡å¼ï¼‰ï¼Œå¯ä»¥ç‚ºæ¯å€‹æ¨¡å¼å–®ç¨å»ºç«‹æ©¢åœ“åŒ…çµ¡ï¼š

```python
from sklearn.cluster import KMeans

# ========================================
# 1. å…ˆç”¨èšé¡è­˜åˆ¥æ“ä½œæ¨¡å¼
# ========================================
kmeans = KMeans(n_clusters=3, random_state=42)
modes = kmeans.fit_predict(X)

# ========================================
# 2. ç‚ºæ¯å€‹æ¨¡å¼å»ºç«‹æ©¢åœ“åŒ…çµ¡
# ========================================
models = {}
for mode in range(3):
    X_mode = X[modes == mode]
    models[mode] = EllipticEnvelope(contamination=0.1, random_state=42)
    models[mode].fit(X_mode)

# ========================================
# 3. é æ¸¬ï¼šä½¿ç”¨æœ€è¿‘æ¨¡å¼çš„æ¨¡å‹
# ========================================
def predict_multimode(X_test):
    # æ‰¾åˆ°æœ€è¿‘çš„æ“ä½œæ¨¡å¼
    mode_pred = kmeans.predict(X_test)
    
    # ä½¿ç”¨å°æ‡‰æ¨¡å¼çš„æ¨¡å‹é æ¸¬
    predictions = np.zeros(len(X_test))
    for mode in range(3):
        mask = mode_pred == mode
        if mask.any():
            predictions[mask] = models[mode].predict(X_test[mask])
    
    return predictions

# æ¸¬è©¦
y_pred_multimode = predict_multimode(X)
```

---

## 6. å¯¦å‹™æ‡‰ç”¨æŒ‡å—

### 6.1 ä½•æ™‚é¸æ“‡æ©¢åœ“åŒ…çµ¡ï¼Ÿ

**é©åˆå ´æ™¯**ï¼š

âœ… æ•¸æ“šæ¥è¿‘å¤šè®Šé‡é«˜æ–¯åˆ†å¸ƒ  
âœ… è®Šæ•¸é–“æœ‰æ˜é¡¯ç›¸é—œæ€§  
âœ… éœ€è¦è€ƒæ…®è®Šæ•¸è¯åˆåˆ†å¸ƒ  
âœ… éœ€è¦å¯è§£é‡‹çš„ç•°å¸¸é‚Šç•Œ  
âœ… æ•¸æ“šç¶­åº¦ä¸­ç­‰ï¼ˆ $d < 20$ ï¼‰  
âœ… æ¨£æœ¬æ•¸å……è¶³ï¼ˆ $n > 10d$ ï¼‰  
âœ… è£½ç¨‹ç©©æ…‹ç›£æ§  
âœ… ç”¢å“å“è³ªæ§åˆ¶

**ä¸é©åˆå ´æ™¯**ï¼š

âŒ æ•¸æ“šæ˜é¡¯éé«˜æ–¯åˆ†å¸ƒï¼ˆåæ…‹ã€å¤šå³°ï¼‰  
âŒ é«˜ç¶­æ•¸æ“šï¼ˆ $d > 50$ ï¼‰  
âŒ è¤‡é›œéç·šæ€§é‚Šç•Œ  
âŒ å¤šæ“ä½œæ¨¡å¼ä¸”æœªåˆ†é–‹å»ºæ¨¡  
âŒ æ¨£æœ¬æ•¸ä¸è¶³ï¼ˆ $n < 5d$ ï¼‰  
âŒ éœ€è¦è™•ç†ä»»æ„å½¢ç‹€ç•°å¸¸å€åŸŸ

### 6.2 åƒæ•¸èª¿æ•´ç­–ç•¥

#### 6.2.1 `contamination` èª¿æ•´

**ç­–ç•¥ 1ï¼šåŸºæ–¼æ­·å²æ•¸æ“š**
```python
# å¦‚æœæœ‰éƒ¨åˆ†æ¨™ç±¤æ•¸æ“šï¼Œä¼°è¨ˆå¯¦éš›ç•°å¸¸æ¯”ä¾‹
historical_outlier_rate = 0.08
model = EllipticEnvelope(contamination=historical_outlier_rate)
```

**ç­–ç•¥ 2ï¼šäº¤å‰é©—è­‰**
```python
from sklearn.model_selection import GridSearchCV

param_grid = {'contamination': [0.05, 0.1, 0.15, 0.2]}
# æ³¨æ„ï¼šéœ€è¦è‡ªå®šç¾©è©•åˆ†å‡½æ•¸ï¼Œå› ç‚º EllipticEnvelope ä¸æ”¯æŒæ¨™æº– GridSearchCV
```

**ç­–ç•¥ 3ï¼šè¦–è¦ºåŒ–èª¿æ•´**
```python
for cont in [0.05, 0.1, 0.15, 0.2]:
    model = EllipticEnvelope(contamination=cont, random_state=42)
    model.fit(X)
    y_pred = model.predict(X)
    
    plt.figure(figsize=(6, 6))
    plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap='RdYlGn')
    plt.title(f'Contamination = {cont}')
    plt.show()
```

#### 6.2.2 `support_fraction` èª¿æ•´

**ä¸€èˆ¬å»ºè­°**ï¼šä½¿ç”¨é è¨­å€¼ï¼ˆ `None` ï¼‰ï¼Œé™¤éï¼š

- å·²çŸ¥æ±¡æŸ“æ¯”ä¾‹å¾ˆé«˜ï¼ˆ $>20\%$ ï¼‰ï¼šé™ä½ `support_fraction`
- æ•¸æ“šéå¸¸ä¹¾æ·¨ï¼šå¯é©åº¦æé«˜ `support_fraction`

```python
# é«˜æ±¡æŸ“å ´æ™¯
model = EllipticEnvelope(
    contamination=0.3,
    support_fraction=0.5,  # ä½¿ç”¨ 50% æ•¸æ“šä¼°è¨ˆ
    random_state=42
)

# ä½æ±¡æŸ“å ´æ™¯
model = EllipticEnvelope(
    contamination=0.05,
    support_fraction=None,  # è‡ªå‹•è¨ˆç®—
    random_state=42
)
```

### 6.3 å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

#### å•é¡Œ 1ï¼šæ•¸æ“šä¸ç¬¦åˆé«˜æ–¯åˆ†å¸ƒ

**è¨ºæ–·**ï¼š
```python
from scipy import stats

# å–®è®Šé‡å¸¸æ…‹æ€§æª¢é©—ï¼ˆShapiro-Wilk Testï¼‰
for i in range(X.shape[1]):
    statistic, pvalue = stats.shapiro(X[:, i])
    print(f"Feature {i}: p-value = {pvalue:.4f}")
    if pvalue < 0.05:
        print("  âš ï¸ ä¸ç¬¦åˆå¸¸æ…‹åˆ†å¸ƒ")

# å¤šè®Šé‡å¸¸æ…‹æ€§æª¢é©—ï¼ˆMardia's Test æˆ–è¦–è¦ºåŒ–ï¼‰
```

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# æ–¹æ¡ˆ 1ï¼šæ•¸æ“šè½‰æ›
from sklearn.preprocessing import PowerTransformer

transformer = PowerTransformer(method='yeo-johnson')
X_transformed = transformer.fit_transform(X)

model = EllipticEnvelope(contamination=0.1)
model.fit(X_transformed)

# æ–¹æ¡ˆ 2ï¼šæ”¹ç”¨å…¶ä»–æ–¹æ³•
from sklearn.ensemble import IsolationForest
model = IsolationForest(contamination=0.1, random_state=42)
```

#### å•é¡Œ 2ï¼šé«˜ç¶­åº¦æ•ˆæœä¸ä½³

**è¨ºæ–·**ï¼š
```python
n_samples, n_features = X.shape
print(f"æ¨£æœ¬æ•¸ / ç¶­åº¦æ¯” = {n_samples / n_features:.2f}")

if n_samples / n_features < 10:
    print("âš ï¸ æ¨£æœ¬æ•¸ç›¸å°ç¶­åº¦éå°‘ï¼Œå¯èƒ½å½±éŸ¿ä¼°è¨ˆæº–ç¢ºæ€§")
```

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# æ–¹æ¡ˆ 1ï¼šé™ç¶­
from sklearn.decomposition import PCA

pca = PCA(n_components=0.95)  # ä¿ç•™ 95% è®Šç•°
X_reduced = pca.fit_transform(X)

model = EllipticEnvelope(contamination=0.1)
model.fit(X_reduced)

# æ–¹æ¡ˆ 2ï¼šç‰¹å¾µé¸æ“‡
from sklearn.feature_selection import VarianceThreshold

selector = VarianceThreshold(threshold=0.1)
X_selected = selector.fit_transform(X)

model = EllipticEnvelope(contamination=0.1)
model.fit(X_selected)
```

#### å•é¡Œ 3ï¼šå¤šæ¨¡æ…‹æ•¸æ“š

**è¨ºæ–·**ï¼š
```python
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# é™ç¶­è‡³ 2D å¯è¦–åŒ–
pca = PCA(n_components=2)
X_2d = pca.fit_transform(X)

plt.scatter(X_2d[:, 0], X_2d[:, 1])
plt.title('Data Distribution (2D PCA)')
plt.show()
# å¦‚æœçœ‹åˆ°æ˜é¡¯å¤šå€‹èšé¡ï¼Œå‰‡ç‚ºå¤šæ¨¡æ…‹
```

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# æ–¹æ¡ˆ 1ï¼šåˆ†æ¨¡å¼å»ºæ¨¡ï¼ˆè¦‹ 5.6 ç¯€ï¼‰

# æ–¹æ¡ˆ 2ï¼šä½¿ç”¨é©åˆå¤šæ¨¡æ…‹çš„æ–¹æ³•
from sklearn.neighbors import LocalOutlierFactor
model = LocalOutlierFactor(n_neighbors=20, contamination=0.1)
```

### 6.4 æ•ˆèƒ½è©•ä¼°

å°æ–¼æœ‰éƒ¨åˆ†æ¨™ç±¤çš„æ•¸æ“šï¼š

```python
from sklearn.metrics import (
    precision_score, recall_score, f1_score,
    roc_auc_score, roc_curve, confusion_matrix
)

# é æ¸¬
y_pred = model.predict(X_test)
y_scores = model.decision_function(X_test)

# åˆ†é¡æŒ‡æ¨™
precision = precision_score(y_true, y_pred, pos_label=-1)
recall = recall_score(y_true, y_pred, pos_label=-1)
f1 = f1_score(y_true, y_pred, pos_label=-1)

print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1-Score: {f1:.3f}")

# ROC æ›²ç·š
# æ³¨æ„ï¼šdecision_function çš„å€¼éœ€è¦å–è² è™Ÿï¼Œå› ç‚ºç•°å¸¸é»çš„å€¼æ›´è² 
fpr, tpr, thresholds = roc_curve(y_true, -y_scores, pos_label=-1)
auc = roc_auc_score(y_true, -y_scores)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')
plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Elliptic Envelope')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

# æ··æ·†çŸ©é™£
cm = confusion_matrix(y_true, y_pred)
print("æ··æ·†çŸ©é™£:")
print(cm)
```

### 6.5 åŒ–å·¥è£½ç¨‹å¯¦å‹™å»ºè­°

#### å»ºè­° 1ï¼šè£½ç¨‹ç©©å®šå¾Œå†å»ºæ¨¡

```python
# ç¢ºä¿ä½¿ç”¨ç©©æ…‹æ•¸æ“šå»ºæ¨¡
# æ’é™¤å•Ÿå‹•ã€é—œæ©Ÿã€éæ¸¡éšæ®µçš„æ•¸æ“š

import pandas as pd

df = pd.read_csv('process_data.csv')

# è­˜åˆ¥ç©©æ…‹æ“ä½œ
df['is_steady_state'] = (
    (df['temperature'].rolling(10).std() < 2) &  # æº«åº¦è®Šç•°å°
    (df['pressure'].rolling(10).std() < 0.1) &   # å£“åŠ›è®Šç•°å°
    (df['flowrate'].rolling(10).std() < 5)       # æµé‡è®Šç•°å°
)

# åƒ…ä½¿ç”¨ç©©æ…‹æ•¸æ“šè¨“ç·´
X_steady = df[df['is_steady_state']][['temperature', 'pressure', 'flowrate']].values
model.fit(X_steady)
```

#### å»ºè­° 2ï¼šå®šæœŸé‡æ–°è¨“ç·´

è£½ç¨‹ç‰¹æ€§å¯èƒ½éš¨æ™‚é–“è®ŠåŒ–ï¼ˆè¨­å‚™è€åŒ–ã€åŸæ–™è®Šæ›´ç­‰ï¼‰ï¼Œå»ºè­°å®šæœŸæ›´æ–°æ¨¡å‹ï¼š

```python
# æ»¾å‹•è¦–çª—è¨“ç·´
window_size = 1000  # ä½¿ç”¨æœ€è¿‘ 1000 å€‹æ­£å¸¸æ¨£æœ¬

def update_model(X_historical, X_new):
    # åˆä½µæ­·å²èˆ‡æ–°æ•¸æ“š
    X_combined = np.vstack([X_historical, X_new])
    
    # åƒ…ä¿ç•™æœ€è¿‘è¦–çª—å…§çš„æ•¸æ“š
    if len(X_combined) > window_size:
        X_combined = X_combined[-window_size:]
    
    # é‡æ–°è¨“ç·´
    model = EllipticEnvelope(contamination=0.1, random_state=42)
    model.fit(X_combined)
    
    return model, X_combined

# å®šæœŸï¼ˆå¦‚æ¯é€±ï¼‰æ›´æ–°
model, X_historical = update_model(X_historical, X_new_week)
```

#### å»ºè­° 3ï¼šçµåˆé ˜åŸŸçŸ¥è­˜

```python
# ç‰©ç†ç´„æŸï¼šæº«åº¦èˆ‡å£“åŠ›çš„åˆç†ç¯„åœ
def apply_domain_knowledge(predictions, X, temp_range=(150, 200), press_range=(1.5, 3.5)):
    """çµåˆé ˜åŸŸçŸ¥è­˜çš„ç•°å¸¸åˆ¤å®š"""
    
    # æ©¢åœ“åŒ…çµ¡é æ¸¬
    elliptic_outliers = predictions == -1
    
    # ç‰©ç†ç´„æŸæª¢æŸ¥
    temp_outliers = (X[:, 0] < temp_range[0]) | (X[:, 0] > temp_range[1])
    press_outliers = (X[:, 1] < press_range[0]) | (X[:, 1] > press_range[1])
    
    # çµ„åˆåˆ¤å®šï¼šæ©¢åœ“åŒ…çµ¡ OR ç‰©ç†ç´„æŸ
    combined_outliers = elliptic_outliers | temp_outliers | press_outliers
    
    return combined_outliers

# æ‡‰ç”¨
y_pred = model.predict(X)
final_outliers = apply_domain_knowledge(y_pred, X)
```

#### å»ºè­° 4ï¼šå¤šå±¤æ¬¡ç›£æ§

```python
# ç¬¬ä¸€å±¤ï¼šå¿«é€Ÿç¯©é¸ï¼ˆæ©¢åœ“åŒ…çµ¡ï¼‰
model_fast = EllipticEnvelope(contamination=0.15, random_state=42)
model_fast.fit(X_train)

# ç¬¬äºŒå±¤ï¼šç²¾ç´°æª¢æ¸¬ï¼ˆåš´æ ¼åƒæ•¸ï¼‰
model_strict = EllipticEnvelope(contamination=0.05, random_state=42)
model_strict.fit(X_train)

# åˆ†ç´šè­¦å ±
def classify_alert_level(X_test):
    pred_fast = model_fast.predict(X_test)
    pred_strict = model_strict.predict(X_test)
    
    alert_levels = []
    for i in range(len(X_test)):
        if pred_strict[i] == -1:
            alert_levels.append('HIGH')      # å…©å€‹æ¨¡å‹éƒ½æª¢æ¸¬åˆ°
        elif pred_fast[i] == -1:
            alert_levels.append('MEDIUM')    # åƒ…å¿«é€Ÿæ¨¡å‹æª¢æ¸¬åˆ°
        else:
            alert_levels.append('NORMAL')    # å‡æœªæª¢æ¸¬åˆ°
    
    return alert_levels

# æ‡‰ç”¨
alerts = classify_alert_level(X_test)
```

#### å»ºè­° 5ï¼šå¯è¦–åŒ–ç›£æ§å„€è¡¨æ¿

```python
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse

def plot_monitoring_dashboard(model, X_current, X_historical):
    """è£½ç¨‹ç›£æ§å„€è¡¨æ¿"""
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 12))
    
    # 1. å¯¦æ™‚ç›£æ§åœ–
    ax1 = axes[0, 0]
    mahal_dist = model.mahalanobis(X_current)
    colors = ['red' if d > model.threshold_ else 'green' for d in mahal_dist]
    ax1.scatter(X_current[:, 0], X_current[:, 1], c=colors, s=50, alpha=0.6)
    ax1.set_xlabel('Temperature (Â°C)')
    ax1.set_ylabel('Pressure (bar)')
    ax1.set_title('Current Process Status')
    
    # ç¹ªè£½æ©¢åœ“é‚Šç•Œ
    eigenvalues, eigenvectors = np.linalg.eigh(model.covariance_)
    angle = np.degrees(np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0]))
    width, height = 2 * np.sqrt(model.threshold_) * np.sqrt(eigenvalues)
    ellipse = Ellipse(model.location_, width, height, angle=angle,
                     fill=False, edgecolor='blue', linewidth=2)
    ax1.add_patch(ellipse)
    
    # 2. é¦¬æ°è·é›¢æ™‚é–“åºåˆ—
    ax2 = axes[0, 1]
    time_steps = np.arange(len(mahal_dist))
    ax2.plot(time_steps, mahal_dist, marker='o', linestyle='-', color='blue')
    ax2.axhline(y=model.threshold_, color='red', linestyle='--', label='Threshold')
    ax2.set_xlabel('Time Step')
    ax2.set_ylabel('Mahalanobis Distance')
    ax2.set_title('Mahalanobis Distance Over Time')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. ç•°å¸¸çµ±è¨ˆ
    ax3 = axes[1, 0]
    n_outliers = np.sum(mahal_dist > model.threshold_)
    n_normal = len(mahal_dist) - n_outliers
    ax3.bar(['Normal', 'Outlier'], [n_normal, n_outliers], color=['green', 'red'])
    ax3.set_ylabel('Count')
    ax3.set_title(f'Status Summary (Outlier Rate: {n_outliers/len(mahal_dist):.1%})')
    
    # 4. æ­·å²è¶¨å‹¢
    ax4 = axes[1, 1]
    ax4.scatter(X_historical[:, 0], X_historical[:, 1], 
               c='gray', s=10, alpha=0.3, label='Historical')
    ax4.scatter(X_current[:, 0], X_current[:, 1], 
               c=colors, s=50, alpha=0.8, label='Current')
    ax4.set_xlabel('Temperature (Â°C)')
    ax4.set_ylabel('Pressure (bar)')
    ax4.set_title('Historical vs Current Data')
    ax4.legend()
    
    plt.tight_layout()
    plt.show()

# ä½¿ç”¨ç¯„ä¾‹
plot_monitoring_dashboard(model, X_current, X_historical)
```

---

## 7. ç¸½çµ

### 7.1 æ ¸å¿ƒè¦é»

1. **æ©¢åœ“åŒ…çµ¡åŸºæ–¼é«˜æ–¯åˆ†å¸ƒå‡è¨­**ï¼Œé€éé¦¬æ°è·é›¢è­˜åˆ¥ç•°å¸¸é»
2. **MCD æ–¹æ³•æä¾›ç©©å¥ä¼°è¨ˆ**ï¼Œèƒ½æŠµæŠ—å°‘é‡æ±¡æŸ“æ•¸æ“š
3. **è€ƒæ…®è®Šæ•¸ç›¸é—œæ€§**ï¼Œé©åˆå¤šè®Šé‡è¯åˆç›£æ§
4. **å¯è§£é‡‹æ€§å¼·**ï¼Œæ©¢åœ“é‚Šç•Œæ˜“æ–¼å¯è¦–åŒ–èˆ‡ç†è§£
5. **é©åˆä¸­ç­‰ç¶­åº¦ã€æ¥è¿‘é«˜æ–¯åˆ†å¸ƒçš„æ•¸æ“š**

### 7.2 ä½¿ç”¨æ±ºç­–æ¨¹

```
é–‹å§‹
â”‚
â”œâ”€ æ•¸æ“šæ˜¯å¦æ¥è¿‘é«˜æ–¯åˆ†å¸ƒï¼Ÿ
â”‚  â”œâ”€ æ˜¯ â†’ ç¹¼çºŒ
â”‚  â””â”€ å¦ â†’ è€ƒæ…®æ•¸æ“šè½‰æ›æˆ–ä½¿ç”¨ Isolation Forest / LOF
â”‚
â”œâ”€ è®Šæ•¸é–“æ˜¯å¦æœ‰ç›¸é—œæ€§ï¼Ÿ
â”‚  â”œâ”€ æ˜¯ â†’ æ©¢åœ“åŒ…çµ¡æ˜¯å¥½é¸æ“‡
â”‚  â””â”€ å¦ â†’ å¯è€ƒæ…®ç°¡å–®çš„çµ±è¨ˆæ–¹æ³•
â”‚
â”œâ”€ ç¶­åº¦æ˜¯å¦ä¸­ç­‰ (d < 20)ï¼Ÿ
â”‚  â”œâ”€ æ˜¯ â†’ ç¹¼çºŒ
â”‚  â””â”€ å¦ â†’ å…ˆé™ç¶­æˆ–ä½¿ç”¨ Isolation Forest
â”‚
â”œâ”€ æ¨£æœ¬æ•¸æ˜¯å¦å……è¶³ (n > 10d)ï¼Ÿ
â”‚  â”œâ”€ æ˜¯ â†’ ä½¿ç”¨æ©¢åœ“åŒ…çµ¡
â”‚  â””â”€ å¦ â†’ æ”¶é›†æ›´å¤šæ•¸æ“šæˆ–ä½¿ç”¨å…¶ä»–æ–¹æ³•
â”‚
â””â”€ æ±ºå®šï¼šä½¿ç”¨æ©¢åœ“åŒ…çµ¡
   â””â”€ è¨­å®š contamination èˆ‡ support_fraction
```

### 7.3 èˆ‡å…¶ä»–æ–¹æ³•çš„é¸æ“‡

| å ´æ™¯ | æ¨è–¦æ–¹æ³• | åŸå›  |
|------|----------|------|
| **é«˜æ–¯åˆ†å¸ƒæ•¸æ“š** | æ©¢åœ“åŒ…çµ¡ | ç¬¦åˆå‡è¨­ï¼Œæ•ˆæœæœ€ä½³ |
| **éé«˜æ–¯åˆ†å¸ƒæ•¸æ“š** | Isolation Forest | ç„¡åˆ†å¸ƒå‡è¨­ |
| **å¤šæ¨¡æ…‹æ•¸æ“š** | LOF | åŸºæ–¼å±€éƒ¨å¯†åº¦ |
| **é«˜ç¶­æ•¸æ“š** | Isolation Forest | å°ç¶­åº¦ä¸æ•æ„Ÿ |
| **å°æ¨£æœ¬æ•¸æ“š** | One-Class SVM | æ ¸æ–¹æ³•é©åˆå°æ¨£æœ¬ |
| **éœ€è¦é«˜åº¦å¯è§£é‡‹æ€§** | æ©¢åœ“åŒ…çµ¡ | æ©¢åœ“é‚Šç•Œç›´è§€ |
| **è¤‡é›œéç·šæ€§é‚Šç•Œ** | One-Class SVM + RBF Kernel | éˆæ´»æ€§é«˜ |

### 7.4 å»¶ä¼¸å­¸ç¿’

1. **ç©©å¥çµ±è¨ˆå­¸**ï¼šæ·±å…¥å­¸ç¿’ MCDã€MVE ç­‰ç©©å¥ä¼°è¨ˆæ–¹æ³•
2. **å¤šè®Šé‡çµ±è¨ˆ**ï¼šHotelling's TÂ² æ§åˆ¶åœ–ã€MEWMA æ§åˆ¶åœ–
3. **éåƒæ•¸æ–¹æ³•**ï¼šKernel Density Estimation (KDE)
4. **æ·±åº¦å­¸ç¿’æ–¹æ³•**ï¼šAutoencoder ç”¨æ–¼ç•°å¸¸æª¢æ¸¬
5. **æ™‚é–“åºåˆ—ç•°å¸¸æª¢æ¸¬**ï¼šå‹•æ…‹è£½ç¨‹çš„ç•°å¸¸æª¢æ¸¬æ–¹æ³•

### 7.5 å¯¦å‹™æª¢æŸ¥æ¸…å–®

åœ¨å¯¦éš›æ‡‰ç”¨æ©¢åœ“åŒ…çµ¡æ™‚ï¼Œè«‹ç¢ºèªï¼š

- [ ] æ•¸æ“šå·²æ¨™æº–åŒ–æˆ–æ­£è¦åŒ–
- [ ] é©—è­‰æ•¸æ“šæ¥è¿‘é«˜æ–¯åˆ†å¸ƒï¼ˆæˆ–å·²è½‰æ›ï¼‰
- [ ] æ¨£æœ¬æ•¸å……è¶³ï¼ˆ $n > 10d$ ï¼‰
- [ ] åˆç†è¨­å®š `contamination` åƒæ•¸
- [ ] è€ƒæ…®å®šæœŸé‡æ–°è¨“ç·´æ¨¡å‹
- [ ] çµåˆé ˜åŸŸçŸ¥è­˜é€²è¡Œé©—è­‰
- [ ] å»ºç«‹å¯è¦–åŒ–ç›£æ§æ©Ÿåˆ¶
- [ ] è©•ä¼°èª¤å ±èˆ‡æ¼å ±çš„æˆæœ¬
- [ ] è¨˜éŒ„ä¸¦åˆ†æèª¤åˆ¤æ¡ˆä¾‹
- [ ] èˆ‡è£½ç¨‹å·¥ç¨‹å¸«ä¿æŒæºé€š

---

## 8. åƒè€ƒè³‡æº

### 8.1 ç†è«–åƒè€ƒ

1. **Rousseeuw, P. J., & Driessen, K. V. (1999)**. "A fast algorithm for the minimum covariance determinant estimator." *Technometrics*, 41(3), 212-223.
   - MCD æ¼”ç®—æ³•çš„åŸå§‹è«–æ–‡

2. **Hardin, J., & Rocke, D. M. (2005)**. "The distribution of robust distances." *Journal of Computational and Graphical Statistics*, 14(4), 928-946.
   - é¦¬æ°è·é›¢åœ¨ç©©å¥ä¼°è¨ˆä¸­çš„åˆ†å¸ƒç†è«–

3. **Hubert, M., Debruyne, M., & Rousseeuw, P. J. (2018)**. "Minimum covariance determinant and extensions." *Wiley Interdisciplinary Reviews: Computational Statistics*, 10(3), e1421.
   - MCD æ–¹æ³•çš„ç¶œè¿°æ–‡ç« 

### 8.2 scikit-learn æ–‡æª”

- [EllipticEnvelope API æ–‡æª”](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html)
- [Novelty and Outlier Detection ç”¨æˆ¶æŒ‡å—](https://scikit-learn.org/stable/modules/outlier_detection.html)
- [Covariance Estimation æ¨¡çµ„](https://scikit-learn.org/stable/modules/covariance.html)

### 8.3 åŒ–å·¥æ‡‰ç”¨æ¡ˆä¾‹

1. **Kourti, T., & MacGregor, J. F. (1995)**. "Process analysis, monitoring and diagnosis, using multivariate projection methods." *Chemometrics and Intelligent Laboratory Systems*, 28(1), 3-21.
   - å¤šè®Šé‡çµ±è¨ˆè£½ç¨‹ç›£æ§ç¶“å…¸æ–‡ç»

2. **Chiang, L. H., Russell, E. L., & Braatz, R. D. (2000)**. *Fault Detection and Diagnosis in Industrial Systems*. Springer.
   - åŒ–å·¥è£½ç¨‹æ•…éšœæª¢æ¸¬å°ˆæ›¸

3. **Qin, S. J. (2012)**. "Survey on data-driven industrial process monitoring and diagnosis." *Annual Reviews in Control*, 36(2), 220-234.
   - æ•¸æ“šé©…å‹•è£½ç¨‹ç›£æ§ç¶œè¿°

### 8.4 ç·šä¸Šè³‡æº

- [scikit-learn ç•°å¸¸æª¢æ¸¬æ•™å­¸](https://scikit-learn.org/stable/auto_examples/applications/plot_outlier_detection_wine.html)
- [Robust Covariance Estimation Tutorial](https://scikit-learn.org/stable/auto_examples/covariance/plot_robust_vs_empirical_covariance.html)
- [Mahalanobis Distance Explained](https://www.machinelearningplus.com/statistics/mahalanobis-distance/)

---

## é™„éŒ„ Aï¼šæ•¸å­¸æ¨å°è£œå……

### A.1 é¦¬æ°è·é›¢èˆ‡æ­æ°è·é›¢çš„é—œä¿‚

ç•¶å…±è®Šç•°æ•¸çŸ©é™£ç‚ºå–®ä½çŸ©é™£ $\mathbf{\Sigma} = \mathbf{I}$ æ™‚ï¼Œé¦¬æ°è·é›¢é€€åŒ–ç‚ºæ­æ°è·é›¢ï¼š

$$
D_M(\mathbf{x}) = \sqrt{(\mathbf{x} - \boldsymbol{\mu})^T \mathbf{I}^{-1} (\mathbf{x} - \boldsymbol{\mu})} = \|\mathbf{x} - \boldsymbol{\mu}\|_2
$$

### A.2 æ©¢åœ“æ–¹ç¨‹çš„æ¨™æº–å½¢å¼

é€éç‰¹å¾µå€¼åˆ†è§£ï¼Œå…±è®Šç•°æ•¸çŸ©é™£å¯è¡¨ç¤ºç‚ºï¼š

$$
\mathbf{\Sigma} = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^T
$$

å…¶ä¸­ $\mathbf{V}$ æ˜¯ç‰¹å¾µå‘é‡çŸ©é™£ï¼Œ $\mathbf{\Lambda} = \text{diag}(\lambda_1, \lambda_2, \ldots, \lambda_d)$ æ˜¯ç‰¹å¾µå€¼çŸ©é™£ã€‚

å°‡æ•¸æ“šè½‰æ›è‡³ä¸»è»¸åº§æ¨™ç³»ï¼š

$$
\mathbf{y} = \mathbf{V}^T (\mathbf{x} - \boldsymbol{\mu})
$$

æ©¢åœ“æ–¹ç¨‹ç°¡åŒ–ç‚ºï¼š

$$
\sum_{i=1}^{d} \frac{y_i^2}{\lambda_i} = c^2
$$

é€™æ˜¯æ¨™æº–æ©¢åœ“æ–¹ç¨‹ï¼Œå„è»¸åŠå¾‘ç‚º $c\sqrt{\lambda_i}$ ã€‚

### A.3 å¡æ–¹åˆ†å¸ƒçš„ç™¾åˆ†ä½æ•¸

å°æ–¼é¡¯è‘—æ€§æ°´æº– $\alpha$ ï¼Œå¡æ–¹åˆ†å¸ƒçš„ $(1-\alpha)$ ç™¾åˆ†ä½æ•¸ç‚º $\chi^2_{d, 1-\alpha}$ ã€‚

å¸¸ç”¨å€¼ï¼ˆè‡ªç”±åº¦ $d=2$ ï¼‰ï¼š
- 95% ä¿¡è³´å€é–“ï¼š $\chi^2_{2, 0.95} = 5.991$
- 99% ä¿¡è³´å€é–“ï¼š $\chi^2_{2, 0.99} = 9.210$

å°æ‡‰çš„é¦¬æ°è·é›¢é–¾å€¼ï¼š
- 95%ï¼š $D_M = \sqrt{5.991} \approx 2.448$
- 99%ï¼š $D_M = \sqrt{9.210} \approx 3.035$

---

## é™„éŒ„ Bï¼šå®Œæ•´ç¨‹å¼ç¢¼ç¯„ä¾‹

å®Œæ•´çš„åŒ–å·¥æ‡‰ç”¨ç¯„ä¾‹ç¨‹å¼ç¢¼è«‹åƒè€ƒé…å¥—çš„ Jupyter Notebookï¼š
**`Unit07_Elliptic_Envelope.ipynb`**

ç¯„ä¾‹å…§å®¹åŒ…å«ï¼š
- æ‰¹æ¬¡åæ‡‰å™¨æ•¸æ“šç”Ÿæˆ
- æ©¢åœ“åŒ…çµ¡æ¨¡å‹è¨“ç·´èˆ‡è¶…åƒæ•¸èª¿æ•´
- å¤šç¨®å¯è¦–åŒ–åˆ†æ
- èˆ‡å…¶ä»–ç•°å¸¸æª¢æ¸¬æ–¹æ³•çš„æ¯”è¼ƒ
- å¯¦æ™‚ç›£æ§å„€è¡¨æ¿å¯¦ä½œ

---

**èª²ç¨‹çµæŸ**

æ­å–œæ‚¨å®Œæˆæ©¢åœ“åŒ…çµ¡ (Elliptic Envelope) ç•°å¸¸æª¢æ¸¬çš„å­¸ç¿’ï¼ç¾åœ¨æ‚¨å·²å…·å‚™ï¼š

âœ… æ©¢åœ“åŒ…çµ¡çš„ç†è«–åŸºç¤èˆ‡æ•¸å­¸åŸç†  
âœ… Python å¯¦ä½œèˆ‡åƒæ•¸èª¿æ•´æŠ€å·§  
âœ… åŒ–å·¥è£½ç¨‹æ‡‰ç”¨çš„å¯¦å‹™ç¶“é©—  
âœ… èˆ‡å…¶ä»–æ–¹æ³•çš„æ¯”è¼ƒèˆ‡é¸æ“‡èƒ½åŠ›

å»ºè­°æ¥ä¸‹ä¾†ï¼š
1. å®Œæˆé…å¥—çš„ Jupyter Notebook ç·´ç¿’
2. å˜—è©¦å°‡æ©¢åœ“åŒ…çµ¡æ‡‰ç”¨æ–¼æ‚¨çš„å¯¦éš›æ•¸æ“š
3. å­¸ç¿’ Unit07 çš„å…¶ä»–ç•°å¸¸æª¢æ¸¬æ–¹æ³•ï¼ˆIsolation Forestã€One-Class SVMã€LOFï¼‰
4. æ¢ç´¢å¤šæ–¹æ³•é›†æˆçš„ç•°å¸¸æª¢æ¸¬ç­–ç•¥

**ä¸‹ä¸€å–®å…ƒé å‘Š**ï¼šUnit08 é—œè¯è¦å‰‡å­¸ç¿’ (Association Rule Learning)

---
