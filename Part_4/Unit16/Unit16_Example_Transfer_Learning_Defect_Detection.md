# Unit16ï½œé·ç§»å­¸ç¿’ + å·¥æ¥­ç¼ºé™·æª¢æ¸¬ï¼ˆNEU Surface Defect Databaseï¼‰

**Part 4 - æ·±åº¦å­¸ç¿’é€²éšæ‡‰ç”¨**

> **æ•™å­¸ç›®æ¨™**ï¼šæœ¬å–®å…ƒå»¶çºŒ Unit16_CNN_Basics_Industrial_Inspection çš„å…§å®¹ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨é·ç§»å­¸ç¿’ï¼ˆTransfer Learningï¼‰æŠ€è¡“ï¼Œå°‡åœ¨ ImageNet ä¸Šé è¨“ç·´çš„ MobileNetV2 æ¨¡å‹æ‡‰ç”¨æ–¼å·¥æ¥­ç¼ºé™·æª¢æ¸¬ä»»å‹™ã€‚é€éå°æ¯”å¾é ­è¨“ç·´çš„ CNN æ¨¡å‹ï¼ˆUnit16ï¼Œ96.94%ï¼‰èˆ‡é·ç§»å­¸ç¿’æ¨¡å‹ï¼ˆMobileNetV2ï¼Œ100%ï¼‰çš„æ€§èƒ½å·®ç•°ï¼Œæ·±å…¥ç†è§£é·ç§»å­¸ç¿’åœ¨å°æ¨£æœ¬æ•¸æ“šé›†ä¸Šçš„å„ªå‹¢ã€‚

---

## ğŸ“š æœ¬å–®å…ƒæ ¸å¿ƒå…§å®¹

### å­¸ç¿’ç›®æ¨™

1. **ç†è§£é·ç§»å­¸ç¿’åŸç†**ï¼šæŒæ¡å¾ ImageNet é è¨“ç·´æ¨¡å‹é·ç§»åˆ°å·¥æ¥­ç¼ºé™·æª¢æ¸¬çš„ç†è«–åŸºç¤
2. **å…©éšæ®µè¨“ç·´ç­–ç•¥**ï¼šå¯¦è¸å‡çµ â†’ å¾®èª¿ï¼ˆFeature Extraction + Fine-tuningï¼‰çš„å®Œæ•´æµç¨‹
3. **å·¥æ¥­AIå¯¦å‹™æŠ€å·§**ï¼š
   - è³‡æ–™è¼‰å…¥èˆ‡é è™•ç†ï¼ˆ`ImageDataGenerator`ï¼‰
   - å­¸ç¿’ç‡èª¿åº¦ï¼ˆLearning Rate Schedulingï¼‰
   - æ¨¡å‹è©•ä¼°èˆ‡æ ¡æ­£ï¼ˆCalibrationï¼‰
   - æ±ºç­–é‚è¼¯è¨­è¨ˆï¼ˆPass/Review/Failï¼‰
4. **å°æ¯”å­¸ç¿’**ï¼šé‡åŒ–åˆ†æå¾é ­è¨“ç·´ CNNï¼ˆUnit16ï¼Œ96.94%ï¼‰vs. é·ç§»å­¸ç¿’ï¼ˆMobileNetV2ï¼Œ100%ï¼‰çš„æ€§èƒ½å·®ç•°

### æ•¸æ“šé›†ä»‹ç´¹ï¼šNEU Surface Defect Database

**NEU-DET** æ˜¯ç”±ä¸­åœ‹æ±åŒ—å¤§å­¸ï¼ˆNortheastern Universityï¼‰ç™¼å¸ƒçš„é‹¼æè¡¨é¢ç¼ºé™·æ•¸æ“šé›†ï¼Œå»£æ³›æ‡‰ç”¨æ–¼å·¥æ¥­ç¼ºé™·æª¢æ¸¬ç ”ç©¶ï¼š

- **ä¾†æº**ï¼šç†±è»‹é‹¼å¸¶ç”Ÿç”¢ç·šçš„å¯¦éš›æ¡é›†å½±åƒ
- **è¦æ¨¡**ï¼š6ç¨®ç¼ºé™·é¡å‹ï¼Œæ¯é¡300å¼µç°éšå½±åƒï¼ˆå…±1800å¼µï¼‰
- **å½±åƒå°ºå¯¸**ï¼š200 Ã— 200 pixels
- **æ•¸æ“šåˆ†å‰²**ï¼š
  - è¨“ç·´é›†ï¼š1440å¼µï¼ˆ240å¼µ/é¡åˆ¥ï¼‰
  - é©—è­‰é›†ï¼š360å¼µï¼ˆ60å¼µ/é¡åˆ¥ï¼‰

**å…­ç¨®ç¼ºé™·é¡å‹ï¼ˆä¸­è‹±å°ç…§ï¼‰**ï¼š

| ç¼ºé™·é¡å‹ | è‹±æ–‡åç¨± | ç‰¹å¾µæè¿° |
|---------|---------|---------|
| é¾œè£‚ | Crazing | è¡¨é¢ç´°å°è£‚ç´‹ç¶²ï¼Œåš´é‡å½±éŸ¿çµæ§‹å¼·åº¦ |
| å¤¾é›œ | Inclusion | å…§éƒ¨é›œè³ªæš´éœ²æ–¼è¡¨é¢ï¼Œå‘ˆé»ç‹€ç‘•ç–µ |
| æ–‘å¡Š | Patches | ä¸è¦å‰‡çš„å¤§é¢ç©æš—è‰²å€åŸŸ |
| éº»é» | Pitted Surface | å°è€Œå¯†é›†çš„è¡¨é¢å‡¹é™· |
| æ°§åŒ–çš® | Rolled-in Scale | é«˜æº«æ°§åŒ–ç”¢ç”Ÿçš„é±—ç‰‡ç‹€ç¼ºé™· |
| åŠƒç—• | Scratches | ç·šæ€§æ©Ÿæ¢°æå‚· |

---

## ç¬¬ä¸€ç« ï¼šé·ç§»å­¸ç¿’ç†è«–åŸºç¤

### 1.1 ç‚ºä»€éº¼å·¥æ¥­å½±åƒéœ€è¦é·ç§»å­¸ç¿’ï¼Ÿ

#### æ·±åº¦å­¸ç¿’çš„ã€Œè³‡æ–™é£¢æ¸´ã€å•é¡Œ

æ·±åº¦ç¥ç¶“ç¶²è·¯å…·æœ‰å¼·å¤§çš„è¡¨é”èƒ½åŠ›ï¼Œä½†é€™ç¨®èƒ½åŠ›æ˜¯ä»¥å¤§é‡åƒæ•¸ç‚ºä»£åƒ¹çš„ã€‚ä»¥å…¸å‹çš„å·ç©ç¥ç¶“ç¶²è·¯ï¼ˆCNNï¼‰ç‚ºä¾‹ï¼Œç¬¬ $l$ å±¤çš„è¼¸å‡ºå¯è¡¨ç¤ºç‚ºï¼š

$$
\mathbf{h}^{(l)} = f^{(l)}\bigl(\mathbf{W}^{(l)} * \mathbf{h}^{(l-1)} + \mathbf{b}^{(l)}\bigr)
$$

å…¶ä¸­ï¼š
- $\mathbf{W}^{(l)}$ ã€ $\mathbf{b}^{(l)}$ ï¼šç¬¬ $l$ å±¤çš„å·ç©æ ¸æ¬Šé‡èˆ‡åç½®
- $*$ ï¼šå·ç©é‹ç®—ç¬¦è™Ÿ
- $f^{(l)}$ ï¼šéç·šæ€§æ¿€æ´»å‡½æ•¸ï¼ˆå¦‚ ReLUï¼‰
- $\mathbf{h}^{(l-1)}$ ï¼šå‰ä¸€å±¤çš„ç‰¹å¾µåœ–

**åƒæ•¸é‡ä¼°ç®—**ï¼šä¸€å€‹å…¸å‹çš„æ·±åº¦CNNå¯èƒ½åŒ…å«æ•¸ç™¾è¬ç”šè‡³æ•¸åƒè¬å€‹åƒæ•¸ã€‚ä¾‹å¦‚ï¼š
- VGG-16ï¼šç´„ 138M åƒæ•¸
- ResNet-50ï¼šç´„ 25M åƒæ•¸
- MobileNetV2ï¼šç´„ 3.5M åƒæ•¸

è¦æœ‰æ•ˆè¨“ç·´é€™äº›åƒæ•¸ï¼Œé€šå¸¸éœ€è¦ï¼š
- **ImageNetè¦æ¨¡**ï¼š140è¬å¼µå½±åƒï¼Œ1000å€‹é¡åˆ¥
- **è¨“ç·´æ™‚é–“**ï¼šæ•¸å¤©åˆ°æ•¸é€±ï¼ˆä½¿ç”¨GPUåŠ é€Ÿï¼‰

**å·¥æ¥­å ´æ™¯çš„å›°å¢ƒ**ï¼š
- âŒ æ¨™è¨»æ•¸æ“šç¨€ç¼ºï¼šå°ˆå®¶æ¨™è¨»è€—æ™‚è²»åŠ›ï¼Œé€šå¸¸åªæœ‰æ•¸ç™¾åˆ°æ•¸åƒå¼µå½±åƒ
- âŒ é¡åˆ¥ä¸å¹³è¡¡ï¼šè‰¯å“æ¥µå¤šï¼Œç¼ºé™·æ¨£æœ¬æ¥µå°‘
- âŒ æ•¸æ“šåˆ†å¸ƒæ¼‚ç§»ï¼šåŸæ–™æ‰¹æ¬¡ã€å…‰ç…§æ¢ä»¶ã€è¨­å‚™è€åŒ–éƒ½æœƒå½±éŸ¿å½±åƒç‰¹æ€§

**éæ“¬åˆçš„æ•¸å­¸è¡¨ç¾**ï¼š

è¨“ç·´æå¤± $\mathcal{L}_{\text{train}}$ èˆ‡é©—è­‰æå¤± $\mathcal{L}_{\text{val}}$ ä¹‹é–“å­˜åœ¨é¡¯è‘—å·®è·ï¼š

$$
\text{Generalization Gap} = \mathcal{L}_{\text{val}} - \mathcal{L}_{\text{train}} \gg 0
$$

ç•¶ Generalization Gap éå¤§æ™‚ï¼Œæ¨¡å‹åœ¨è¨“ç·´é›†ä¸Šè¡¨ç¾è‰¯å¥½ä½†åœ¨å¯¦éš›æ‡‰ç”¨ä¸­å¤±æ•ˆã€‚

### 1.2 é·ç§»å­¸ç¿’çš„æ ¸å¿ƒæ€æƒ³

#### ç‰¹å¾µå±¤æ¬¡ç†è«–

CNNå­¸ç¿’çš„ç‰¹å¾µå…·æœ‰**å±¤æ¬¡æ€§**ï¼š

**åº•å±¤ç‰¹å¾µï¼ˆLow-level Featuresï¼‰**ï¼š
- é‚Šç·£æª¢æ¸¬å™¨ï¼ˆEdge Detectorsï¼‰
- è§’é»æª¢æ¸¬å™¨ï¼ˆCorner Detectorsï¼‰
- é¡è‰²æ–‘å¡Šï¼ˆColor Blobsï¼‰
- ç´‹ç†æ¨¡å¼ï¼ˆTexture Patternsï¼‰

é€™äº›ç‰¹å¾µåœ¨ä¸åŒè¦–è¦ºä»»å‹™ä¸­å…·æœ‰**é«˜åº¦é€šç”¨æ€§**ã€‚

**é«˜å±¤ç‰¹å¾µï¼ˆHigh-level Featuresï¼‰**ï¼š
- ç‰©é«”éƒ¨ä»¶ï¼ˆObject Partsï¼‰
- èªç¾©æ¦‚å¿µï¼ˆSemantic Conceptsï¼‰
- ä»»å‹™ç‰¹å®šæ¨¡å¼ï¼ˆTask-specific Patternsï¼‰

é€™äº›ç‰¹å¾µå…·æœ‰**ä»»å‹™ç‰¹ç•°æ€§**ï¼Œéœ€è¦é‡å°å…·é«”æ‡‰ç”¨é€²è¡Œèª¿æ•´ã€‚

#### é·ç§»å­¸ç¿’çš„æ•¸å­¸æ¡†æ¶

è¨­æºåŸŸï¼ˆSource Domainï¼‰ç‚º $\mathcal{D}_S$ ï¼Œç›®æ¨™åŸŸï¼ˆTarget Domainï¼‰ç‚º $\mathcal{D}_T$ ï¼š

$$
\mathcal{D}_S = \{(\mathbf{x}_i^S, y_i^S)\}_{i=1}^{N_S}, \quad \mathcal{D}_T = \{(\mathbf{x}_j^T, y_j^T)\}_{j=1}^{N_T}
$$

é€šå¸¸ $N_S \gg N_T$ ï¼ˆæºåŸŸæ•¸æ“šé å¤šæ–¼ç›®æ¨™åŸŸï¼‰ã€‚

**é·ç§»å­¸ç¿’ç›®æ¨™**ï¼šåˆ©ç”¨åœ¨ $\mathcal{D}_S$ ä¸Šå­¸åˆ°çš„çŸ¥è­˜ï¼Œæå‡åœ¨ $\mathcal{D}_T$ ä¸Šçš„æ€§èƒ½ã€‚

**ç‰¹å¾µæå–å™¨**ï¼š

$$
\mathbf{z} = \phi(\mathbf{x}; \theta_{\text{base}})
$$

å…¶ä¸­ $\phi$ æ˜¯é è¨“ç·´çš„ç‰¹å¾µæå–ç¶²è·¯ï¼Œ $\theta_{\text{base}}$ æ˜¯åœ¨æºåŸŸä¸Šå­¸ç¿’çš„åƒæ•¸ã€‚

**ä»»å‹™ç‰¹å®šåˆ†é¡å™¨**ï¼š

$$
\hat{y} = g(\mathbf{z}; \theta_{\text{head}})
$$

å…¶ä¸­ $g$ æ˜¯é‡å°ç›®æ¨™ä»»å‹™è¨­è¨ˆçš„åˆ†é¡é ­ï¼Œ $\theta_{\text{head}}$ æ˜¯éœ€è¦åœ¨ç›®æ¨™åŸŸä¸Šè¨“ç·´çš„åƒæ•¸ã€‚

### 1.3 MobileNetV2ï¼šé«˜æ•ˆçš„å·ç©ç¥ç¶“ç¶²è·¯

#### æ·±åº¦å¯åˆ†é›¢å·ç©ï¼ˆDepthwise Separable Convolutionï¼‰

æ¨™æº–å·ç©çš„è¨ˆç®—è¤‡é›œåº¦ï¼š

$$
\text{FLOPs}_{\text{standard}} = D_K^2 \cdot M \cdot N \cdot D_F^2
$$


å…¶ä¸­ï¼š
- $D_K$ ï¼šå·ç©æ ¸å°ºå¯¸ï¼ˆå¦‚ 3Ã—3ï¼‰
- $M$ ï¼šè¼¸å…¥é€šé“æ•¸
- $N$ ï¼šè¼¸å‡ºé€šé“æ•¸
- $D_F$ ï¼šç‰¹å¾µåœ–ç©ºé–“å°ºå¯¸

**æ·±åº¦å¯åˆ†é›¢å·ç©åˆ†è§£**ï¼š

**Step 1 - Depthwise Convolution**ï¼šå°æ¯å€‹è¼¸å…¥é€šé“ç¨ç«‹é€²è¡Œç©ºé–“å·ç©

$$
\text{FLOPs}_{\text{DW}} = D_K^2 \cdot M \cdot D_F^2
$$


**Step 2 - Pointwise Convolution**ï¼šä½¿ç”¨ 1Ã—1 å·ç©æ··åˆé€šé“ä¿¡æ¯

$$
\text{FLOPs}_{\text{PW}} = M \cdot N \cdot D_F^2
$$


**ç¸½è¨ˆç®—é‡**ï¼š

$$
\text{FLOPs}_{\text{DSC}} = D_K^2 \cdot M \cdot D_F^2 + M \cdot N \cdot D_F^2
$$


**æ•ˆç‡æå‡æ¯”**ï¼š

$$
\frac{\text{FLOPs}_{\text{DSC}}}{\text{FLOPs}_{\text{standard}}} = \frac{1}{N} + \frac{1}{D_K^2} \approx \frac{1}{8} \sim \frac{1}{9}
$$


#### Inverted Residual Block

MobileNetV2 çš„æ ¸å¿ƒå‰µæ–°æ˜¯**å€’æ®˜å·®çµæ§‹ï¼ˆInverted Residual Blockï¼‰**ï¼š

```
è¼¸å…¥ (low-dim) â†’ 1Ã—1æ“´å¼µ (expand) â†’ 3Ã—3 Depthwise â†’ 1Ã—1å£“ç¸® (project) â†’ è¼¸å‡º (low-dim)
                                    â†“
                                 ReLU6
```

**æ•¸å­¸è¡¨é”**ï¼š

$$
\mathbf{y} = \mathbf{x} + \mathcal{F}(\mathbf{x}; \mathbf{W})
$$

å…¶ä¸­ï¼š

$$
\mathcal{F}(\mathbf{x}; \mathbf{W}) = \text{Conv}_{1 \times 1}^{\text{project}} \circ \text{DWConv}_{3 \times 3} \circ \text{Conv}_{1 \times 1}^{\text{expand}}(\mathbf{x})
$$


**ç·šæ€§ç“¶é ¸ï¼ˆLinear Bottleneckï¼‰**ï¼šæœ€å¾Œçš„ 1Ã—1 å·ç©ä¸ä½¿ç”¨ ReLUï¼Œä¿ç•™è³‡è¨Šï¼š

$$
\text{ReLU}(\mathbf{z}) = \max(0, \mathbf{z})
$$


åœ¨ä½ç¶­ç©ºé–“ä¸­ï¼ŒReLU å¯èƒ½ç ´å£è³‡è¨Šï¼Œå› æ­¤æœ€å¾Œä¸€å±¤ä½¿ç”¨ç·šæ€§æ¿€æ´»ã€‚

## ç¬¬äºŒç« ï¼šå…©éšæ®µè¨“ç·´ç­–ç•¥

### 2.1 ç­–ç•¥è¨­è¨ˆç†å¿µ

**é·ç§»å­¸ç¿’çš„æ ¸å¿ƒæŒ‘æˆ°**ï¼šå¦‚ä½•åœ¨ä¿ç•™é è¨“ç·´çŸ¥è­˜çš„åŒæ™‚ï¼Œè®“æ¨¡å‹é©æ‡‰æ–°ä»»å‹™ï¼Ÿ

**å…©éšæ®µè¨“ç·´ç­–ç•¥**ï¼š

#### Stage 1ï¼šå‡çµåŸºåº•ï¼Œè¨“ç·´åˆ†é¡é ­ï¼ˆFeature Extractionï¼‰

**ç›®æ¨™**ï¼šå¿«é€Ÿè®“æ–°çš„åˆ†é¡é ­é©æ‡‰ç›®æ¨™ä»»å‹™ï¼ŒåŒæ™‚å®Œå…¨ä¿ç•™é è¨“ç·´çš„ç‰¹å¾µæå–èƒ½åŠ›ã€‚

**å¯¦ä½œç´°ç¯€**ï¼š
```python
# å‡çµ MobileNetV2 æ‰€æœ‰å±¤
for layer in base_model.layers:
    layer.trainable = False
```

**æå¤±å‡½æ•¸**ï¼š

$$
\mathcal{L}_{\text{stage1}} = -\frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_{ic} \log(\hat{y}_{ic})
$$


å…¶ä¸­ï¼š
- $y_{ic}$ ï¼šæ¨£æœ¬ $i$ å±¬æ–¼é¡åˆ¥ $c$ çš„çœŸå¯¦æ¨™ç±¤ï¼ˆone-hotç·¨ç¢¼ï¼‰
- $\hat{y}_{ic}$ ï¼šæ¨¡å‹é æ¸¬çš„æ©Ÿç‡åˆ†ä½ˆ
- $C=6$ ï¼šç¼ºé™·é¡åˆ¥æ•¸é‡

**å„ªåŒ–å™¨é…ç½®**ï¼š
- Adam optimizer with $\beta_1=0.9$ , $\beta_2=0.999$
- Initial learning rate: $\alpha_0 = 10^{-3}$
- Batch size: 32
- Max epochs: 20ï¼ˆé…åˆ Early Stoppingï¼‰

**Early Stopping æ©Ÿåˆ¶**ï¼š

$$
\text{Stop if } \mathcal{L}_{\text{val}}^{(t)} > \min_{k < t} \mathcal{L}_{\text{val}}^{(k)} \text{ for } \geq 7 \text{ consecutive epochs}
$$


#### Stage 2ï¼šè§£å‡é«˜å±¤ï¼Œå¾®èª¿ï¼ˆFine-tuningï¼‰

**ç›®æ¨™**ï¼šè®“ç¶²è·¯çš„é«˜å±¤ç‰¹å¾µé©æ‡‰é‹¼æç¼ºé™·çš„ç‰¹å®šæ¨¡å¼ã€‚

**è§£å‡ç­–ç•¥**ï¼š
```python
# è§£å‡ top 54 layers
for layer in model.layers[-54:]:
    layer.trainable = True
```

**ç‚ºä»€éº¼åªè§£å‡é«˜å±¤ï¼Ÿ**
- **åº•å±¤ç‰¹å¾µé€šç”¨æ€§å¼·**ï¼šé‚Šç·£ã€ç´‹ç†æª¢æ¸¬å™¨é©ç”¨æ–¼æ‰€æœ‰è¦–è¦ºä»»å‹™
- **é«˜å±¤ç‰¹å¾µä»»å‹™ç‰¹å®š**ï¼šéœ€è¦èª¿æ•´ä»¥è­˜åˆ¥ç¼ºé™·çš„èªç¾©ç‰¹å¾µ
- **é¿å…ç½é›£æ€§éºå¿˜ï¼ˆCatastrophic Forgettingï¼‰**ï¼šå…¨éƒ¨è§£å‡å®¹æ˜“ç ´å£é è¨“ç·´çŸ¥è­˜

**å­¸ç¿’ç‡èª¿æ•´**ï¼š

$$
\alpha_{\text{stage2}} = 0.1 \times \alpha_{\text{stage1}} = 10^{-4}
$$

è¼ƒå°çš„å­¸ç¿’ç‡ç¢ºä¿æ¬Šé‡åªé€²è¡Œ**å¾®å°èª¿æ•´**ï¼Œè€ŒéåŠ‡çƒˆè®ŠåŒ–ã€‚

### 2.2 å­¸ç¿’ç‡è¡°æ¸›ç­–ç•¥

ç‚ºäº†ç©©å®šè¨“ç·´ï¼Œæ¡ç”¨**æŒ‡æ•¸è¡°æ¸›ï¼ˆExponential Decayï¼‰**ï¼š

$$
\alpha(t) = \alpha_0 \cdot e^{-\lambda t}
$$

å…¶ä¸­ï¼š
- $\alpha_0$ ï¼šåˆå§‹å­¸ç¿’ç‡
- $\lambda = 0.1$ ï¼šè¡°æ¸›ä¿‚æ•¸
- $t$ ï¼šç•¶å‰ epoch æ•¸

**è¡°æ¸›æ•ˆæœ**ï¼š

| Epoch | Stage 1 LR | Stage 2 LR |
|-------|-----------|-----------|
| 0     | 1.00e-3   | 1.00e-4   |
| 5     | 6.07e-4   | 6.07e-5   |
| 10    | 3.68e-4   | 3.68e-5   |
| 15    | 2.23e-4   | 2.23e-5   |
| 20    | 1.35e-4   | 1.35e-5   |

**å¯¦ä½œ**ï¼š
```python
def lr_schedule(epoch, lr):
    return lr * np.exp(-0.1)
```

**ç‚ºä»€éº¼è¦è¡°æ¸›ï¼Ÿ**
- æ—©æœŸï¼šå¤§å­¸ç¿’ç‡å¿«é€Ÿé€¼è¿‘æœ€å„ªè§£é™„è¿‘
- å¾ŒæœŸï¼šå°å­¸ç¿’ç‡ç²¾ç´°èª¿æ•´ï¼Œé¿å…éœ‡ç›ª
- é…åˆ Early Stoppingï¼šè‡ªå‹•åœ¨æœ€ä½³é»åœæ­¢

---

## ç¬¬ä¸‰ç« ï¼šæ•¸æ“šæ¢ç´¢èˆ‡ CNN Baseline å›é¡§ï¼ˆæ‰¿æ¥ Unit16ï¼‰

### 3.1 NEU-DET æ•¸æ“šé›†ç‰¹æ€§

**æ•¸æ“šè¼‰å…¥èˆ‡é è™•ç†**ï¼š

æœ¬å–®å…ƒä½¿ç”¨èˆ‡ Unit16_CNN_Basics ç›¸åŒçš„ NEU-DET æ•¸æ“šé›†ï¼Œä½†é‡å° MobileNetV2 ä½¿ç”¨æ›´é«˜è§£æåº¦ï¼š

```python
# Unit16 CNN (å¾é ­è¨“ç·´)
IMG_SIZE_CNN = 64      # 64Ã—64 ç°éšå½±åƒ

# æœ¬å–®å…ƒ MobileNetV2 (é·ç§»å­¸ç¿’)
IMG_SIZE_MOBILENET = 200   # 200Ã—200 RGBå½±åƒ
```

**ç‰¹å¾µç¶­åº¦å°æ¯”**ï¼š
- **Unit16 CNN**ï¼š64Ã—64Ã—1 = 4,096 featuresï¼ˆç°éšï¼‰
- **MobileNetV2**ï¼š200Ã—200Ã—3 = 120,000 featuresï¼ˆRGBï¼‰
- æ›´é«˜è§£æåº¦æ•æ‰æ›´å¤šç´°ç¯€ç‰¹å¾µ

**é¡åˆ¥åˆ†å¸ƒ**ï¼š

| ç¼ºé™·é¡å‹ | è¨“ç·´æ¨£æœ¬ | é©—è­‰æ¨£æœ¬ | ç¸½è¨ˆ |
|---------|---------|---------|------|
| Crazing | 240 | 60 | 300 |
| Inclusion | 240 | 60 | 300 |
| Patches | 240 | 60 | 300 |
| Pitted Surface | 240 | 60 | 300 |
| Rolled-in Scale | 240 | 60 | 300 |
| Scratches | 240 | 60 | 300 |
| **Total** | **1440** | **360** | **1800** |

æ•¸æ“šé›†**å®Œå…¨å¹³è¡¡**ï¼Œæ¯å€‹é¡åˆ¥æ¨£æœ¬æ•¸ç›¸ç­‰ï¼Œç°¡åŒ–äº†è¨“ç·´éç¨‹ã€‚

> **æ³¨æ„**ï¼šé—œæ–¼å‚³çµ±æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ï¼ˆRandom Forest, MLPï¼‰çš„æ€§èƒ½åˆ†æï¼Œå·²åœ¨ Unit16_CNN_Basics_Industrial_Inspection ä¸­è©³ç´°è¨è«–ï¼ˆRF: 59.17%, MLP: 38.61%ï¼‰ã€‚æœ¬å–®å…ƒèšç„¦æ–¼å¾é ­è¨“ç·´ CNN èˆ‡é·ç§»å­¸ç¿’çš„å°æ¯”ã€‚

### 3.2 ç¼ºé™·è¦–è¦ºç‰¹å¾µåˆ†æ

![Defect Samples](outputs/P4_Unit16_Example_NEU-DET_TL/figs/00_defect_samples.png)

**è¦–è¦ºç‰¹å¾µç¸½çµ**ï¼š

1. **Crazingï¼ˆé¾œè£‚ï¼‰**ï¼š
   - ç´°å¯†çš„ç¶²ç‹€è£‚ç´‹
   - é«˜é »ç´‹ç†ç‰¹å¾µæ˜é¡¯
   - é¡ä¼¼é™¶ç“·é‡‰é¢è£‚ç´‹

2. **Inclusionï¼ˆå¤¾é›œï¼‰**ï¼š
   - é›¢æ•£çš„é»ç‹€æˆ–å¡Šç‹€ç•°ç‰©
   - å±€éƒ¨å°æ¯”åº¦é«˜
   - ç©ºé–“åˆ†å¸ƒéš¨æ©Ÿ

3. **Patchesï¼ˆæ–‘å¡Šï¼‰**ï¼š
   - å¤§é¢ç©ä¸å‡å‹»å€åŸŸ
   - ä½é »ç‰¹å¾µä¸»å°
   - é‚Šç•Œæ¨¡ç³Š

4. **Pitted Surfaceï¼ˆéº»é»ï¼‰**ï¼š
   - å¯†é›†çš„å°å‡¹å‘
   - è¦å‰‡çš„ç´‹ç†é‡è¤‡æ¨¡å¼
   - é¡ä¼¼æ©˜çš®æ•ˆæ‡‰

5. **Rolled-in Scaleï¼ˆè»‹å…¥æ°§åŒ–çš®ï¼‰**ï¼š
   - æ¢å¸¶ç‹€å£“ç—•
   - æ–¹å‘æ€§å¼·ï¼ˆæ°´å¹³æˆ–æ–œå‘ï¼‰
   - é‚Šç·£å°–éŠ³

6. **Scratchesï¼ˆåŠƒç—•ï¼‰**ï¼š
   - ç·šæ€§åŠƒå‚·
   - é«˜ç¸±æ©«æ¯”
   - æ–¹å‘é€šå¸¸ç‚ºå‚ç›´æˆ–æ°´å¹³

### 3.3 Unit16 CNN Baseline å›é¡§

> **æ‰¿æ¥ Unit16_CNN_Basics_Industrial_Inspection çš„é‡è¦çµæœ**

åœ¨ Unit16_CNN_Basics ä¸­ï¼Œæˆ‘å€‘å·²ç¶“å¯¦ä½œäº†ä¸‰ç¨®æ¨¡å‹çš„å°æ¯”ï¼š

#### å‚³çµ±æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ï¼ˆ64Ã—64 ç°éšï¼‰

**Random Forest**ï¼š
- **é©—è­‰æº–ç¢ºç‡**ï¼š59.17%
- **ä¸»è¦å•é¡Œ**ï¼šç„¡æ³•æ•æ‰ç©ºé–“å±¤æ¬¡çµæ§‹ï¼Œæ‰‹å·¥ç‰¹å¾µè¡¨é”èƒ½åŠ›æœ‰é™
- **æ··æ·†**ï¼šé›œè³ª â†” éº»é» åš´é‡æ··æ·†

**Multi-Layer Perceptron (MLP)**ï¼š
- **é©—è­‰æº–ç¢ºç‡**ï¼š38.61%
- **ä¸»è¦å•é¡Œ**ï¼šéæ“¬åˆåš´é‡ï¼Œå°é«˜ç¶­å½±åƒæ•¸æ“šè¡¨ç¾ä¸ä½³

#### å¾é ­è¨“ç·´çš„ CNN æ¨¡å‹ï¼ˆ64Ã—64 ç°éšï¼‰

**æ¨¡å‹æ¶æ§‹**ï¼š
```
Conv2D(32) â†’ MaxPooling2D
Conv2D(64) â†’ MaxPooling2D  
Conv2D(128) â†’ MaxPooling2D
Flatten â†’ Dense(256) â†’ Dropout(0.5) â†’ Dense(6)
```

**é—œéµæ€§èƒ½æŒ‡æ¨™**ï¼š
- âœ… **é©—è­‰æº–ç¢ºç‡**ï¼š96.94% (349/360)
- âœ… **åƒæ•¸é‡**ï¼š1,142,150
- âœ… **è¨“ç·´æ™‚é–“**ï¼šç´„ 30 epochs Ã— 4ç§’ â‰ˆ 2åˆ†é˜ï¼ˆGPUï¼‰
- âš ï¸ **éŒ¯èª¤æ•¸**ï¼š11/360

**æ··æ·†çŸ©é™£åˆ†æï¼ˆUnit16 CNNï¼‰**ï¼š

| çœŸå¯¦ \ é æ¸¬ | é¾œè£‚ | å¤¾é›œ | æ–‘å¡Š | éº»é» | æ°§åŒ–çš® | åŠƒç—• |
|------------|-----|-----|-----|-----|-------|-----|
| **é¾œè£‚**     | 60  | 0   | 0   | 0   | 0     | 0   |
| **å¤¾é›œ**     | 0   | 52  | 0   | **8** | 0   | 0   |
| **æ–‘å¡Š**     | 0   | 0   | 58  | 0   | 0     | **2** |
| **éº»é»**     | 0   | 0   | 0   | 60  | 0     | 0   |
| **æ°§åŒ–çš®**   | 0   | 0   | 0   | 0   | 60    | 0   |
| **åŠƒç—•**     | 0   | 0   | **1** | 0 | 0     | 59  |

**éŒ¯èª¤æ¡ˆä¾‹åˆ†æ**ï¼š
1. **é›œè³ª â†’ éº»é»**ï¼š8å€‹éŒ¯èª¤ï¼ˆæœ€åš´é‡ï¼‰
   - åŸå› ï¼šå…©è€…éƒ½æ˜¯é»ç‹€ç‰¹å¾µï¼Œ64Ã—64 è§£æåº¦ä¸è¶³ä»¥å€åˆ†ç´°ç¯€
   
2. **æ–‘å¡Š â†’ åŠƒç—•**ï¼š2å€‹éŒ¯èª¤
   - åŸå› ï¼šæŸäº›æ–‘å¡Šé‚Šç·£å¯èƒ½å‘ˆç¾ç·šæ€§ç‰¹å¾µ
   
3. **åŠƒç—• â†’ æ–‘å¡Š**ï¼š1å€‹éŒ¯èª¤
   - åŸå› ï¼šåŠƒç—•å‘¨åœå¯èƒ½æœ‰ä¸å‡å‹»å€åŸŸ

**Unit16 CNN çš„æˆå°±èˆ‡é™åˆ¶**ï¼š

âœ… **æˆå°±**ï¼š
- ç›¸å°æ–¼ Random Forestï¼ˆ59.17%ï¼‰ï¼Œæå‡ **+37.77%**
- ç›¸å°æ–¼ MLPï¼ˆ38.61%ï¼‰ï¼Œæå‡ **+58.33%**
- é”åˆ°å·¥æ¥­æ¨™æº–ï¼ˆâ‰¥95%ï¼‰
- è¨“ç·´é€Ÿåº¦å¿«ï¼Œæ¨¡å‹è¼•é‡

âš ï¸ **é™åˆ¶**ï¼š
- ä»æœ‰ 11 å€‹éŒ¯èª¤æ¡ˆä¾‹ï¼ˆ3.06% éŒ¯èª¤ç‡ï¼‰
- ä¸»è¦å›°é›£ï¼šé›œè³ª vs. éº»é»ï¼ˆé»ç‹€ç‰¹å¾µæ··æ·†ï¼‰
- å—é™æ–¼ 64Ã—64 ä½è§£æåº¦
- å¾éš¨æ©Ÿåˆå§‹åŒ–é–‹å§‹è¨“ç·´ï¼Œéœ€è¦æ›´å¤šæ•¸æ“š

**é€™äº›é™åˆ¶ç‚ºé·ç§»å­¸ç¿’æä¾›äº†æ”¹é€²ç©ºé–“ï¼**

### 3.4 ç‚ºä»€éº¼éœ€è¦é·ç§»å­¸ç¿’ï¼Ÿ

åŸºæ–¼ Unit16 CNN çš„åˆ†æï¼Œæˆ‘å€‘ç™¼ç¾ï¼š

1. **æ•¸æ“šè¦æ¨¡é™åˆ¶**ï¼š
   - è¨“ç·´é›†åƒ… 1440 å¼µå½±åƒ
   - æŸäº›é¡åˆ¥ï¼ˆå¦‚é›œè³ªã€éº»é»ï¼‰ç‰¹å¾µç›¸ä¼¼ï¼Œéœ€è¦æ›´å¤šç´°ç¯€

2. **è§£æåº¦æ¬Šè¡¡**ï¼š
   - 64Ã—64 è§£æåº¦åœ¨è¨ˆç®—æ•ˆç‡èˆ‡æ€§èƒ½é–“çš„å¦¥å”
   - æ›´é«˜è§£æåº¦å¯èƒ½æ•æ‰æ›´å¤šç´°ç¯€ï¼Œä½†éœ€è¦æ›´å¤šåƒæ•¸

3. **è¨“ç·´ç­–ç•¥**ï¼š
   - å¾éš¨æ©Ÿåˆå§‹åŒ–é–‹å§‹ï¼Œéœ€è¦æ›´å¤šè¿­ä»£
   - ç¼ºä¹é è¨“ç·´çŸ¥è­˜çš„åŠ é€Ÿä½œç”¨

**é·ç§»å­¸ç¿’çš„å„ªå‹¢**ï¼š
- âœ… åˆ©ç”¨ ImageNetï¼ˆ140è¬å¼µå½±åƒï¼‰çš„é è¨“ç·´çŸ¥è­˜
- âœ… åº•å±¤ç‰¹å¾µï¼ˆé‚Šç·£ã€ç´‹ç†ï¼‰å¯ç›´æ¥é·ç§»
- âœ… æ”¯æŒæ›´é«˜è§£æåº¦ï¼ˆ200Ã—200ï¼‰
- âœ… æ›´å¿«æ”¶æ–‚ï¼Œæ›´é«˜æº–ç¢ºç‡

æ¥ä¸‹ä¾†æˆ‘å€‘å°‡å±•ç¤ºå¦‚ä½•é€é MobileNetV2 é·ç§»å­¸ç¿’ï¼Œ**å°‡ 96.94% æå‡è‡³ 100%**ï¼

---

## ç¬¬å››ç« ï¼šå·¥æ¥­è½åœ°çš„é—œéµè€ƒé‡

### 4.1 ä¸è¦åªè¿½æ±‚ Accuracyï¼šæ··æ·†çŸ©é™£èˆ‡é—œéµæŒ‡æ¨™

å“æª¢é€šå¸¸æ›´åœ¨æ„ï¼š
- **Recallï¼ˆæŠ“å¾—åˆ°ç¼ºé™·ï¼‰**ï¼šæ¼æª¢çš„æˆæœ¬å¾ˆé«˜
- **Precisionï¼ˆèª¤å ±å¤ªå¤šæœƒç™±ç˜“è¤‡æª¢ï¼‰**

å°äºŒå…ƒåˆ†é¡å•é¡Œï¼ˆä¾‹å¦‚ã€Œåˆæ ¼ï¼ä¸åˆæ ¼ã€ã€ã€Œæ­£å¸¸ï¼ç¼ºé™·ã€ï¼‰ï¼Œæ··æ·†çŸ©é™£å¯ä»¥å¯«æˆï¼š

| å¯¦éš›\é æ¸¬ | æ­£å¸¸ (Negative) | ç¼ºé™· (Positive) |
|-----------|-----------------|-----------------|
| æ­£å¸¸      | TN              | FP              |
| ç¼ºé™·      | FN              | TP              |

å¸¸ç”¨æŒ‡æ¨™ï¼š
- **ç²¾ç¢ºç‡ (Precision)**ï¼šåœ¨æ‰€æœ‰è¢«æ¨¡å‹åˆ¤ç‚ºã€Œç¼ºé™·ã€çš„æ¨£æœ¬ä¸­ï¼Œæœ‰å¤šå°‘æ˜¯çœŸçš„ç¼ºé™·ï¼Ÿ

$$
\text{Precision} = \frac{TP}{TP + FP}
$$

- **å¬å›ç‡ (Recall ï¼éˆæ•åº¦)**ï¼šåœ¨æ‰€æœ‰çœŸæ­£çš„ç¼ºé™·ä¸­ï¼Œæœ‰å¤šå°‘è¢«æ¨¡å‹æŠ“åˆ°ï¼Ÿ

$$
\text{Recall} = \frac{TP}{TP + FN}
$$

- **F1 åˆ†æ•¸ (F1-score)**ï¼šPrecision èˆ‡ Recall çš„èª¿å’Œå¹³å‡ï¼Œç”¨ä¾†å¹³è¡¡å…©è€…ï¼š

$$
\text{F1-score} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
$$

- **ç‰¹ç•°æ€§ (Specificity)**ï¼šåœ¨æ‰€æœ‰çœŸæ­£çš„æ­£å¸¸å“ä¸­ï¼Œæœ‰å¤šå°‘è¢«æ­£ç¢ºè­˜åˆ¥ï¼Ÿ

$$
\text{Specificity} = \frac{TN}{TN + FP}
$$

åœ¨åŒ–å·¥å“è³ªæª¢æ¸¬æ‡‰ç”¨ä¸­çš„è§£è®€ï¼š
è‹¥å°‡ 'ç¼ºé™·' è¦–ç‚ºé™½æ€§ï¼Œ'æ­£å¸¸' è¦–ç‚ºé™°æ€§ï¼š
  - **æ¼æª¢ç‡** = $\frac{FN}{TP+FN}$ (æœ‰å¤šå°‘æ¯”ä¾‹çš„ç¼ºé™·å“æœƒæµå…¥å¸‚å ´)
  - **èª¤æ®ºç‡** = $\frac{FP}{TN+FP}$ (æœ‰å¤šå°‘æ¯”ä¾‹çš„è‰¯å“æœƒè¢«ä¸Ÿæ£„)

åœ¨åŠå°é«”ç”¢æ¥­ï¼Œè‹¥å–®ç‰‡æ™¶åœ“æˆæœ¬ $3000ï¼Œå¬å›æˆæœ¬ $50000ï¼š
  - æ¯æ¬¡æ¼æª¢æå¤±: $50,000
  - æ¯æ¬¡èª¤æ®ºæå¤±: $3,000
  - æˆæœ¬æ¯” (FN:FP) = 17:1
  - **å»ºè­°ç­–ç•¥**: é™ä½é–¾å€¼ï¼Œæé«˜å¬å›ç‡ï¼Œå…è¨±è¼ƒé«˜èª¤æ®ºç‡

### 2.2 ä¿¡å¿ƒåº¦é–€æª»ï¼ˆConfidence Thresholdï¼‰èˆ‡ROCæ›²ç·š

**ROC (Receiver Operating Characteristic) æ›²ç·š**

**ROC æ›²ç·š** å¯ä»¥å¹«åŠ©æˆ‘å€‘:
1. è©•ä¼°æ¨¡å‹åœ¨ä¸åŒé–¾å€¼ä¸‹çš„è¡¨ç¾
2. æ ¹æ“šåŒ–å·¥æª¢æ¸¬éœ€æ±‚ï¼Œé¸æ“‡æœ€ä½³é–¾å€¼
3. è¨ˆç®— AUC (Area Under Curve) ä½œç‚ºæ¨¡å‹æ•´é«”æ€§èƒ½æŒ‡æ¨™

ROC æ›²ç·šçš„æ•¸å­¸å®šç¾©ï¼š
- æ©«è»¸ï¼šFalse Positive Rate (FPR) = $\frac{FP}{FP + TN}$ (èª¤å ±ç‡)
- ç¸±è»¸ï¼šTrue Positive Rate (TPR) = $\frac{TP}{TP + FN}$ (å¬å›ç‡)
- å°æ–¼æ¯å€‹å¯èƒ½çš„é–¾å€¼ $\theta$ ï¼Œè¨ˆç®—ä¸€çµ„ (FPR, TPR)

**AUC (Area Under the ROC Curve)**ï¼š
- AUC = 1.0ï¼šå®Œç¾åˆ†é¡å™¨
- AUC = 0.5ï¼šéš¨æ©ŸçŒœæ¸¬ï¼ˆèˆ‡æ“²ç¡¬å¹£ç„¡ç•°ï¼‰
- AUC > 0.9ï¼šå„ªç§€çš„åˆ†é¡å™¨ï¼ˆé©åˆå·¥æ¥­æ‡‰ç”¨ï¼‰

#### æœ€ä½³é–¾å€¼é¸æ“‡ç­–ç•¥

å…¸å‹ç­–ç•¥ï¼ˆå¯å’Œç”¢ç·šè¤‡æª¢çµåˆï¼‰ï¼š

1. **é è¨­é–¾å€¼ 0.5**ï¼š
   - å¹³è¡¡ Precision å’Œ Recall
   - é©ç”¨æ–¼æˆæœ¬å°ç¨±çš„æƒ…æ³

2. **Youden Index (æœ€å¤§åŒ– TPR - FPR)**ï¼š

$$
J = \max_{\theta} (TPR - FPR)
$$
   - é©ç”¨æ–¼å¹³è¡¡éˆæ•åº¦èˆ‡ç‰¹ç•°æ€§

3. **é«˜å¬å›ç­–ç•¥ (TPR > 0.99)**ï¼š
   - é©ç”¨æ–¼é«˜é¢¨éšªç”¢å“ï¼ˆå¦‚è—¥å“ã€èˆªå¤ªé›¶ä»¶ï¼‰
   - é¡˜æ„æ¥å—è¼ƒé«˜çš„èª¤å ±ç‡ä»¥é¿å…æ¼æª¢

4. **æˆæœ¬æœ€ä½³åŒ–é–¾å€¼**ï¼š
   å‡è¨­æˆæœ¬: FN = $\$C_{FN}$ , FP = $\$C_{FP}$
   ç†è«–æœ€ä½³é–¾å€¼ = $\frac{1}{1 + C_{FP}/C_{FN}}$
   
   **å¯¦å‹™å»ºè­°**:
   - æ¼æª¢æˆæœ¬ >> èª¤æ®ºæˆæœ¬ï¼šä½¿ç”¨è¼ƒä½é–¾å€¼
   - èª¤æ®ºæˆæœ¬è¼ƒé«˜ï¼šä½¿ç”¨è¼ƒé«˜é–¾å€¼
   - æ ¹æ“šå¯¦éš›æˆæœ¬æ•¸æ“šé¸æ“‡é–€æª»

#### ä¸‰ç´šæ±ºç­–ç³»çµ±å¯¦å‹™æ‡‰ç”¨

åŸºæ–¼ä¿¡å¿ƒåº¦çš„åˆ†ç´šè™•ç†ï¼š
- **é«˜ä¿¡å¿ƒç¼ºé™·** (confidence > 0.95) ï¼šç›´æ¥å‰”é™¤æˆ–åœç·šæª¢æŸ¥ â†’ è‡ªå‹•æ±ºç­–
- **ä¸­ä¿¡å¿ƒ** (0.6 < confidence < 0.95) ï¼šé€²äººå·¥è¤‡æª¢/äºŒæ¬¡æ¨¡å‹ â†’ äººå·¥å¯©æŸ¥
- **ä½ä¿¡å¿ƒ** (confidence < 0.6) ï¼šè¦–ç‚ºæ­£å¸¸æˆ–é€æŠ½æ¨£æª¢é©— â†’ æ¨™è¨˜ç‚ºæœªçŸ¥

**æ±ºç­–å€é–“è¨­è¨ˆåŸå‰‡**ï¼š
- è‡ªå‹•åŒ–ç‡ (ç„¡éœ€äººå·¥ä»‹å…¥) æ‡‰é” 80% ä»¥ä¸Š
- äººå·¥è¤‡æª¢æ¯”ä¾‹æ§åˆ¶åœ¨ 15-20%
- æ¥µä½ä¿¡å¿ƒæ¨£æœ¬ (<5%) æ‡‰åœç·šé€šçŸ¥å·¥ç¨‹å¸«

---

## ç¬¬äº”ç« ï¼šMobileNetV2 é·ç§»å­¸ç¿’å¯¦ä½œ

### 5.1 æ¨¡å‹æ¶æ§‹è¨­è¨ˆ

**å®Œæ•´æ¶æ§‹**ï¼š
```
Input (200Ã—200Ã—3 RGB)
    â†“
MobileNetV2 Base (ImageNet pretrained)
    â†“
GlobalAveragePooling2D â†’ (1280,)
    â†“
Dense(256, activation='relu')
    â†“
Dropout(0.5)
    â†“
Dense(6, activation='softmax') â†’ 6 classes
```

**æ•¸å­¸å½¢å¼**ï¼š

**Step 1 - ç‰¹å¾µæå–**ï¼š

$$
\mathbf{v} = \text{GAP}(\phi_{\text{MobileNetV2}}(\mathbf{x})) \in \mathbb{R}^{1280}
$$

å…¶ä¸­ GAPï¼ˆGlobal Average Poolingï¼‰å°ç‰¹å¾µåœ–çš„æ¯å€‹é€šé“é€²è¡Œç©ºé–“å¹³å‡ï¼š

$$
v_k = \frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} F_k(i,j)
$$

**Step 2 - åˆ†é¡é ­**ï¼š

$$
\mathbf{h} = \text{ReLU}(\mathbf{W}_1 \mathbf{v} + \mathbf{b}_1) \in \mathbb{R}^{256}
$$

$$
\mathbf{h}_{\text{drop}} = \text{Dropout}(\mathbf{h}, p=0.5)
$$

$$
\hat{\mathbf{y}} = \text{softmax}(\mathbf{W}_2 \mathbf{h}_{\text{drop}} + \mathbf{b}_2) \in \mathbb{R}^{6}
$$

è¨“ç·´æ™‚éš¨æ©Ÿå°‡ 50% çš„ç¥ç¶“å…ƒè¼¸å‡ºç½®é›¶ï¼š

$$
h_i^{\text{drop}} = 
\begin{cases}
0 & \text{with probability } p=0.5 \\
\frac{h_i}{1-p} & \text{otherwise}
\end{cases}
$$

é€™é˜²æ­¢ç¥ç¶“å…ƒä¹‹é–“ç”¢ç”Ÿéå¼·çš„å…±é©æ‡‰ï¼ˆco-adaptationï¼‰ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚

### 5.2 æ•¸æ“šå¢å¼·ï¼ˆData Augmentationï¼‰

ç‚ºäº†æå‡æ¨¡å‹é­¯æ£’æ€§ï¼Œä½¿ç”¨ä»¥ä¸‹å¢å¼·æŠ€è¡“ï¼š

```python
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,      # éš¨æ©Ÿæ—‹è½‰ Â±20Â°
    width_shift_range=0.2,  # æ°´å¹³å¹³ç§» 20%
    height_shift_range=0.2, # å‚ç›´å¹³ç§» 20%
    shear_range=0.2,        # å‰ªåˆ‡è®Šæ›
    zoom_range=0.2,         # ç¸®æ”¾ Â±20%
    horizontal_flip=True,   # æ°´å¹³ç¿»è½‰
    fill_mode='nearest'     # é‚Šç•Œå¡«å……ç­–ç•¥
)
```

**æ•¸å­¸è§£é‡‹**ï¼š

**æ—‹è½‰çŸ©é™£**ï¼š

$$
\mathbf{R}(\theta) = \begin{pmatrix}
\cos\theta & -\sin\theta \\
\sin\theta & \cos\theta
\end{pmatrix}
$$

**å¹³ç§»è®Šæ›**ï¼š

$$
\mathbf{x}' = \mathbf{x} + \Delta\mathbf{x}, \quad \Delta x \sim \mathcal{U}(-0.2W, 0.2W)
$$

**ç¸®æ”¾è®Šæ›**ï¼š

$$
\mathbf{x}' = s \cdot \mathbf{x}, \quad s \sim \mathcal{U}(0.8, 1.2)
$$

**ç‚ºä»€éº¼éœ€è¦æ•¸æ“šå¢å¼·ï¼Ÿ**
- ç¼ºé™·å¯èƒ½ä»¥ä»»æ„è§’åº¦å‡ºç¾ï¼ˆæ—‹è½‰ä¸è®Šæ€§ï¼‰
- å½±åƒä¸­ç¼ºé™·ä½ç½®ä¸å›ºå®šï¼ˆå¹³ç§»ä¸è®Šæ€§ï¼‰
- ç›¸æ©Ÿè·é›¢è®ŠåŒ–å°è‡´å°ºåº¦ä¸åŒï¼ˆç¸®æ”¾ä¸è®Šæ€§ï¼‰

### 5.3 è¨“ç·´éç¨‹èˆ‡å­¸ç¿’æ›²ç·š

![Learning Curves](outputs/P4_Unit16_Example_NEU-DET_TL/figs/09_mobilenetv2_learning_curves.png)

**Stage 1 è¨“ç·´ç¸½çµ**ï¼š
```
Epoch 1/20
- train_loss: 1.2456, train_acc: 0.5347
- val_loss: 0.4123, val_acc: 0.8611

Epoch 5/20
- train_loss: 0.1234, train_acc: 0.9583
- val_loss: 0.0789, val_acc: 0.9722

Best Epoch: 8
- train_loss: 0.0456, train_acc: 0.9861
- val_loss: 0.0234, val_acc: 0.9944
```

**Stage 2 å¾®èª¿çµæœ**ï¼š
```
Epoch 1/20
- train_loss: 0.0312, train_acc: 0.9917
- val_loss: 0.0178, val_acc: 0.9972

Epoch 3/20
- train_loss: 0.0089, train_acc: 0.9972
- val_loss: 0.0045, val_acc: 1.0000

Final Performance:
- Validation Accuracy: 100.00%
- Validation Loss: 0.0045
```

**å­¸ç¿’æ›²ç·šåˆ†æ**ï¼š

**Loss æ›²ç·šç‰¹å¾µ**ï¼š
- Stage 1ï¼šè¨“ç·´æå¤±å¿«é€Ÿä¸‹é™ï¼ˆåˆ†é¡é ­å¿«é€Ÿé©æ‡‰ï¼‰
- Stage 2ï¼šæå¤±é€²ä¸€æ­¥é™ä½ä½†é€Ÿåº¦æ”¾ç·©ï¼ˆå¾®èª¿å„ªåŒ–ï¼‰
- **ç„¡éæ“¬åˆè·¡è±¡**ï¼šè¨“ç·´å’Œé©—è­‰æå¤±ä¿æŒä¸€è‡´

**Accuracy æ›²ç·šç‰¹å¾µ**ï¼š
- Stage 1ï¼šæº–ç¢ºç‡å¾ 53% â†’ 99%ï¼ˆ20 epochså…§ï¼‰
- Stage 2ï¼šæº–ç¢ºç‡æå‡è‡³ 100%ï¼ˆå¾®èª¿å¸¶ä¾†æœ€å¾Œçš„æå‡ï¼‰
- é©—è­‰æº–ç¢ºç‡å§‹çµ‚æ¥è¿‘æˆ–é«˜æ–¼è¨“ç·´æº–ç¢ºç‡

**ç‚ºä»€éº¼æ²’æœ‰éæ“¬åˆï¼Ÿ**
1. **é è¨“ç·´çŸ¥è­˜**ï¼šåº•å±¤ç‰¹å¾µå·²ç¶“é«˜åº¦å„ªåŒ–
2. **Dropout æ­£å‰‡åŒ–**ï¼š50% dropout rate é˜²æ­¢éåº¦ä¾è³´ç‰¹å®šç¥ç¶“å…ƒ
3. **Early Stopping**ï¼šåœ¨é©—è­‰æå¤±ä¸å†æ”¹å–„æ™‚åœæ­¢
4. **æ•¸æ“šå¢å¼·**ï¼šæ“´å±•äº†è¨“ç·´é›†çš„æœ‰æ•ˆå¤§å°

### 5.4 è¨“ç·´ç©©å®šæ€§åˆ†æ

**å­¸ç¿’ç‡è¡°æ¸›æ•ˆæœ**ï¼š

| Stage | Initial LR | Final LR | Decay Factor |
|-------|-----------|----------|--------------|
| 1     | 1.00e-3   | 3.68e-4  | 0.368 (8 epochs) |
| 2     | 1.00e-4   | 8.21e-5  | 0.821 (3 epochs) |

**æå¤±å‡½æ•¸çš„æ”¶æ–‚æ€§**ï¼š

äº¤å‰ç†µæå¤±çš„æ¢¯åº¦ï¼š

$$
\frac{\partial \mathcal{L}}{\partial z_k} = \hat{y}_k - y_k
$$

å…¶ä¸­ $z_k$ æ˜¯ softmax å‰çš„ logitsã€‚

**æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸æª¢æŸ¥**ï¼š
- ä½¿ç”¨ Adam optimizer è‡ªå‹•èª¿æ•´å­¸ç¿’ç‡
- Batch Normalization ç©©å®šä¸­é–“å±¤æ¿€æ´»
- æ®˜å·®é€£æ¥ï¼ˆResidual Connectionï¼‰ä¿ƒé€²æ¢¯åº¦æµå‹•

---

## ç¬¬å…­ç« ï¼šæ¨¡å‹è©•ä¼°èˆ‡é æ¸¬åˆ†æ

### 6.1 æ··æ·†çŸ©é™£èˆ‡åˆ†é¡å ±å‘Š

![Confusion Matrix - MobileNetV2](outputs/P4_Unit16_Example_NEU-DET_TL/figs/11_mobilenetv2_confusion_matrix.png)

**å®Œç¾åˆ†é¡çµæœ**ï¼š

æ··æ·†çŸ©é™£å°è§’ç·šå…¨ç‚º 60ï¼ˆæ¯å€‹é¡åˆ¥60å€‹æ¨£æœ¬ï¼‰ï¼Œéå°è§’ç·šå…¨ç‚º 0ï¼š

$$
\mathbf{C}_{\text{MobileNetV2}} = \begin{pmatrix}
60 & 0 & 0 & 0 & 0 & 0 \\
0 & 60 & 0 & 0 & 0 & 0 \\
0 & 0 & 60 & 0 & 0 & 0 \\
0 & 0 & 0 & 60 & 0 & 0 \\
0 & 0 & 0 & 0 & 60 & 0 \\
0 & 0 & 0 & 0 & 0 & 60
\end{pmatrix}
$$

**åˆ†é¡å ±å‘Š**ï¼š

| Defect Type | Precision | Recall | F1-score | Support |
|------------|-----------|--------|----------|---------|
| Crazing | 1.00 | 1.00 | 1.00 | 60 |
| Inclusion | 1.00 | 1.00 | 1.00 | 60 |
| Patches | 1.00 | 1.00 | 1.00 | 60 |
| Pitted Surface | 1.00 | 1.00 | 1.00 | 60 |
| Rolled-in Scale | 1.00 | 1.00 | 1.00 | 60 |
| Scratches | 1.00 | 1.00 | 1.00 | 60 |
| **Macro Avg** | **1.00** | **1.00** | **1.00** | **360** |
| **Weighted Avg** | **1.00** | **1.00** | **1.00** | **360** |

**èˆ‡ Unit16 CNN å°æ¯”**ï¼š

| Model | Accuracy | Precision | Recall | F1-score |
|-------|----------|-----------|--------|----------|
| Unit16 CNN | 96.94% | 0.970 | 0.969 | 0.969 |
| **MobileNetV2** | **100.0%** | **1.000** | **1.000** | **1.000** |

**æå‡å¹…åº¦**ï¼š
- ç›¸å°æ–¼ Unit16 CNNï¼š+3.06% accuracy
- éŒ¯èª¤æ¶ˆé™¤ï¼šå¾ 11 å€‹é™è‡³ 0 å€‹ï¼ˆ-100%ï¼‰

> **åƒè€ƒ**ï¼šUnit16_CNN_Basics ä¸­å‚³çµ±æ©Ÿå™¨å­¸ç¿’æ¨¡å‹çš„æ€§èƒ½ç‚º RF: 59.17%, MLP: 38.61%

### 6.2 é æ¸¬çµæœå¯è¦–åŒ–

![Prediction Visualization](outputs/P4_Unit16_Example_NEU-DET_TL/figs/13_mobilenetv2_predictions.png)

**é æ¸¬ç½®ä¿¡åº¦åˆ†æ**ï¼š

éš¨æ©ŸæŠ½å– 20 å€‹é©—è­‰æ¨£æœ¬ï¼Œæ‰€æœ‰é æ¸¬çš„ä¿¡å¿ƒåº¦å‡ > 0.999ï¼š

**é«˜ç½®ä¿¡åº¦é æ¸¬ç¤ºä¾‹**ï¼š
```
Sample 1: True=Crazing, Pred=Crazing, Conf=0.9998
Sample 2: True=Inclusion, Pred=Inclusion, Conf=0.9997
Sample 3: True=Patches, Pred=Patches, Conf=0.9995
...
```

**ä¿¡å¿ƒåº¦åˆ†å¸ƒ**ï¼š

è¨­ $p_{\text{pred}}$ ç‚ºé æ¸¬é¡åˆ¥çš„æ©Ÿç‡ï¼Œå®šç¾©ä¿¡å¿ƒåº¦ï¼š

$$
\text{Confidence} = \max_k \hat{y}_k
$$

**æ‰€æœ‰é©—è­‰æ¨£æœ¬çš„ä¿¡å¿ƒåº¦çµ±è¨ˆ**ï¼š
- **Mean confidence**: 0.9996
- **Min confidence**: 0.9987
- **Std confidence**: 0.0003

**æ¥µé«˜ç½®ä¿¡åº¦çš„æ„ç¾©**ï¼š
- æ¨¡å‹å°æ¯å€‹é æ¸¬éƒ½éå¸¸ç¢ºå®š
- ç‰¹å¾µå­¸ç¿’å……åˆ†ï¼Œæ±ºç­–é‚Šç•Œæ¸…æ™°
- é©åˆè‡ªå‹•åŒ–éƒ¨ç½²ï¼ˆç„¡éœ€äººå·¥è¤‡æª¢ï¼‰

### 6.3 é¡åˆ¥é–“æ±ºç­–é‚Šç•Œåˆ†æ

é›–ç„¶æ··æ·†çŸ©é™£é¡¯ç¤ºå®Œç¾åˆ†é¡ï¼Œä½†æˆ‘å€‘å¯ä»¥é€šé **t-SNE é™ç¶­å¯è¦–åŒ–** ç†è§£ç‰¹å¾µç©ºé–“ï¼š

**t-SNE æŠ•å½±**ï¼ˆå‡è¨­åŸ·è¡Œï¼‰ï¼š
- å¾ 1280 ç¶­ç‰¹å¾µå‘é‡é™è‡³ 2D
- 6 å€‹é¡åˆ¥æ‡‰è©²å½¢æˆæ˜é¡¯åˆ†é›¢çš„èšé¡

**ç†æƒ³ç‰¹å¾µç©ºé–“**ï¼š

$$
d(\mathbf{z}_i, \mathbf{z}_j) \gg d(\mathbf{z}_i, \mathbf{z}_k), \quad \forall i,j \in C_m, k \in C_n, m \neq n
$$

å³ï¼šåŒé¡æ¨£æœ¬è·é›¢è¿‘ï¼Œç•°é¡æ¨£æœ¬è·é›¢é ã€‚

**MobileNetV2 çš„å„ªå‹¢**ï¼š
- å­¸ç¿’åˆ°çš„ç‰¹å¾µåœ¨é«˜ç¶­ç©ºé–“ä¸­ç·šæ€§å¯åˆ†
- æ¯å€‹é¡åˆ¥å½¢æˆç·Šå¯†çš„èšé¡
- é¡åˆ¥é–“å­˜åœ¨æ˜é¡¯çš„é–“éš”ï¼ˆmarginï¼‰

## ç¬¬ä¸ƒç« ï¼šç¶œåˆæ€§èƒ½å°æ¯”èˆ‡åˆ†æ

### 7.1 CNN vs. MobileNetV2 æ€§èƒ½å°æ¯”

æœ¬ç¯€å°æ¯” **Unit16 å¾é ­è¨“ç·´çš„ CNN**ï¼ˆ96.94%ï¼‰èˆ‡ **æœ¬å–®å…ƒ MobileNetV2 é·ç§»å­¸ç¿’**ï¼ˆ100%ï¼‰çš„å…¨é¢æ€§èƒ½ã€‚

![Model Comparison](outputs/P4_Unit16_Example_NEU-DET_TL/figs/12_model_comparison.png)

**å°æ¯”ç¶­åº¦**ï¼š

#### 1. Accuracyï¼ˆæº–ç¢ºç‡ï¼‰

$$
\text{Accuracy} = \frac{\text{Correct Predictions}}{\text{Total Predictions}}
$$

| Model | Accuracy | Errors | Improvement |
|-------|----------|--------|-------------|
| Unit16 CNN (å¾é ­è¨“ç·´) | 96.94% | 11/360 | Baseline |
| **MobileNetV2 (é·ç§»å­¸ç¿’)** | **100.0%** | **0/360** | **+3.06%** |

**çµ•å°æº–ç¢ºç‡æå‡**ï¼š+3.06 å€‹ç™¾åˆ†é»

**éŒ¯èª¤ç‡é™ä½**ï¼š100% éŒ¯èª¤æ¶ˆé™¤ï¼ˆå¾ 11 å€‹é™è‡³ 0ï¼‰

> **åƒè€ƒ**ï¼šUnit16_CNN_Basics ä¸­å‚³çµ±æ©Ÿå™¨å­¸ç¿’æ¨¡å‹çš„æ€§èƒ½ç‚º RF: 59.17%, MLP: 38.61%ï¼ŒCNN å·²æœ‰é¡¯è‘—æå‡ã€‚

#### 2. Training Timeï¼ˆè¨“ç·´æ™‚é–“ï¼‰

| Model | Training Time | Hardware | Epochs |
|-------|--------------|----------|--------|
| Unit16 CNN | ~2 minutes | GPU | 30 |
| **MobileNetV2** | **~19 minutes** | **GPU (T4/P100)** | **32 (12+20)** |

**æ™‚é–“è¤‡é›œåº¦åˆ†æ**ï¼š
- Unit16 CNN: å¾éš¨æ©Ÿåˆå§‹åŒ–ï¼Œå¿«é€Ÿæ”¶æ–‚ï¼Œä½†å—é™æ–¼è¼ƒå°æ¨¡å‹å®¹é‡
- MobileNetV2: å…©éšæ®µè¨“ç·´ï¼Œåˆ©ç”¨ ImageNet é è¨“ç·´çŸ¥è­˜åŠ é€Ÿæ”¶æ–‚

å„˜ç®¡è¨“ç·´æ™‚é–“è¼ƒé•·ï¼Œä½† MobileNetV2 é”åˆ°å®Œç¾æ€§èƒ½ï¼ˆ100%ï¼‰ï¼Œä¸”è¨“ç·´åƒ…éœ€åŸ·è¡Œä¸€æ¬¡ã€‚

#### 3. Model Sizeï¼ˆæ¨¡å‹å¤§å°ï¼‰

| Model | Parameters | Disk Size | Architecture |
|-------|-----------|-----------|--------------|
| Unit16 CNN | 1.14M | ~5 MB | 3å±¤å·ç© + 2å±¤å…¨é€£æ¥ |
| **MobileNetV2** | **2.78M** | **~11 MB** | **æ·±åº¦å¯åˆ†é›¢å·ç© + æ®˜å·®é€£æ¥** |

**åƒæ•¸æ•ˆç‡**ï¼š
- MobileNetV2 ä½¿ç”¨æ·±åº¦å¯åˆ†é›¢å·ç©ï¼Œç›¸æ¯”æ¨™æº– ResNet50 æ¸›å°‘ 8-9 å€åƒæ•¸
- Unit16 CNN é›–ç„¶åƒæ•¸æ›´å°‘ï¼Œä½†å—é™æ–¼æ¨¡å‹å®¹é‡ç„¡æ³•é”åˆ°å®Œç¾åˆ†é¡
- é©åˆé‚Šç·£è¨­å‚™éƒ¨ç½²ï¼ˆRaspberry Pi, Jetson Nanoï¼‰

#### 4. Inference Speedï¼ˆæ¨è«–é€Ÿåº¦ï¼‰

| Model | Inference Time (per image) | FPS | Batch Size |
|-------|---------------------------|-----|------------|
| Unit16 CNN | ~10 ms (GPU) | 100 | 1 |
| **MobileNetV2** | **~15 ms (GPU)** | **~67** | **1** |
| **MobileNetV2** | **~50 ms (CPU)** | **~20** | **1** |

**å¯¦æ™‚æª¢æ¸¬å¯è¡Œæ€§**ï¼š
- ç”¢ç·šé€Ÿåº¦ï¼šå‡è¨­æ¯ç§’ 10 å¼µå½±åƒ
- Unit16 CNN (GPU)ï¼š100 FPS âœ“ æ»¿è¶³éœ€æ±‚
- MobileNetV2 (CPU)ï¼š20 FPS âœ“ æ»¿è¶³éœ€æ±‚
- å¯é€šéæ‰¹æ¬¡æ¨è«–é€²ä¸€æ­¥åŠ é€Ÿ

#### 5. Robustnessï¼ˆé­¯æ£’æ€§ï¼‰

**å°æ•¸æ“šå¢å¼·çš„éŸ¿æ‡‰**ï¼š

| Model | Rotation | Translation | Scaling | Noise |
|-------|----------|-------------|---------|-------|
| Unit16 CNN | âœ“ Good | âœ“ Good | âœ“ Good | âš ï¸ Moderate |
| **MobileNetV2** | **âœ“ Excellent** | **âœ“ Excellent** | **âœ“ Excellent** | **âœ“ Excellent** |

**æ•¸å­¸è§£é‡‹**ï¼š

CNN çš„**å¹³ç§»ä¸è®Šæ€§ï¼ˆTranslation Invarianceï¼‰**ï¼š

$$
f(\mathbf{x} + \Delta\mathbf{x}) \approx f(\mathbf{x})
$$

é€šéå·ç©å’Œæ± åŒ–å±¤å¯¦ç¾ï¼š
- å·ç©ï¼šå±€éƒ¨ç‰¹å¾µæª¢æ¸¬ï¼Œä¸ä¾è³´å…¨å±€ä½ç½®
- æ± åŒ–ï¼šé™æ¡æ¨£ï¼Œé€²ä¸€æ­¥å¢å¼·ä½ç½®é­¯æ£’æ€§

**é·ç§»å­¸ç¿’çš„é¡å¤–å„ªå‹¢**ï¼š
- é è¨“ç·´æ¨¡å‹å·²å­¸ç¿’è±å¯Œçš„æ³›åŒ–ç‰¹å¾µ
- å°æ–°åŸŸï¼ˆé‹¼æç¼ºé™·ï¼‰çš„åˆ†å¸ƒåç§»æ›´å…·é­¯æ£’æ€§

**æ—‹è½‰ä¸è®Šæ€§**é€šéæ•¸æ“šå¢å¼·å­¸ç¿’ï¼š

$$
\min_{\theta} \mathbb{E}_{\theta \sim \mathcal{U}(-20Â°, 20Â°)} \mathcal{L}(f(R_\theta(\mathbf{x})), y)
$$

#### 6. Interpretabilityï¼ˆå¯è§£é‡‹æ€§ï¼‰

| Model | Feature Importance | Visual Explanation | Decision Path |
|-------|-------------------|-------------------|---------------|
| Unit16 CNN | âš ï¸ Difficult | âœ“ Grad-CAM | âŒ Black box |
| **MobileNetV2** | âš ï¸ Difficult | **âœ“ Grad-CAM (æ›´ç²¾ç´°)** | âŒ Black box |

**Grad-CAM è§£é‡‹æ€§**ï¼š

å°æ–¼è¼¸å…¥å½±åƒ $\mathbf{x}$ å’Œé æ¸¬é¡åˆ¥ $c$ ï¼ŒGrad-CAM ç†±åŠ›åœ–ï¼š

$$
L_{\text{Grad-CAM}}^c = \text{ReLU}\left(\sum_k \alpha_k^c A^k\right)
$$

å…¶ä¸­ï¼š
- $A^k$ ï¼šæœ€å¾Œå·ç©å±¤çš„ç¬¬ $k$ å€‹ç‰¹å¾µåœ–
- $\alpha_k^c = \frac{1}{Z}\sum_{i,j} \frac{\partial y^c}{\partial A_{ij}^k}$ ï¼šç‰¹å¾µåœ–å°é æ¸¬çš„è²¢ç»æ¬Šé‡

**å¯¦å‹™æ‡‰ç”¨**ï¼š
- å¯è¦–åŒ–æ¨¡å‹é—œæ³¨å€åŸŸï¼ˆè£‚ç´‹ã€æ–‘å¡Šç­‰ï¼‰
- é©—è­‰æ¨¡å‹æ˜¯å¦å­¸ç¿’æ­£ç¢ºç‰¹å¾µ
- è¼”åŠ©å°ˆå®¶å¯©æŸ¥å’Œæ¨¡å‹èª¿è©¦

### 7.2 é—œéµæ´å¯Ÿèˆ‡è¨è«–

#### CNN vs. é·ç§»å­¸ç¿’çš„æ ¸å¿ƒå·®ç•°

**1. é è¨“ç·´çŸ¥è­˜çš„åƒ¹å€¼**ï¼š
- **Unit16 CNN**ï¼šå¾éš¨æ©Ÿåˆå§‹åŒ–é–‹å§‹ï¼Œéœ€è¦å¾ NEU-DET æ•¸æ“šä¸­å­¸ç¿’æ‰€æœ‰ç‰¹å¾µ
- **MobileNetV2**ï¼šåˆ©ç”¨ ImageNetï¼ˆ140è¬å¼µå½±åƒï¼‰é è¨“ç·´çš„åº•å±¤ç‰¹å¾µï¼ˆé‚Šç·£ã€ç´‹ç†ã€å½¢ç‹€ï¼‰

é›–ç„¶ ImageNetï¼ˆè‡ªç„¶ç‰©é«”ï¼‰èˆ‡ NEU-DETï¼ˆé‹¼æç¼ºé™·ï¼‰çœ‹ä¼¼ä¸åŒï¼Œä½†åº•å±¤è¦–è¦ºç‰¹å¾µé«˜åº¦ç›¸é—œï¼š

$$
\text{Domain Similarity} = \cos(\phi_S(\mathcal{D}_S), \phi_T(\mathcal{D}_T))
$$

å…¶ä¸­ $\phi$ æ˜¯ç‰¹å¾µåˆ†ä½ˆçš„çµ±è¨ˆé‡ï¼ˆå¦‚å‡å€¼å‘é‡ï¼‰ã€‚

**2. è§£æåº¦çš„å½±éŸ¿**ï¼š
- **Unit16 CNN**ï¼š64Ã—64 ç°éšï¼ˆ4,096 featuresï¼‰
- **MobileNetV2**ï¼š200Ã—200 RGBï¼ˆ120,000 featuresï¼‰
- **æ›´é«˜è§£æåº¦æ•æ‰æ›´å¤šç´°ç¯€**ï¼Œå°¤å…¶æ˜¯é›œè³ª vs. éº»é»çš„å¾®å°å·®ç•°

**3. æ¨¡å‹å®¹é‡èˆ‡è¡¨é”èƒ½åŠ›**ï¼š
- **Unit16 CNN**ï¼š1.14M åƒæ•¸ï¼Œ3å±¤å·ç©
- **MobileNetV2**ï¼š2.78M åƒæ•¸ï¼Œ17å±¤æ®˜å·®ç“¶é ¸å¡Š
- **æ›´æ·±çš„ç¶²è·¯å­¸ç¿’æ›´è¤‡é›œçš„ç‰¹å¾µå±¤æ¬¡**

#### Unit16 CNN çš„ 11 å€‹éŒ¯èª¤ç‚ºä½•è¢« MobileNetV2 å®Œå…¨æ¶ˆé™¤ï¼Ÿ

**éŒ¯èª¤åˆ†æ**ï¼š

| éŒ¯èª¤é¡å‹ | Unit16 CNN éŒ¯èª¤æ•¸ | MobileNetV2 éŒ¯èª¤æ•¸ | åŸå› åˆ†æ |
|---------|-----------------|-------------------|---------|
| é›œè³ª â†’ éº»é» | 8 | 0 | æ›´é«˜è§£æåº¦ + é è¨“ç·´ç‰¹å¾µ |
| æ–‘å¡Š â†’ åŠƒç—• | 2 | 0 | æ®˜å·®é€£æ¥æ•æ‰é•·ç¨‹ä¾è³´ |
| åŠƒç—• â†’ æ–‘å¡Š | 1 | 0 | æ·±åº¦æ¨¡å‹å€åˆ†é‚Šç·£ç‰¹å¾µ |

**æŠ€è¡“è§£é‡‹**ï¼š
1. **é›œè³ª vs. éº»é»**ï¼š
   - éƒ½æ˜¯é»ç‹€ç‰¹å¾µï¼Œéœ€è¦ç´°ç²’åº¦ç´‹ç†åˆ†æ
   - 200Ã—200 vs. 64Ã—64ï¼š3.1å€è§£æåº¦æå‡
   - MobileNetV2 çš„æ·±åº¦å¯åˆ†é›¢å·ç©æ›´æ“…é•·æ•æ‰å±€éƒ¨ç´°ç¯€

2. **æ–‘å¡Š vs. åŠƒç—•**ï¼š
   - éœ€è¦å…¨åŸŸä¸Šä¸‹æ–‡ç†è§£
   - MobileNetV2 çš„æ®˜å·®é€£æ¥ä¿ç•™å¤šå°ºåº¦ç‰¹å¾µ
   - ImageNet é è¨“ç·´å·²å­¸æœƒå€åˆ†ä¸åŒå½¢ç‹€æ¨¡å¼

#### è¨“ç·´æ•¸æ“šè³ªé‡èˆ‡ç­–ç•¥

**è¨“ç·´æ•¸æ“šè³ªé‡**ï¼š
- NEU-DET æ¨™è¨»æº–ç¢ºï¼Œé¡åˆ¥å¹³è¡¡
- ç„¡å™ªè²æ¨™ç±¤ï¼ˆLabel Noiseï¼‰ï¼Œè¨“ç·´ç©©å®š

**è¨“ç·´ç­–ç•¥å°æ¯”**ï¼š
- **Unit16 CNN**ï¼šå–®éšæ®µè¨“ç·´ï¼Œ30 epochsï¼Œå­¸ç¿’ç‡å›ºå®šè¡°æ¸›
- **MobileNetV2**ï¼šå…©éšæ®µè¨“ç·´ï¼ˆå‡çµ + å¾®èª¿ï¼‰ï¼Œå­¸ç¿’ç‡ç²¾ç´°èª¿åº¦

#### é©ç•¶çš„æ­£å‰‡åŒ–ï¼š
- Dropout (50%)ï¼šé˜²æ­¢éæ“¬åˆ
- L2 weight decayï¼šå¹³æ»‘æ¬Šé‡
- æ•¸æ“šå¢å¼·ï¼šæ“´å±•æœ‰æ•ˆè¨“ç·´é›†

#### 100% æº–ç¢ºç‡çš„å¯ä¿¡åº¦

**æ˜¯å¦éæ“¬åˆï¼Ÿ**

**è­‰æ“š 1 - å­¸ç¿’æ›²ç·š**ï¼š
- è¨“ç·´å’Œé©—è­‰æå¤±åŒæ­¥ä¸‹é™
- ç„¡æ˜é¡¯åˆ†å‰ï¼ˆdivergenceï¼‰

**è­‰æ“š 2 - è¨“ç·´ç­–ç•¥**ï¼š
- Early stopping é˜²æ­¢éåº¦è¨“ç·´
- Dropout åœ¨æ¸¬è©¦æ™‚é—œé–‰ï¼Œä¸å½±éŸ¿æ¨è«–

**è­‰æ“š 3 - æ•¸æ“šè³ªé‡**ï¼š
- é©—è­‰é›†èˆ‡è¨“ç·´é›†ä¾†è‡ªç›¸åŒåˆ†ä½ˆ
- ç„¡æ•¸æ“šæ´©éœ²ï¼ˆdata leakageï¼‰

**å¯¦éš›éƒ¨ç½²å»ºè­°**ï¼š
å„˜ç®¡é©—è­‰æº–ç¢ºç‡ 100%ï¼Œå¯¦éš›éƒ¨ç½²æ™‚ä»éœ€ï¼š
- åœ¨çœŸå¯¦ç”¢ç·šæ•¸æ“šä¸Šæ¸¬è©¦ï¼ˆç”Ÿç”¢ç’°å¢ƒå¯èƒ½æœ‰ç…§æ˜è®ŠåŒ–ã€æ±¡æŸ“ç­‰ï¼‰
- è¨­ç½®ä¿¡å¿ƒåº¦é–¾å€¼ï¼ˆå¦‚ 0.95ï¼‰é€²è¡Œä¸ç¢ºå®šæ¨£æœ¬çš„äººå·¥è¤‡æª¢
- æŒçºŒç›£æ§æ¨¡å‹æ€§èƒ½ï¼Œå®šæœŸé‡æ–°è¨“ç·´

### 7.3 å·¥æ¥­åŒ–éƒ¨ç½²è€ƒé‡

#### æ¨¡å‹å£“ç¸®èˆ‡åŠ é€Ÿ

**é‡åŒ–ï¼ˆQuantizationï¼‰**ï¼š
å°‡ FP32 æ¬Šé‡è½‰æ›ç‚º INT8ï¼š

$$
w_{\text{int8}} = \text{round}\left(\frac{w_{\text{fp32}} - w_{\min}}{w_{\max} - w_{\min}} \times 255\right)
$$

**æ•ˆç›Š**ï¼š
- æ¨¡å‹å¤§å°ï¼š14 MB â†’ ~4 MB
- æ¨è«–é€Ÿåº¦ï¼šæå‡ 2-4 å€
- æº–ç¢ºç‡ä¸‹é™ï¼š< 1%ï¼ˆé€šå¸¸å¯æ¥å—ï¼‰

**çŸ¥è­˜è’¸é¤¾ï¼ˆKnowledge Distillationï¼‰**ï¼š
è¨“ç·´å°æ¨¡å‹ï¼ˆStudentï¼‰æ¨¡ä»¿å¤§æ¨¡å‹ï¼ˆTeacherï¼‰ï¼š

$$
\mathcal{L}_{\text{KD}} = \alpha \mathcal{L}_{\text{CE}}(y, \hat{y}_S) + (1-\alpha) \mathcal{L}_{\text{KL}}(\hat{y}_T, \hat{y}_S)
$$

å…¶ä¸­ï¼š
- $\hat{y}_S$ ï¼šå­¸ç”Ÿæ¨¡å‹è¼¸å‡º
- $\hat{y}_T$ ï¼šæ•™å¸«æ¨¡å‹è¼¸å‡ºï¼ˆsoft labelsï¼‰
- $\mathcal{L}_{\text{KL}}$ ï¼šKLæ•£åº¦

#### é‚Šç·£è¨­å‚™éƒ¨ç½²

**ç›®æ¨™ç¡¬é«”**ï¼š
- Raspberry Pi 4 (ARM Cortex-A72)
- NVIDIA Jetson Nano (128-core GPU)
- Intel Neural Compute Stick

**å„ªåŒ–ç­–ç•¥**ï¼š
1. TensorFlow Lite è½‰æ›
2. ONNX æ ¼å¼çµ±ä¸€
3. TensorRT åŠ é€Ÿï¼ˆNVIDIAå¹³å°ï¼‰

**éƒ¨ç½²ä»£ç¢¼ç¤ºä¾‹**ï¼š
```python
# è½‰æ›ç‚º TFLite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

# æ¨è«–
interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.set_tensor(input_details[0]['index'], input_data)
interpreter.invoke()
predictions = interpreter.get_tensor(output_details[0]['index'])
```

---

## ç¬¬å…«ç« ï¼šç¸½çµèˆ‡æœªä¾†å±•æœ›

### 8.1 æœ¬å–®å…ƒæ ¸å¿ƒæˆæœ

**æŠ€è¡“æˆå°±**ï¼š

| æŒ‡æ¨™ | Unit16 CNN | MobileNetV2 | æå‡å¹…åº¦ |
|------|-----------|-------------|---------|
| Validation Accuracy | 96.94% | **100.0%** | **+3.06%** |
| F1-score (macro) | 0.969 | **1.000** | **+3.1%** |
| éŒ¯èª¤æ•¸ | 11/360 | **0/360** | **-100%** |
| è¨“ç·´æ™‚é–“ | 2 min (GPU) | 19 min (GPU) | +850% |
| æ¨è«–é€Ÿåº¦ (GPU) | 10 ms | 15 ms | +50% |
| æ¨¡å‹å¤§å° | 5 MB | 11 MB | +120% |
| å½±åƒè§£æåº¦ | 64Ã—64 ç°éš | 200Ã—200 RGB | +9.4Ã— pixels |

> **åƒè€ƒ**ï¼šUnit16_CNN_Basics ä¸­å‚³çµ±æ©Ÿå™¨å­¸ç¿’æ¨¡å‹çš„æ€§èƒ½ç‚º RF: 59.17%, MLP: 38.61%

**é—œéµæ´å¯Ÿ**ï¼š

1. **é·ç§»å­¸ç¿’çš„å¨åŠ›**ï¼š
   - ImageNet é è¨“ç·´ç‰¹å¾µï¼ˆé‚Šç·£ã€ç´‹ç†ï¼‰åœ¨å·¥æ¥­ç¼ºé™·æª¢æ¸¬ä¸­é«˜åº¦æœ‰æ•ˆ
   - åƒ…éœ€ 1440 å¼µè¨“ç·´å½±åƒå³å¯é”åˆ°å®Œç¾åˆ†é¡
   - æ¶ˆé™¤äº† Unit16 CNN çš„ 11 å€‹éŒ¯èª¤æ¡ˆä¾‹ï¼ˆé›œè³ªâ†’éº»é» 8å€‹ï¼Œæ–‘å¡Šâ†’åŠƒç—• 2å€‹ï¼ŒåŠƒç—•â†’æ–‘å¡Š 1å€‹ï¼‰

2. **å…©éšæ®µè¨“ç·´çš„å¿…è¦æ€§**ï¼š
   - Stage 1 å¿«é€Ÿé©æ‡‰ï¼ˆ12 epochs â†’ æ¥è¿‘æ”¶æ–‚ï¼‰
   - Stage 2 ç²¾ç´°èª¿å„ªï¼ˆ20 epochs â†’ 100% accï¼‰
   - å°å­¸ç¿’ç‡å¾®èª¿é¿å…ç½é›£æ€§éºå¿˜

3. **æ­£å‰‡åŒ–èˆ‡æ³›åŒ–**ï¼š
   - Dropout (50%) + æ•¸æ“šå¢å¼· â†’ ç„¡éæ“¬åˆ
   - Early stopping è‡ªå‹•åœ¨æœ€ä½³é»åœæ­¢
   - é©—è­‰æå¤±èˆ‡è¨“ç·´æå¤±åŒæ­¥ä¸‹é™

4. **å¾é ­è¨“ç·´ vs. é·ç§»å­¸ç¿’çš„æ¬Šè¡¡**ï¼š
   - **è¨“ç·´æ™‚é–“**ï¼šCNN 2åˆ†é˜ vs. MobileNetV2 19åˆ†é˜ï¼ˆ9.5Ã— slowerï¼‰
   - **æº–ç¢ºç‡**ï¼šCNN 96.94% vs. MobileNetV2 100%ï¼ˆ+3.06%ï¼‰
   - **éŒ¯èª¤æ¶ˆé™¤**ï¼šCNN 11å€‹éŒ¯èª¤ vs. MobileNetV2 0å€‹éŒ¯èª¤
   - **å¯¦å‹™é¸æ“‡**ï¼šä¸€èˆ¬ç”¢ç·šç”¨ CNNï¼Œé—œéµç”¢ç·šç”¨ MobileNetV2

### 8.2 å·¥æ¥­éƒ¨ç½²ç­–ç•¥

#### æ¨¡å‹é¸æ“‡æ±ºç­–æ¨¹

æ ¹æ“šä¸åŒç”¢ç·šéœ€æ±‚é¸æ“‡é©ç•¶æ¨¡å‹ï¼š

```
ç”¢ç·šéœ€æ±‚è©•ä¼°
  â”‚
  â”œâ”€ æº–ç¢ºç‡è¦æ±‚ > 99%ï¼Ÿ
  â”‚   â”œâ”€ Yes â†’ MobileNetV2 é·ç§»å­¸ç¿’ï¼ˆ100%ï¼‰
  â”‚   â””â”€ No â†’ ç¹¼çºŒ
  â”‚
  â”œâ”€ æº–ç¢ºç‡è¦æ±‚ > 95%ï¼Ÿ
  â”‚   â”œâ”€ Yes â†’ 
  â”‚   â”‚   â”œâ”€ è¨ˆç®—è³‡æºå……è¶³ï¼Ÿâ†’ Yes â†’ MobileNetV2
  â”‚   â”‚   â””â”€ è¨ˆç®—è³‡æºæœ‰é™ï¼Ÿâ†’ Yes â†’ Unit16 CNN (96.94%)
  â”‚   â””â”€ No â†’ ç¹¼çºŒ
  â”‚
  â””â”€ å¿«é€ŸåŸå‹é©—è­‰ï¼Ÿ
      â””â”€ Yes â†’ Unit16 CNNï¼ˆ2åˆ†é˜è¨“ç·´ï¼Œ5MBæ¨¡å‹ï¼‰
```

**æ¨¡å‹é¸æ“‡å»ºè­°**ï¼š

| å ´æ™¯ | æ¨è–¦æ¨¡å‹ | ç†ç”± |
|------|---------|------|
| **é—œéµç”¢ç·š**ï¼ˆèˆªå¤ªã€é†«ç™‚ï¼‰ | MobileNetV2 | 100% æº–ç¢ºç‡ï¼Œé›¶æ¼æª¢ |
| **ä¸€èˆ¬ç”¢ç·š**ï¼ˆé‹¼æã€å¡‘è† ï¼‰ | Unit16 CNN | 96.94% å·²é”æ¨™ï¼Œè¨“ç·´å¿«é€Ÿ |
| **é‚Šç·£è¨­å‚™**ï¼ˆRaspberry Piï¼‰ | Unit16 CNN | åƒæ•¸å°‘ï¼ˆ1.14Mï¼‰ï¼Œæ¨è«–å¿« |
| **é›²ç«¯éƒ¨ç½²**ï¼ˆAzure, AWSï¼‰ | MobileNetV2 | GPU å……è¶³ï¼Œè¿½æ±‚æ¥µè‡´æ€§èƒ½ |
| **å¿«é€ŸPOCé©—è­‰** | Unit16 CNN | 2åˆ†é˜è¨“ç·´ï¼Œå¿«é€Ÿè¿­ä»£ |

#### å®Œæ•´çš„AIå“æª¢ç³»çµ±æ¶æ§‹

```
[ç”¢ç·šå½±åƒæ“·å–] â†’ [é è™•ç†] â†’ [æ¨¡å‹æ¨è«–] â†’ [æ±ºç­–é‚è¼¯] â†’ [æ§åˆ¶å‹•ä½œ]
        â†“              â†“          â†“            â†“            â†“
    å…‰ç…§æ¨™æº–åŒ–     å»å™ª/å¢å¼·   ä¿¡å¿ƒåº¦è¨ˆç®—    ä¸‰ç´šåˆ†é¡    åœç·š/æ¨™è¨˜/æ”¾è¡Œ
```

**ä¸‰ç´šæ±ºç­–ç³»çµ±**ï¼š

| ä¿¡å¿ƒåº¦å€é–“ | æ±ºç­– | å‹•ä½œ | æ¯”ä¾‹ï¼ˆMobileNetV2ï¼‰ | æ¯”ä¾‹ï¼ˆCNNï¼‰ |
|-----------|-----|------|-------------------|------------|
| > 0.95 | è‡ªå‹•åˆ†é¡ | ç›´æ¥æ”¾è¡Œ/å‰”é™¤ | 85% | 75% |
| 0.60 - 0.95 | äººå·¥è¤‡æª¢ | é€²å…¥å¯©æŸ¥éšŠåˆ— | 12% | 20% |
| < 0.60 | ä½ä¿¡å¿ƒ | åœç·šæª¢æŸ¥ | 3% | 5% |

**æˆæœ¬æ•ˆç›Šåˆ†æï¼ˆMobileNetV2ï¼‰**ï¼š

è¨­ï¼š
- $C_{\text{FN}}$ ï¼šæ¼æª¢æˆæœ¬ï¼ˆç¼ºé™·æµå…¥å¸‚å ´ï¼‰
- $C_{\text{FP}}$ ï¼šèª¤åˆ¤æˆæœ¬ï¼ˆè‰¯å“è¢«å‰”é™¤ï¼‰
- $C_{\text{review}}$ ï¼šäººå·¥è¤‡æª¢æˆæœ¬
- $p_{\text{auto}}$ ï¼šè‡ªå‹•åŒ–ç‡

ç¸½æˆæœ¬ï¼š

$$
C_{\text{total}} = N \cdot [C_{\text{FN}} \cdot \text{FNR} + C_{\text{FP}} \cdot \text{FPR} + C_{\text{review}} \cdot (1 - p_{\text{auto}})]
$$

**å¯¦éš›æ¡ˆä¾‹**ï¼ˆå‡è¨­ï¼‰ï¼š
- æ¼æª¢æˆæœ¬ï¼š5000 å…ƒ/ä»¶
- èª¤åˆ¤æˆæœ¬ï¼š500 å…ƒ/ä»¶
- äººå·¥è¤‡æª¢ï¼š20 å…ƒ/ä»¶
- è‡ªå‹•åŒ–ç‡ï¼ˆMobileNetV2ï¼‰ï¼š85%
- è‡ªå‹•åŒ–ç‡ï¼ˆUnit16 CNNï¼‰ï¼š75%

ä½¿ç”¨ MobileNetV2ï¼ˆFNR=0, FPR=0ï¼‰ï¼š

$$
C_{\text{total, MobileNetV2}} = 10000 \times [0 + 0 + 20 \times 0.15] = 30,000 \text{ å…ƒ/æ—¥}
$$

ä½¿ç”¨ Unit16 CNNï¼ˆFNRâ‰ˆ0.03, FPRâ‰ˆ0ï¼‰ï¼š

$$
C_{\text{total, CNN}} = 10000 \times [5000 \times 0.03 + 0 + 20 \times 0.25] = 1,505,000 \text{ å…ƒ/æ—¥}
$$

ç›¸æ¯”å…¨äººå·¥æª¢æ¸¬ï¼ˆæ¯ä»¶ 30 å…ƒï¼‰ï¼š

$$
C_{\text{manual}} = 10000 \times 30 = 300,000 \text{ å…ƒ/æ—¥}
$$

**çµè«–**ï¼š
- å°æ–¼é«˜æ¼æª¢æˆæœ¬ç”¢ç·šï¼ŒMobileNetV2 çš„é›¶éŒ¯èª¤è‡³é—œé‡è¦
- å°æ–¼ä¸€èˆ¬ç”¢ç·šï¼ŒUnit16 CNN çš„ 96.94% å¯èƒ½å·²è¶³å¤ ï¼ˆéœ€çµåˆä¿¡å¿ƒåº¦é–€æª»ï¼‰

**å¹´åº¦ç¯€çœ**ï¼š $(300,000 - 30,000) \times 365 = 98,550,000$ å…ƒ

#### æŒçºŒæ”¹å–„èˆ‡æ¨¡å‹ç¶­è­·

**æ¼‚ç§»ç›£æ§ï¼ˆDrift Detectionï¼‰**ï¼š

**çµ±è¨ˆæ–¹æ³•**ï¼š
- ç›£æ§è¼¸å…¥ç‰¹å¾µåˆ†ä½ˆï¼šKolmogorov-Smirnov æª¢é©—
- ç›£æ§é æ¸¬åˆ†ä½ˆï¼šPopulation Stability Index (PSI)

$$
\text{PSI} = \sum_{i=1}^{K} (p_i^{\text{prod}} - p_i^{\text{train}}) \ln\left(\frac{p_i^{\text{prod}}}{p_i^{\text{train}}}\right)
$$

å…¶ä¸­ï¼š
- $p_i^{\text{train}}$ ï¼šè¨“ç·´æ™‚é¡åˆ¥ $i$ çš„æ¯”ä¾‹
- $p_i^{\text{prod}}$ ï¼šç”Ÿç”¢æ™‚é¡åˆ¥ $i$ çš„æ¯”ä¾‹

**é–¾å€¼è¨­å®š**ï¼š
- PSI < 0.1ï¼šç„¡é¡¯è‘—æ¼‚ç§»
- 0.1 < PSI < 0.25ï¼šä¸­ç­‰æ¼‚ç§»ï¼ˆç›£æ§ï¼‰
- PSI > 0.25ï¼šåš´é‡æ¼‚ç§»ï¼ˆéœ€é‡æ–°è¨“ç·´ï¼‰

**ä¸»å‹•å­¸ç¿’æµç¨‹**ï¼š

1. **ä¸ç¢ºå®šæ€§æ¡æ¨£**ï¼šå„ªå…ˆæ¨™è¨»ä½ä¿¡å¿ƒæ¨£æœ¬

$$
\mathbf{x}^* = \arg\min_{\mathbf{x} \in \mathcal{U}} \max_k p(y=k|\mathbf{x})
$$

2. **å¤šæ¨£æ€§æ¡æ¨£**ï¼šç¢ºä¿è¦†è“‹ç‰¹å¾µç©ºé–“

$$
\mathbf{x}^* = \arg\max_{\mathbf{x} \in \mathcal{U}} \min_{\mathbf{x}' \in \mathcal{L}} \|\phi(\mathbf{x}) - \phi(\mathbf{x}')\|
$$

3. **å¢é‡è¨“ç·´**ï¼šå®šæœŸï¼ˆå¦‚æ¯æœˆï¼‰ç”¨æ–°æ¨™è¨»æ•¸æ“šå¾®èª¿

### 8.3 å»¶ä¼¸è­°é¡Œ

#### 1. æ¨¡å‹è§£é‡‹æ€§ï¼ˆExplainabilityï¼‰

**Grad-CAM å¯è¦–åŒ–**ï¼š

```python
def generate_gradcam(model, img, class_idx):
    grad_model = tf.keras.models.Model(
        [model.inputs], 
        [model.get_layer('last_conv').output, model.output]
    )
    
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img)
        loss = predictions[:, class_idx]
    
    grads = tape.gradient(loss, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    
    heatmap = tf.reduce_sum(pooled_grads * conv_outputs, axis=-1)
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap
```

**LIME (Local Interpretable Model-Agnostic Explanations)**ï¼š
- ç”¨è¶…åƒç´ ï¼ˆSuperpixelï¼‰é®è”½å½±åƒå€åŸŸ
- è§€å¯Ÿé æ¸¬è®ŠåŒ–
- è­˜åˆ¥é—œéµå€åŸŸ

#### 2. å°‘æ¨£æœ¬å­¸ç¿’ï¼ˆFew-shot Learningï¼‰

ç•¶æ–°å¢ç¼ºé™·é¡åˆ¥ä½†åªæœ‰å°‘é‡æ¨£æœ¬æ™‚ï¼š

**åŸå‹ç¶²è·¯ï¼ˆPrototypical Networksï¼‰**ï¼š

$$
c_k = \frac{1}{|S_k|} \sum_{(\mathbf{x}_i, y_i) \in S_k} \phi(\mathbf{x}_i)
$$

$$
p(y=k|\mathbf{x}) = \frac{\exp(-d(\phi(\mathbf{x}), c_k))}{\sum_{k'} \exp(-d(\phi(\mathbf{x}), c_{k'}))}
$$

**åŒ¹é…ç¶²è·¯ï¼ˆMatching Networksï¼‰**ï¼š
åŸºæ–¼æ³¨æ„åŠ›æ©Ÿåˆ¶çš„è¨˜æ†¶ç¶²è·¯

#### 3. ç•°å¸¸æª¢æ¸¬ï¼ˆAnomaly Detectionï¼‰

å°æ–¼æœªçŸ¥ç¼ºé™·é¡å‹ï¼š

**è‡ªç·¨ç¢¼å™¨ï¼ˆAutoencoderï¼‰**ï¼š

$$
\mathcal{L}_{\text{recon}} = \|\mathbf{x} - \text{Dec}(\text{Enc}(\mathbf{x}))\|^2
$$

æ­£å¸¸æ¨£æœ¬é‡å»ºèª¤å·®å°ï¼Œç•°å¸¸æ¨£æœ¬é‡å»ºèª¤å·®å¤§ã€‚

**One-Class SVM**ï¼š

$$
\min_{\mathbf{w}, \rho} \frac{1}{2}\|\mathbf{w}\|^2 - \rho + \frac{1}{\nu N} \sum_i \max(0, \rho - \mathbf{w}^T \phi(\mathbf{x}_i))
$$

### 8.4 å¯¦è¸å»ºè­°

**çµ¦åŒ–å·¥ç³»å­¸ç”Ÿçš„å»ºè­°**ï¼š

1. **ç´®å¯¦çš„åŸºç¤**ï¼š
   - æŒæ¡å·ç©ã€æ± åŒ–ã€æ¿€æ´»å‡½æ•¸çš„æ•¸å­¸åŸç†
   - ç†è§£æå¤±å‡½æ•¸èˆ‡å„ªåŒ–å™¨
   - ç†Ÿæ‚‰æ­£å‰‡åŒ–æŠ€è¡“ï¼ˆDropout, Batch Normalizationï¼‰

2. **å‹•æ‰‹å¯¦ä½œ**ï¼š
   - è‡ªå·±è¨“ç·´æ¨¡å‹ï¼Œè§€å¯Ÿå­¸ç¿’æ›²ç·š
   - å˜—è©¦ä¸åŒè¶…åƒæ•¸ï¼Œç†è§£å…¶å½±éŸ¿
   - ç”¨ Grad-CAM å¯è¦–åŒ–æ¨¡å‹é—œæ³¨å€åŸŸ

3. **é ˜åŸŸçµåˆ**ï¼š
   - å°‡ AI èˆ‡åŒ–å·¥å°ˆæ¥­çŸ¥è­˜çµåˆ
   - ç†è§£ç¼ºé™·æˆå› ï¼ˆåŒ–å­¸ã€ç†±åŠ›å­¸ã€æµé«”åŠ›å­¸ï¼‰
   - è¨­è¨ˆç‰©ç†ç´„æŸçš„æ¨¡å‹ï¼ˆPhysics-informed Neural Networksï¼‰

4. **å·¥ç¨‹æ€ç¶­**ï¼š
   - ä¸åªè¿½æ±‚æº–ç¢ºç‡ï¼Œè€ƒæ…®æ¨è«–é€Ÿåº¦ã€æ¨¡å‹å¤§å°
   - è¨­è¨ˆå®Œæ•´ç³»çµ±ï¼ˆæ•¸æ“šæµã€æ±ºç­–é‚è¼¯ã€ç•°å¸¸è™•ç†ï¼‰
   - é—œæ³¨é•·æœŸç¶­è­·ï¼ˆæ¼‚ç§»ç›£æ§ã€å¢é‡è¨“ç·´ï¼‰

### 8.5 æ€è€ƒé¡Œ

1. **é·ç§»å­¸ç¿’çš„æ¥µé™**ï¼š
   - å¦‚æœæºåŸŸèˆ‡ç›®æ¨™åŸŸå®Œå…¨ä¸åŒï¼ˆå¦‚é†«å­¸å½±åƒ â†’ é‹¼æç¼ºé™·ï¼‰ï¼Œé·ç§»å­¸ç¿’é‚„æœ‰æ•ˆå—ï¼Ÿ
   - å¦‚ä½•é‡åŒ–åŸŸä¹‹é–“çš„ç›¸ä¼¼æ€§ï¼Ÿ

2. **100% æº–ç¢ºç‡çš„éš±æ†‚**ï¼š
   - é©—è­‰é›† 100% æº–ç¢ºç‡æ˜¯å¦æ„å‘³è‘—æ¸¬è©¦é›†ä¹Ÿæœƒ 100%ï¼Ÿ
   - å¦‚ä½•è©•ä¼°æ¨¡å‹åœ¨çœŸå¯¦ç”¢ç·šç’°å¢ƒçš„æ³›åŒ–èƒ½åŠ›ï¼Ÿ

3. **æˆæœ¬æ•æ„Ÿå­¸ç¿’**ï¼š
   - å¦‚æœä¸åŒé¡åˆ¥çš„æ¼æª¢æˆæœ¬ä¸åŒï¼ˆå¦‚è£‚ç´‹ vs è‰²æ–‘ï¼‰ï¼Œå¦‚ä½•èª¿æ•´è¨“ç·´ç­–ç•¥ï¼Ÿ
   - æç¤ºï¼šåŠ æ¬Šäº¤å‰ç†µæå¤±

4. **å¤šæ¨¡æ…‹èåˆ**ï¼š
   - å¦‚æœåŒæ™‚æœ‰å…‰å­¸å½±åƒå’Œç†±å½±åƒï¼Œå¦‚ä½•èåˆï¼Ÿ
   - æ—©æœŸèåˆ vs æ™šæœŸèåˆçš„å„ªåŠ£ï¼Ÿ

5. **å¯è§£é‡‹æ€§èˆ‡æ€§èƒ½çš„æ¬Šè¡¡**ï¼š
   - åœ¨ç›£ç®¡åš´æ ¼çš„è¡Œæ¥­ï¼ˆå¦‚èˆªå¤ªã€é†«è—¥ï¼‰ï¼Œæ˜¯å¦æ‡‰çŠ§ç‰²éƒ¨åˆ†æº–ç¢ºç‡æ›å–å¯è§£é‡‹æ€§ï¼Ÿ
   - å¦‚ä½•å‘éæŠ€è¡“äººå“¡è§£é‡‹æ·±åº¦å­¸ç¿’æ±ºç­–ï¼Ÿ

---

## åƒè€ƒæ–‡ç»

### æ ¸å¿ƒè«–æ–‡

1. **MobileNetV2**ï¼š
   - Sandler, M., et al. (2018). "MobileNetV2: Inverted Residuals and Linear Bottlenecks." *CVPR 2018*.
   - https://arxiv.org/abs/1801.04381

2. **Transfer Learning ç†è«–**ï¼š
   - Pan, S. J., & Yang, Q. (2010). "A survey on transfer learning." *IEEE TKDE*, 22(10), 1345-1359.
   - Yosinski, J., et al. (2014). "How transferable are features in deep neural networks?" *NIPS 2014*.

3. **NEU Surface Defect Database**ï¼š
   - Song, K., & Yan, Y. (2013). "A noise robust method based on completed local binary patterns for hot-rolled steel strip surface defects." *Applied Surface Science*, 285, 858-864.
   - æ•¸æ“šé›†ï¼šhttp://faculty.neu.edu.cn/yunhyan/NEU_surface_defect_database.html

### æ·±åº¦å­¸ç¿’åŸºç¤

4. **CNN åŸºç¤**ï¼š
   - LeCun, Y., et al. (1998). "Gradient-based learning applied to document recognition." *Proceedings of the IEEE*, 86(11), 2278-2324.

5. **Batch Normalization**ï¼š
   - Ioffe, S., & Szegedy, C. (2015). "Batch normalization: Accelerating deep network training by reducing internal covariate shift." *ICML 2015*.

6. **Dropout**ï¼š
   - Srivastava, N., et al. (2014). "Dropout: a simple way to prevent neural networks from overfitting." *JMLR*, 15(1), 1929-1958.

### å·¥æ¥­æ‡‰ç”¨

7. **å·¥æ¥­ç¼ºé™·æª¢æ¸¬ç¶œè¿°**ï¼š
   - Czimmermann, T., et al. (2020). "Visual-based defect detection and classification approaches for industrial applicationsâ€”a survey." *Sensors*, 20(5), 1459.

8. **ç•°å¸¸æª¢æ¸¬**ï¼š
   - Bergmann, P., et al. (2019). "MVTec ADâ€“A comprehensive real-world dataset for unsupervised anomaly detection." *CVPR 2019*.

### æ¨¡å‹è§£é‡‹æ€§

9. **Grad-CAM**ï¼š
   - Selvaraju, R. R., et al. (2017). "Grad-cam: Visual explanations from deep networks via gradient-based localization." *ICCV 2017*.

10. **LIME**ï¼š
    - Ribeiro, M. T., et al. (2016). "Why should I trust you?: Explaining the predictions of any classifier." *KDD 2016*.

### å¯¦ç”¨è³‡æº

11. **Keras å®˜æ–¹æ–‡æª”**ï¼š
    - https://keras.io/api/applications/

12. **TensorFlow é·ç§»å­¸ç¿’æŒ‡å—**ï¼š
    - https://www.tensorflow.org/tutorials/images/transfer_learning

13. **å·¥æ¥­AIéƒ¨ç½²æœ€ä½³å¯¦è¸**ï¼š
    - NVIDIA Jetson Developer Guide: https://developer.nvidia.com/embedded/jetson

---

## é™„éŒ„ï¼šä»£ç¢¼å¯¦ç¾ç´°ç¯€

### A. å®Œæ•´è¨“ç·´æµç¨‹

```python
# Stage 1: Feature Extraction
base_model.trainable = False

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history1 = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=20,
    callbacks=[
        EarlyStopping(patience=7, restore_best_weights=True),
        LearningRateScheduler(lambda epoch, lr: lr * np.exp(-0.1))
    ]
)

# Stage 2: Fine-tuning
for layer in model.layers[-54:]:
    layer.trainable = True

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history2 = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=20,
    callbacks=[
        EarlyStopping(patience=7, restore_best_weights=True),
        LearningRateScheduler(lambda epoch, lr: lr * np.exp(-0.1))
    ]
)
```

### B. æ€§èƒ½è©•ä¼°

```python
# Confusion Matrix
from sklearn.metrics import confusion_matrix, classification_report

y_pred = model.predict(X_val)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_val, axis=1)

cm = confusion_matrix(y_true, y_pred_classes)
print(classification_report(y_true, y_pred_classes, target_names=class_names))

# Visualization
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=class_names, yticklabels=class_names)
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.title('Confusion Matrix - MobileNetV2')
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
```

### C. æ¨¡å‹ä¿å­˜èˆ‡è¼‰å…¥

```python
# Save model
model.save('mobilenetv2_neu_defect.h5')

# Save in SavedModel format
model.save('saved_model/mobilenetv2_neu_defect')

# Load model
loaded_model = tf.keras.models.load_model('mobilenetv2_neu_defect.h5')

# Convert to TFLite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
    f.write(tflite_model)
```

---

**æœ¬è¬›ç¾©å®Œæˆæ–¼ 2025 å¹´ï¼ŒçµåˆåŒ–å·¥å°ˆæ¥­èˆ‡æ·±åº¦å­¸ç¿’å¯¦å‹™ï¼Œæ—¨åœ¨åŸ¹é¤Šå…·å‚™AIæ‡‰ç”¨èƒ½åŠ›çš„åŒ–å·¥äººæ‰ã€‚**

**æˆèª²æ•™å¸«**ï¼š[æ‚¨çš„å§“å]  
**èª²ç¨‹åç¨±**ï¼šåŒ–å·¥AIæ‡‰ç”¨  
**å–®å…ƒ**ï¼šUnit17 - é·ç§»å­¸ç¿’èˆ‡å·¥æ¥­ç¼ºé™·æª¢æ¸¬  
**ç‰ˆæœ¬**ï¼šv2.0ï¼ˆ2025å¹´æ›´æ–°ï¼‰

---

1. **MVTec AD** (ç•°å¸¸æª¢æ¸¬æ¨™æº–è³‡æ–™é›†)
   - URL: https://www.mvtec.com/company/research/datasets/mvtec-ad
   - åŒ…å« 15 ç¨®å·¥æ¥­ç”¢å“, 5000+ é«˜è§£æåº¦å½±åƒ
   - ç‘•ç–µé¡å‹: åˆ®ç—•ã€å‡¹é™·ã€æ±¡æŸ“ã€è£‚ç´‹ç­‰
   - æ‡‰ç”¨: ç´¡ç¹”ã€é›»è·¯æ¿ã€èºçµ²ã€è—¥ä¸¸ç­‰

2. **Severstal Steel Defect Detection** (Kaggle)
   - URL: https://www.kaggle.com/c/severstal-steel-defect-detection
   - é‹¼éµè¡¨é¢ç‘•ç–µæª¢æ¸¬, 18000+ å½±åƒ
   - 4 ç¨®ç‘•ç–µé¡å‹, åŒ…å«åƒç´ ç´šæ¨™è¨»

3. **NEU Surface Defect Database** (æ±åŒ—å¤§å­¸)
   - URL: http://faculty.neu.edu.cn/yunhyan/NEU_surface_defect_database.html
   - ç†±è»‹é‹¼å¸¶è¡¨é¢ç‘•ç–µ, 1800 å¼µå½±åƒ
   - 6 ç¨®å…¸å‹ç‘•ç–µ: æ°§åŒ–çš®ã€æ–‘é»ã€è£‚ç´‹ç­‰

4. **Magnetic Tile Defects** (ç£ç£šç‘•ç–µ)
   - URL: https://github.com/abin24/Magnetic-tile-defect-datasets
   - é™¶ç“·ç£ç£šè¡¨é¢ç‘•ç–µæª¢æ¸¬

**å¯¦ä½œå»ºè­°**:
- ä¸‹è¼‰ MVTec AD è³‡æ–™é›†çš„ "Capsule" é¡åˆ¥ï¼ˆè—¥ä¸¸/è† å›Šï¼‰
- ä½¿ç”¨æœ¬å–®å…ƒçš„ç¨‹å¼ç¢¼æ¶æ§‹ï¼Œå°‡ NEU æ›¿æ›ç‚ºå…¶ä»–å·¥æ¥­è³‡æ–™
- å°æ¯”é·ç§»å­¸ç¿’ vs. å¾é ­è¨“ç·´çš„æ•ˆæœå·®ç•°

---

## 8. ç¸½çµèˆ‡å»¶ä¼¸æ€è€ƒ

### 8.1 æœ¬å–®å…ƒé—œéµè¦é»

**æŠ€è¡“å±¤é¢**ï¼š
1. **é·ç§»å­¸ç¿’çš„åƒ¹å€¼**ï¼šåœ¨å°æ¨£æœ¬ï¼ˆ<2000 å¼µï¼‰æƒ…å¢ƒä¸‹ï¼Œé·ç§»å­¸ç¿’å¯å°‡æº–ç¢ºç‡å¾ 50-70% æå‡è‡³ 95-100%
2. **å…©éšæ®µè¨“ç·´**ï¼šå…ˆå‡çµç‰¹å¾µæå–å™¨è¨“ç·´åˆ†é¡é ­ï¼Œå†å¾®èª¿é«˜å±¤ä»¥é©æ‡‰ç‰¹å®šç´‹ç†
3. **MobileNetV2 å„ªå‹¢**ï¼šè¼•é‡åŒ–ï¼ˆ2.6M åƒæ•¸ï¼‰ã€é«˜æ•ˆèƒ½ï¼ˆé©åˆé‚Šç·£éƒ¨ç½²ï¼‰

**å·¥æ¥­æ‡‰ç”¨**ï¼š
1. **ä¿¡å¿ƒåº¦é–€æª»**ï¼šä¸æ˜¯ä¸€åˆ€åˆ‡çš„ 0.5ï¼Œè€Œæ˜¯æ ¹æ“šæˆæœ¬è¨­è¨ˆä¸‰ç´šæ±ºç­–ï¼ˆpass/review/failï¼‰
2. **Calibration**ï¼šæ¨¡å‹èªª 90% æ™‚ï¼ŒçœŸçš„ 90% å—ï¼Ÿéœ€è¦ reliability diagram æª¢é©—
3. **æŒçºŒæ”¹å–„**ï¼šç›£æ§æ¼‚ç§»ã€äººå·¥è¤‡æª¢å›æµã€ä¸»å‹•å­¸ç¿’

### 8.2 å¸¸è¦‹å•é¡Œèˆ‡è§£æ³•

**Q1: è¨“ç·´ loss ä¸é™æ€éº¼è¾¦ï¼Ÿ**
- æª¢æŸ¥è³‡æ–™æ¨™è¨»æ˜¯å¦æ­£ç¢º
- é™ä½å­¸ç¿’ç‡ï¼ˆ1e-3 â†’ 1e-4ï¼‰
- æª¢æŸ¥è³‡æ–™å¢å¼·æ˜¯å¦éå¼·

**Q2: é©—è­‰é›†è¡¨ç¾é ä½æ–¼è¨“ç·´é›†ï¼Ÿ**
- å…¸å‹éæ“¬åˆï¼ŒåŠ å¼· Dropoutï¼ˆ0.3 â†’ 0.5ï¼‰
- å¢åŠ è³‡æ–™å¢å¼·ï¼ˆæ—‹è½‰ã€ç¿»è½‰ã€äº®åº¦èª¿æ•´ï¼‰
- æ”¶é›†æ›´å¤šæ¨™è¨»è³‡æ–™

**Q3: å¦‚ä½•é¸æ“‡å¾®èª¿å±¤æ•¸ï¼Ÿ**
- è³‡æ–™è¶Šå°‘ï¼Œå‡çµè¶Šå¤šå±¤ï¼ˆé¿å…éæ“¬åˆï¼‰
- NEU è³‡æ–™é›†ï¼ˆ1440 å¼µï¼‰ï¼šè§£å‡å¾Œ 50-100 å±¤æ•ˆæœè¼ƒå¥½
- MVTecï¼ˆ5000+ å¼µï¼‰ï¼šå¯è§£å‡æ›´å¤šå±¤ç”šè‡³å…¨éƒ¨å¾®èª¿

**Q4: RGB vs. ç°éšå½±åƒï¼Ÿ**
- é è¨“ç·´æ¨¡å‹ï¼ˆMobileNetV2ï¼‰éœ€è¦ 3 é€šé“è¼¸å…¥
- è‹¥åŸå§‹å½±åƒæ˜¯ç°éšï¼Œè¤‡è£½ 3 æ¬¡ï¼ˆR=G=Bï¼‰
- å¯¦é©—è­‰æ˜ï¼šRGB + é·ç§»å­¸ç¿’ >> ç°éš + å¾é ­è¨“ç·´

### 8.3 é€²éšä¸»é¡Œ

1. **æ¨¡å‹å£“ç¸®èˆ‡éƒ¨ç½²**ï¼š
   - TensorFlow Lite é‡åŒ–ï¼ˆINT8ï¼‰ï¼šæ¨¡å‹å¤§å°å£“ç¸®è‡³ 1/4
   - æ¨è«–é€Ÿåº¦ï¼šJetson Nano å¯é” 30+ FPS
   - é©åˆé‚Šç·£è£ç½®ï¼ˆç”¢ç·šæ—çš„å·¥æ¥­é›»è…¦ï¼‰

2. **å¾åˆ†é¡åˆ°ç‰©ä»¶åµæ¸¬**ï¼š
   - ç•¶å‰ï¼šå½±åƒç´šåˆ†é¡ï¼ˆæ•´å¼µåœ–æ˜¯å“ªç¨®ç¼ºé™·ï¼‰
   - é€²éšï¼šåƒç´ ç´šå®šä½ï¼ˆç¼ºé™·åœ¨å“ªè£¡ï¼Œæœ‰å¤šå¤§ï¼‰
   - æŠ€è¡“ï¼šYOLOã€Faster R-CNNã€Mask R-CNN

3. **å¤šæ¨™ç±¤åˆ†é¡**ï¼š
   - ç•¶å‰ï¼šå–®ä¸€ç¼ºé™·åˆ†é¡
   - å¯¦å‹™ï¼šä¸€å¼µåœ–å¯èƒ½æœ‰å¤šç¨®ç¼ºé™·ä¸¦å­˜
   - æŠ€è¡“ï¼šMulti-label classificationï¼ˆSigmoid è¼¸å‡ºå±¤ï¼‰

4. **å°‘æ¨£æœ¬å­¸ç¿’ï¼ˆFew-shot Learningï¼‰**ï¼š
   - ç•¶æ–°å¢ç¼ºé™·é¡å‹æ™‚ï¼Œç„¡éœ€é‡æ–°æ¨™è¨»å¤§é‡è³‡æ–™
   - æŠ€è¡“ï¼šPrototypical Networksã€Siamese Networks

### 8.4 èˆ‡å‰å¾Œå–®å…ƒçš„é€£çµ

**èˆ‡ Unit16ï¼ˆCNN åŸºç¤ï¼‰çš„é—œä¿‚**ï¼š
- Unit16ï¼šå¾é ­è¨“ç·´ CNNï¼Œåœ¨ NEU ä¸Šæº–ç¢ºç‡ç´„ 75-85%
- Unit17ï¼šé·ç§»å­¸ç¿’ï¼Œåœ¨åŒæ¨£è³‡æ–™ä¸Šé”åˆ° 95-100%
- **å°æ¯”æ•™å­¸**ï¼šè®“å­¸ç”Ÿé«”æœƒé·ç§»å­¸ç¿’çš„åƒ¹å€¼

**èˆ‡å¾ŒçºŒå–®å…ƒçš„é—œä¿‚**ï¼š
- Unit18ï¼šæ™‚é–“åºåˆ—é æ¸¬ï¼ˆLSTMã€Transformerï¼‰
- Unit19ï¼šå¼·åŒ–å­¸ç¿’ï¼ˆè£½ç¨‹æ§åˆ¶ï¼‰
- å…±åŒä¸»é¡Œï¼š**å¦‚ä½•åœ¨å°æ•¸æ“šæƒ…å¢ƒä¸‹å»ºç«‹å¯é æ¨¡å‹**

### 8.5 è‡ªæˆ‘ç·´ç¿’

1. **è³‡æ–™é›†æ›¿æ›**ï¼š
   - å°‡ NEU è³‡æ–™é›†æ›¿æ›ç‚º MVTec AD çš„ "Capsule" é¡åˆ¥
   - æ¯”è¼ƒé·ç§»å­¸ç¿’èˆ‡å¾é ­è¨“ç·´çš„å·®ç•°

2. **é–€æª»æœ€ä½³åŒ–**ï¼š
   - å‡è¨­æ¼æª¢æˆæœ¬ $50,000ã€èª¤æ®ºæˆæœ¬ $3,000
   - æ ¹æ“š ROC æ›²ç·šè¨ˆç®—æœ€ä½³é–¾å€¼
   - ä¼°ç®—è‡ªå‹•åŒ–ç‡èˆ‡äººå·¥è¤‡æª¢æ¯”ä¾‹

3. **Ablation Study**ï¼š
   - æ¯”è¼ƒä¸åŒé è¨“ç·´æ¨¡å‹ï¼ˆResNet50ã€EfficientNetB0ï¼‰
   - æ¯”è¼ƒä¸åŒå¾®èª¿å±¤æ•¸ï¼ˆ50, 100, 150 layersï¼‰
   - è¨˜éŒ„æº–ç¢ºç‡ã€è¨“ç·´æ™‚é–“ã€æ¨è«–é€Ÿåº¦

4. **éƒ¨ç½²å¯¦ä½œ**ï¼š
   - å°‡è¨“ç·´å¥½çš„æ¨¡å‹è½‰æ›ç‚º TensorFlow Lite
   - åœ¨ Raspberry Pi æˆ– Jetson Nano ä¸Šæ¸¬è©¦æ¨è«–é€Ÿåº¦
   - è¨­è¨ˆç°¡å–®çš„ Web API æ¥å—å½±åƒä¸¦è¿”å›é æ¸¬çµæœ

---

**åƒè€ƒè³‡æ–™**ï¼š
- MobileNetV2 è«–æ–‡: "Inverted Residuals and Linear Bottlenecks" (Sandler et al., 2018)
- é·ç§»å­¸ç¿’ç¶œè¿°: "A Survey on Transfer Learning" (Pan & Yang, 2010)
- NEU è³‡æ–™é›†: Song & Yan, "A noise robust method based on completed local binary patterns for hot-rolled steel strip surface defects" (2013)
- ROC åˆ†æ: Fawcett, "An introduction to ROC analysis" (Pattern Recognition Letters, 2006)

---

**[Next Unit]**
æŒæ¡äº†éœæ…‹å½±åƒè¾¨è­˜èˆ‡é·ç§»å­¸ç¿’å¾Œï¼Œ**Unit 18** å°‡é€²å…¥ **æ™‚é–“åºåˆ—é æ¸¬ (Time Series Forecasting)**ï¼Œå­¸ç¿’å¦‚ä½•ä½¿ç”¨ LSTM è™•ç†å‹•æ…‹è®ŠåŒ–çš„åŒ–å·¥è£½ç¨‹æ•¸æ“šã€‚
