# Unit 16: 卷積神經網路(CNN)概述

## 課程目標
- 理解卷積神經網路(CNN)的基本原理與數學基礎
- 掌握CNN與DNN的核心差異及各自適用場景
- 學會使用TensorFlow/Keras建立、訓練、評估CNN模型
- 了解經典CNN架構的演進與創新
- 掌握CNN在化工領域的應用場景與實踐技巧

---

## 1. CNN基礎理論

### 本章學習地圖

> [!IMPORTANT]
> **本章核心問題**: 為什麼DNN不適合處理影像?CNN如何解決這個問題?

**學習目標**:
1. 🎯 **理解CNN的必要性**: 認識為何影像處理需要專門的網路架構
2. 🧮 **掌握核心運算**: 了解卷積、池化等關鍵操作的數學原理
3. 🔍 **學會參數計算**: 知道如何計算CNN的參數量和輸出尺寸
4. 🎛️ **建立直覺理解**: 透過化工類比理解抽象概念

**為什麼化工人需要學CNN?**

在化工領域,我們經常需要處理影像數據:
- 顯微鏡下的晶體結構分析
- 產品表面的缺陷檢測
- 反應過程的視覺監控
- 光譜影像的成分分析

傳統的DNN雖然強大,但**處理影像時效率極低且容易過擬合**。CNN透過特殊的架構設計,能夠高效地提取影像特徵,是影像分析的首選工具。

**本章架構**:

```
為什麼需要CNN? (1.1)
    ↓
CNN的核心概念 (1.2)
    ├─ 卷積運算
    ├─ 池化操作
    └─ 感受野
    ↓
CNN的典型架構 (1.3)
```

> [!TIP]
> 建議學習方式:先理解「為什麼」,再學習「是什麼」,最後掌握「怎麼做」。不要被數學公式嚇到,每個公式都有其物理意義!

---

### 1.1 為什麼需要CNN?

**DNN處理影像的三大問題**:

#### 問題1: 參數量爆炸 💥

**場景**: 假設我們要用DNN處理一張小小的彩色影像

```
影像尺寸: 224×224×3 (RGB三通道)
輸入神經元數量: 224 × 224 × 3 = 150,528 個
```

如果第一層隱藏層有1024個神經元:

$$
\text{參數量} = 150,528 \times 1,024 + 1,024 = 154,141,696 \approx 1.54億個參數
$$

**化工類比**: 想像你要分析一個反應器的溫度分布
- **DNN方式**: 把每個溫度測點都連接到每個分析單元 → 線路複雜到無法管理
- **CNN方式**: 只關注局部區域的溫度梯度 → 用少量「溫度梯度檢測器」掃描整個反應器

> [!WARNING]
> 1.54億個參數意味著:
> - 需要海量訓練數據(至少數百萬張影像)
> - 訓練時間極長(可能數週)
> - 極易過擬合
> - 記憶體需求巨大

#### 問題2: 忽略空間結構 🗺️

**DNN的致命缺陷**: 將影像展平為一維向量,完全破壞了空間關係

```python
# DNN處理方式
image = np.array([[1, 2, 3],
                  [4, 5, 6],
                  [7, 8, 9]])

flattened = image.flatten()  # [1, 2, 3, 4, 5, 6, 7, 8, 9]
# 像素1和像素2的鄰近關係完全丟失!
```

**化工類比**: 
- **DNN**: 把一張反應器的熱成像圖打散成一串數字,失去了「哪裡溫度高」、「熱點在哪個區域」的空間資訊
- **CNN**: 保持影像的二維結構,能夠識別「左上角有熱點」、「中心區域溫度均勻」等空間模式

#### 問題3: 無法利用平移不變性 🔄

**平移不變性**: 一隻貓不管出現在影像的左邊還是右邊,都應該被識別為貓

**DNN的問題**:
- 需要學習「左上角的貓」、「右下角的貓」、「中間的貓」...
- 每個位置都要重新學習一次特徵
- 浪費大量參數和訓練時間

**化工實例**:
- 產品缺陷可能出現在任何位置
- DNN需要為每個位置訓練一個檢測器
- CNN只需一個檢測器,掃描整個影像

---

**CNN如何解決這些問題?**

| 問題 | DNN的困境 | CNN的解決方案 |
|------|----------|--------------|
| **參數爆炸** | 全連接,參數量 = 輸入×輸出 | 局部連接+參數共享,參數量僅與濾波器大小相關 |
| **空間結構** | 展平為1D,丟失空間資訊 | 保持2D/3D結構,卷積操作保留空間關係 |
| **平移不變性** | 每個位置重新學習 | 同一濾波器掃描整張影像,自動具備平移不變性 |

> [!IMPORTANT]
> **CNN的三大核心設計原則**:
> 1. **局部連接** (Local Connectivity): 每個神經元只看一小塊區域
> 2. **參數共享** (Parameter Sharing): 同一個濾波器在整張影像上重複使用
> 3. **池化降維** (Pooling): 逐步降低空間維度,提取高階特徵

---

### 1.2 CNN的核心概念

#### 1.2.1 卷積運算 (Convolution)

**核心概念**: 卷積是用一個小的「濾波器」(也稱為卷積核或kernel)在影像上滑動,提取局部特徵。

**二維卷積的數學定義**:

$$
S(i, j) = (I * K)(i, j) = \sum_{m} \sum_{n} I(i+m, j+n) \cdot K(m, n)
$$

其中:
- $I$ : 輸入影像 (Input)
- $K$ : 卷積核 (Kernel),通常是 3×3 或 5×5
- $(i, j)$ : 輸出特徵圖的位置
- $(m, n)$ : 卷積核內的相對位置
- $S$ : 輸出特徵圖 (Feature Map)

**直覺理解**: 卷積就是「模板匹配」

想像你有一個3×3的模板,在影像上滑動:
1. 將模板覆蓋在影像的某個區域
2. 對應位置相乘後求和
3. 得到一個數值,代表「匹配程度」
4. 移動模板到下一個位置,重複步驟1-3

**具體範例**:

```
輸入影像 (5×5):          卷積核 (3×3):
┌─────────────┐          ┌─────────┐
│ 1  2  3  4  5│          │ 1  0 -1 │  ← 垂直邊緣檢測器
│ 6  7  8  9 10│          │ 1  0 -1 │
│11 12 13 14 15│    *     │ 1  0 -1 │
│16 17 18 19 20│          └─────────┘
│21 22 23 24 25│
└─────────────┘

計算輸出 (3×3) 的第一個元素:
S(0,0) = 1×1 + 2×0 + 3×(-1) + 6×1 + 7×0 + 8×(-1) + 11×1 + 12×0 + 13×(-1)
       = 1 + 0 - 3 + 6 + 0 - 8 + 11 + 0 - 13
       = -6
```

**化工類比: 濾波器像「化學濾紙」**

| 濾波器類型 | 化學實驗類比 | 檢測特徵 | 化工應用 |
|-----------|-------------|---------|---------|
| **邊緣檢測** | 微分器(檢測濃度梯度) | 裂紋邊界、輪廓線 | 材料表面缺陷檢測 |
| **平滑濾波** | 低通濾波器(去除雜訊) | 消除顆粒感、保留主結構 | 顯微影像降噪 |
| **紋理檢測** | 週期性圖案分析 | 金屬軋製紋路、編織布料 | 產品表面品質檢測 |
| **高頻檢測** | 高通濾波器 | 細節、雜訊 | 微小缺陷識別 |

**常見濾波器範例**:

**Sobel邊緣檢測濾波器** (手工設計,CNN會自動學習類似功能):

$$
K_x = \begin{bmatrix}
-1 & 0 & 1 \\
-2 & 0 & 2 \\
-1 & 0 & 1
\end{bmatrix}, \quad
K_y = \begin{bmatrix}
-1 & -2 & -1 \\
0 & 0 & 0 \\
1 & 2 & 1
\end{bmatrix}
$$

- $K_x$ : 檢測垂直邊緣(左右亮度差異)
- $K_y$ : 檢測水平邊緣(上下亮度差異)

> [!NOTE]
> **CNN的神奇之處**: 這些濾波器的數值不是人工設計的,而是**透過訓練自動學習**出來的!網路會自動學會需要什麼樣的特徵檢測器。

---

**卷積運算的關鍵特性**:

**1. 平移不變性 (Translation Invariance)**

數字在影像中移動,CNN仍能正確辨識(不像全連接層對位置敏感)

**化工實例**:
- 產品缺陷可能出現在任何位置
- 同一個缺陷檢測器可以掃描整個產品表面
- 不需要為每個位置訓練獨立的檢測器

**2. 參數共享 (Parameter Sharing)**

同一個濾波器掃描整張影像,參數量遠小於全連接層

**參數量對比**:
```
全連接層: 224×224×3 → 1024 neurons
參數量 = 150,528 × 1,024 = 154,141,696 個

卷積層: 3×3 濾波器, 32個
參數量 = (3 × 3 × 3 + 1) × 32 = 896 個

減少倍數 = 154,141,696 / 896 ≈ 172,000 倍!
```

**3. 局部連接 (Local Connectivity)**

每個神經元只看一小塊影像區域(感受野 Receptive Field)

**化工類比**:
- 分析反應器溫度分布時,先看局部區域的溫度梯度
- 不需要一次看整個反應器的所有測點
- 逐步整合局部資訊,形成全局理解

---

#### 1.2.2 特徵圖 (Feature Map)

**定義**: 卷積運算的輸出稱為特徵圖,表示輸入數據中特定特徵的激活程度。

**多通道輸出**: 一個卷積層通常包含多個卷積核,產生多個特徵圖

```
輸入: 28×28×1 (灰階影像)
卷積層: 32個 3×3 濾波器
輸出: 26×26×32 (32個特徵圖)
       ↑
       每個特徵圖檢測不同的特徵
       (邊緣、角點、紋理等)
```

**特徵圖尺寸計算**:

$$
O = \frac{W - K + 2P}{S} + 1
$$

其中:
- $O$ : 輸出特徵圖的尺寸(寬或高)
- $W$ : 輸入尺寸(寬或高)
- $K$ : 卷積核尺寸
- $P$ : 填充(padding)大小
- $S$ : 步長(stride)

**計算範例**:

```python
# 範例1: 無填充, 步長1
W = 28, K = 3, P = 0, S = 1
O = (28 - 3 + 0) / 1 + 1 = 26

# 範例2: 有填充, 保持尺寸
W = 28, K = 3, P = 1, S = 1
O = (28 - 3 + 2) / 1 + 1 = 28  # 輸出與輸入同尺寸

# 範例3: 步長2, 快速降維
W = 28, K = 3, P = 0, S = 2
O = (28 - 3 + 0) / 2 + 1 = 13.5 → 13 (向下取整)
```

> [!TIP]
> **Padding的選擇**:
> - ` (無填充): 輸出尺寸會縮小,邊緣資訊可能丟失
> - ` (填充): 輸出尺寸與輸入相同,保留更多資訊
> - 化工應用建議: 影像邊緣有重要資訊時使用`

---

#### 1.2.3 池化 (Pooling)

**核心概念**: 池化層用於降低特徵圖的空間維度,減少參數量並提高模型的平移不變性。

**最大池化 (Max Pooling)**:

$$
y_{i,j} = \max_{(p,q) \in \mathcal{R}_{i,j}} x_{p,q}
$$

其中 $\mathcal{R}_{i,j}$ 為 2×2 池化視窗覆蓋的區域。

**直覺理解**: 在每個小區域中,只保留最強的訊號

```
輸入 (4×4):              輸出 (2×2):
┌──────────┐            ┌─────┐
│ 1  3  2  4│            │ 3  4│
│ 5  6  7  8│    Max     │ 9 12│
│ 9  2  1  3│   Pool     └─────┘
│ 4  5 11 12│   2×2
└──────────┘

計算過程:
左上: max(1,3,5,6) = 6  → 但實際是 max(1,3,5,6) = 6
右上: max(2,4,7,8) = 8  → 實際是 max(2,4,7,8) = 8
左下: max(9,2,4,5) = 9
右下: max(1,3,11,12) = 12
```

**平均池化 (Average Pooling)**:

$$
y_{i,j} = \frac{1}{|\mathcal{R}_{i,j}|} \sum_{(p,q) \in \mathcal{R}_{i,j}} x_{p,q}
$$

**兩種池化的對比**:

| 特性 | Max Pooling | Average Pooling |
|------|-------------|-----------------|
| **保留資訊** | 最強特徵 | 平均特徵 |
| **適用場景** | 分類任務(保留最顯著特徵) | 需要平滑輸出時 |
| **對雜訊** | 較敏感(可能選中雜訊) | 較穩健(平均化雜訊) |
| **化工應用** | 缺陷檢測(找最嚴重的) | 溫度場分析(區域平均) |

**生物學啟發**:
- 模擬視覺皮層的「側抑制」機制
- 只保留最強烈的特徵訊號(類似「贏者全拿」)
- 提高對微小位移的容忍度

**池化層的效果**:

1. **降低維度**: 
   ```
   28×28 → MaxPool(2×2) → 14×14
   14×14 → MaxPool(2×2) → 7×7
   ```

2. **提升平移容忍度**: 
   - 數字稍微移動幾個像素仍能辨識
   - 化工應用: 產品位置稍有偏移不影響檢測

3. **防止過擬合**: 
   - 減少參數數量
   - 強迫模型學習更魯棒的特徵

> [!WARNING]
> **池化的代價**: 會丟失一些空間資訊和細節
> - 現代架構(如ResNet)傾向減少池化層
> - 改用步長卷積(strided convolution)來降維
> - 化工應用: 如果細節很重要(如微小裂紋),謹慎使用池化

---

#### 1.2.4 感受野 (Receptive Field)

**定義**: 感受野是指輸出特徵圖中的一個神經元在原始輸入影像上所對應的區域大小。

**為什麼重要?**
- 感受野決定了神經元能「看到」多大範圍的資訊
- 感受野太小: 無法捕捉大尺度特徵(如整個物體)
- 感受野太大: 計算成本高,可能包含無關資訊

**感受野計算公式**:

$$
RF_l = RF_{l-1} + (K_l - 1) \times \prod_{i=1}^{l-1} S_i
$$

其中:
- $RF_l$ : 第 $l$ 層的感受野
- $K_l$ : 第 $l$ 層的卷積核尺寸
- $S_i$ : 第 $i$ 層的步長
- 初始條件: $RF_0 = 1$ (輸入層)

**計算範例**:

```
網路架構:
Input (28×28) 
  → Conv1 (3×3, stride=1) 
  → MaxPool (2×2, stride=2)
  → Conv2 (3×3, stride=1)
  → MaxPool (2×2, stride=2)

計算感受野:
Layer 0 (Input):     RF = 1
Layer 1 (Conv1):     RF = 1 + (3-1)×1 = 3
Layer 2 (MaxPool):   RF = 3 + (2-1)×1 = 4
Layer 3 (Conv2):     RF = 4 + (3-1)×2 = 8
Layer 4 (MaxPool):   RF = 8 + (2-1)×2 = 10
```

**視覺化理解**:

```
原始影像 (28×28)
┌─────────────────────────┐
│                         │
│    ┌─────────┐          │  ← Layer 1: 3×3 感受野
│    │  ┌───┐  │          │  ← Layer 2: 4×4 感受野  
│    │  │ ● │  │          │  ← Layer 3: 8×8 感受野
│    │  └───┘  │          │
│    └─────────┘          │
│                         │
└─────────────────────────┘

● = 某個深層神經元
它的感受野覆蓋了原始影像的一大塊區域
```

**化工類比**:

想像分析一個反應器的溫度分布:
- **第一層** (小感受野): 看局部3×3區域的溫度梯度
- **第二層** (中感受野): 整合多個局部梯度,識別「熱點」
- **第三層** (大感受野): 理解整體溫度場的分布模式

**設計原則**:

| 應用場景 | 所需感受野 | 網路設計建議 |
|---------|-----------|-------------|
| **細節檢測** (微小裂紋) | 小 (10-30像素) | 淺層網路,小卷積核 |
| **物體識別** (產品分類) | 中 (50-100像素) | 中等深度,混合卷積核 |
| **場景理解** (整體品質) | 大 (>100像素) | 深層網路,或使用空洞卷積 |

> [!TIP]
> **增大感受野的方法**:
> 1. 增加網路深度(堆疊更多卷積層)
> 2. 使用更大的卷積核(但參數量會增加)
> 3. 使用池化層或步長卷積
> 4. 使用空洞卷積(Dilated Convolution)

---

### 1.3 CNN的典型架構

**標準CNN架構流程**:

```
Input → [Conv → Activation → Pooling] × N → Flatten → Dense → Output
```

**各部分的作用**:

| 組件 | 作用 | 化工類比 |
|------|------|---------|
| **卷積層** | 提取局部特徵 | 局部溫度梯度檢測器 |
| **激活函數** | 引入非線性 | 閾值判斷(超過某溫度才反應) |
| **池化層** | 降維、提取主要特徵 | 區域平均或最大值統計 |
| **展平層** | 轉換為1D向量 | 將2D溫度場轉為特徵向量 |
| **全連接層** | 整合特徵進行決策 | 綜合所有資訊做最終判斷 |
| **輸出層** | 產生預測結果 | 輸出分類或數值預測 |

**具體範例: MNIST手寫數字識別**

```python
from tensorflow.keras import models, layers

model = models.Sequential([
    # 第一個卷積塊: 提取低階特徵(邊緣、角點)
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    
    # 第二個卷積塊: 提取中階特徵(筆畫組合)
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    # 第三個卷積塊: 提取高階特徵(數字形狀)
    layers.Conv2D(64, (3, 3), activation='relu'),
    
    # 展平並連接全連接層
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),  # 防止過擬合
    layers.Dense(10, activation='softmax')  # 10類別輸出
])
```

**特徵提取的層次結構**:

```
原始影像 (28×28)
    ↓
第一層卷積 → 檢測邊緣、線條
    ↓
第二層卷積 → 組合成筆畫、角度
    ↓
第三層卷積 → 識別數字的局部形狀
    ↓
全連接層 → 整合所有特徵,識別完整數字
```

**本章小結**

恭喜!您已經理解了CNN的核心原理:

✅ **CNN的必要性**: 解決DNN處理影像的三大問題(參數爆炸、空間結構、平移不變性)  
✅ **卷積運算**: 局部連接+參數共享,高效提取特徵  
✅ **池化操作**: 降維+提升魯棒性  
✅ **感受野**: 理解神經元「看到」的範圍  
✅ **典型架構**: 掌握CNN的標準組成部分  

**關鍵要點回顧**:

| 概念 | 核心思想 | 化工類比 |
|------|---------|---------|
| 卷積 | 局部特徵提取 | 溫度梯度檢測器 |
| 池化 | 降維+魯棒性 | 區域統計量 |
| 感受野 | 神經元視野範圍 | 感測器覆蓋範圍 |
| 參數共享 | 同一檢測器掃描全圖 | 同一分析方法用於所有區域 |

> [!IMPORTANT]
> **記住**: CNN不是魔法,而是針對影像數據特性(局部性、平移不變性)設計的高效架構。理解這些設計原則,才能在化工應用中靈活運用!

---

## 2. 經典CNN架構演進

### 本章學習地圖

> [!IMPORTANT]
> **本章核心問題**: CNN架構如何演進?每一代創新解決了什麼問題?

**學習目標**:
1. 🎯 **理解架構演進**: 認識CNN從簡單到複雜的發展歷程
2. 🔍 **掌握核心創新**: 了解每個經典架構的關鍵突破
3. 🏭 **學會選擇架構**: 知道在化工應用中該選擇哪種架構
4. 📊 **建立全局視野**: 理解CNN發展的大趨勢

**為什麼要學習這些經典架構?**

雖然我們可以直接使用最新的架構,但理解演進歷程能夠:
- ✅ 理解每個設計選擇背後的原因
- ✅ 在遇到問題時知道該往哪個方向優化
- ✅ 根據實際需求(準確度、速度、資源)選擇合適架構
- ✅ 站在巨人的肩膀上,避免重複犯錯

**CNN架構演進時間線**:

```
1998        2012        2014        2015        2017        2019
 │           │           │           │           │           │
LeNet    AlexNet    VGGNet      ResNet    MobileNet  EfficientNet
 │           │       GoogLeNet     │           │           │
 │           │           │           │           │           │
手寫     ImageNet   深度堆疊   殘差連接   移動端    複合縮放
數字      突破      簡化設計   訓練深網   輕量化    最優平衡
```

**本章架構**:

```
CNN演進史 (2.1-2.7)
    ├─ LeNet (1998): 開山之作
    ├─ AlexNet (2012): 深度學習復興
    ├─ VGGNet (2014): 深度的力量
    ├─ GoogLeNet (2014): 寬度的智慧
    ├─ ResNet (2015): 突破深度極限
    ├─ MobileNet (2017): 輕量化革命
    └─ EfficientNet (2019): 系統化優化
    ↓
架構選擇指南 (2.8)
```

> [!TIP]
> 學習重點:不要死記每個架構的細節,而要理解「為什麼」要這樣設計,以及「什麼時候」該用哪個架構。

---

### 2.1 LeNet-5 (1998) - 開山之作

**提出者**: Yann LeCun et al.

**歷史地位**: CNN的開山之作,首次證明CNN可以有效處理影像識別任務

**網路結構**:

```
Input (32×32×1)
    ↓
Conv1 (6個 5×5 filters) → 28×28×6
    ↓
AvgPool (2×2) → 14×14×6
    ↓
Conv2 (16個 5×5 filters) → 10×10×16
    ↓
AvgPool (2×2) → 5×5×16
    ↓
Flatten → 400
    ↓
FC1 (120 neurons)
    ↓
FC2 (84 neurons)
    ↓
Output (10 classes)
```

**核心特點**:

| 特點 | 說明 | 現代視角 |
|------|------|---------|
| **卷積層** | 2層,濾波器數量少(6, 16) | 現代網路通常32+起跳 |
| **池化方式** | 平均池化(Average Pooling) | 現代多用最大池化 |
| **激活函數** | Tanh | 現代多用ReLU |
| **參數量** | 約6萬個 | 非常輕量 |

**創新點**:

1. **局部感受野**: 首次系統化使用局部連接
2. **權重共享**: 大幅減少參數量
3. **子採樣**: 使用池化層降維

**應用場景**: 
- MNIST手寫數字識別(準確率~99%)
- 支票上的手寫數字辨識

**化工應用啟示**:
- 適合簡單、低解析度的影像任務
- 例如:數字儀表讀數識別、簡單符號檢測

> [!NOTE]
> LeNet雖然古老,但其核心思想(卷積+池化+全連接)仍是現代CNN的基礎架構。

---

### 2.2 AlexNet (2012) - 深度學習復興

**提出者**: Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton

**歷史地位**: ImageNet 2012冠軍,Top-5錯誤率從26%降至15.3%,引爆深度學習熱潮

**網路結構**:

```
Input (227×227×3)
    ↓
Conv1 (96個 11×11, stride=4) → 55×55×96
    ↓
MaxPool (3×3, stride=2) → 27×27×96
    ↓
Conv2 (256個 5×5) → 27×27×256
    ↓
MaxPool (3×3, stride=2) → 13×13×256
    ↓
Conv3 (384個 3×3) → 13×13×384
Conv4 (384個 3×3) → 13×13×384
Conv5 (256個 3×3) → 13×13×256
    ↓
MaxPool (3×3, stride=2) → 6×6×256
    ↓
Flatten → 9216
    ↓
FC1 (4096) + Dropout(0.5)
FC2 (4096) + Dropout(0.5)
    ↓
Output (1000 classes)
```

**突破性創新**:

| 創新 | 說明 | 影響 |
|------|------|------|
| **ReLU激活** | 首次大規模使用ReLU替代Tanh | 訓練速度提升6倍 |
| **Dropout** | 隨機丟棄50%神經元 | 有效防止過擬合 |
| **數據增強** | 隨機裁剪、翻轉、顏色抖動 | 擴充訓練集,提升泛化 |
| **GPU訓練** | 雙GPU並行訓練 | 使大規模訓練成為可能 |
| **局部響應正規化** | Local Response Normalization (LRN) | 後被Batch Norm取代 |

**參數量**: 約6000萬個(是LeNet的1000倍)

**為什麼能成功?**

1. **更深的網路** (8層 vs LeNet的5層)
2. **更多的數據** (ImageNet 120萬張影像)
3. **更強的算力** (GPU加速)
4. **更好的技巧** (ReLU, Dropout, Data Augmentation)

**化工應用啟示**:
- 適合複雜、高解析度的影像任務
- 例如:產品表面缺陷檢測、複雜場景分析
- 需要GPU支持

> [!IMPORTANT]
> **AlexNet的歷史意義**: 證明了深度學習在影像識別上的巨大潛力,開啟了深度學習的黃金時代。

---

### 2.3 VGGNet (2014) - 深度的力量

**提出者**: Visual Geometry Group, Oxford University

**核心哲學**: "deeper is better" - 用簡單的小卷積核堆疊出深層網路

**網路結構** (以VGG-16為例):

```
Input (224×224×3)
    ↓
Block 1: Conv(64) × 2 + MaxPool → 112×112×64
Block 2: Conv(128) × 2 + MaxPool → 56×56×128
Block 3: Conv(256) × 3 + MaxPool → 28×28×256
Block 4: Conv(512) × 3 + MaxPool → 14×14×512
Block 5: Conv(512) × 3 + MaxPool → 7×7×512
    ↓
Flatten → 25088
FC1 (4096) + Dropout
FC2 (4096) + Dropout
Output (1000)
```

**核心創新**:

**1. 統一使用3×3小卷積核**

為什麼用3×3而不是更大的卷積核?

$$
\text{兩層3×3卷積的感受野} = 5×5
$$

$$
\text{三層3×3卷積的感受野} = 7×7
$$

**參數量對比**:
```
一層 7×7 卷積: 7×7×C = 49C 個參數
三層 3×3 卷積: 3×(3×3×C) = 27C 個參數

節省: (49-27)/49 = 45%
```

**優勢**:
- ✅ 參數更少
- ✅ 非線性更強(三層激活 vs 一層)
- ✅ 更容易訓練

**2. 深度堆疊**

| 變體 | 層數 | 參數量 | Top-5錯誤率 |
|------|------|--------|------------|
| VGG-11 | 11層 | 133M | 10.4% |
| VGG-13 | 13層 | 133M | 9.9% |
| VGG-16 | 16層 | 138M | 8.8% |
| VGG-19 | 19層 | 144M | 9.0% |

**觀察**: VGG-16是甜蜜點,再深(VGG-19)效果提升有限

**優點**:
- ✅ 結構簡單,易於理解和實現
- ✅ 遷移學習效果好(特徵提取能力強)
- ✅ 視覺化效果好(特徵圖清晰)

**缺點**:
- ❌ 參數量巨大(138M)
- ❌ 計算量大,訓練慢
- ❌ 全連接層佔用大量記憶體

**化工應用**:
- 適合作為特徵提取器(遷移學習)
- 例如:在預訓練VGG基礎上微調,用於化工影像分類
- 需要較強的計算資源

**Keras實現**:
```python
from tensorflow.keras.applications import VGG16

# 載入預訓練模型
base_model = VGG16(weights='imagenet', include_top=False, 
                   input_shape=(224, 224, 3))

# 凍結預訓練層
base_model.trainable = False

# 添加自定義分類頭
model = models.Sequential([
    base_model,
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation='softmax')
])
```

> [!TIP]
> **VGG的遺產**: 雖然參數量大,但其簡單的設計和強大的特徵提取能力,使其至今仍是遷移學習的熱門選擇。

---

### 2.4 GoogLeNet / Inception (2014) - 寬度的智慧

**提出者**: Google (Christian Szegedy et al.)

**核心哲學**: "wider is smarter" - 在同一層使用多種尺寸的卷積核

**Inception模組**:

```
                Input
                  │
        ┌─────────┼─────────┬─────────┐
        │         │         │         │
    1×1 Conv  1×1 Conv  1×1 Conv  MaxPool
        │         │         │         │
        │     3×3 Conv  5×5 Conv  1×1 Conv
        │         │         │         │
        └─────────┴─────────┴─────────┘
                  │
            Concatenate
                  │
               Output
```

**設計思想**:

**問題**: 不知道該用3×3還是5×5卷積核?

**Inception的答案**: 全都要!讓網路自己學習哪個重要

**1×1卷積的妙用**:

$$
\text{降維}: 256 \text{通道} \xrightarrow{1×1 \text{ Conv}} 64 \text{通道}
$$

**參數量對比**:
```
直接5×5卷積: 256 → 256
參數量 = 5×5×256×256 = 1,638,400

先1×1降維再5×5:
  256 → 64 (1×1): 256×64 = 16,384
  64 → 256 (5×5): 5×5×64×256 = 409,600
總計 = 425,984 (節省74%)
```

**核心創新**:

| 創新 | 說明 | 優勢 |
|------|------|------|
| **多尺度特徵** | 同時提取1×1, 3×3, 5×5特徵 | 捕捉不同尺度的模式 |
| **1×1卷積降維** | 減少計算量 | 參數少,速度快 |
| **全局平均池化** | 替代全連接層 | 大幅減少參數 |

**網路統計**:

- **層數**: 22層
- **參數量**: 500萬(僅為AlexNet的1/12)
- **Top-5錯誤率**: 6.7%

**化工應用場景**:

**多尺度缺陷檢測**:
- 小缺陷(微裂紋): 5×5卷積捕捉
- 中缺陷(劃痕): 3×3卷積捕捉
- 大缺陷(變色區): 1×1卷積捕捉

> [!IMPORTANT]
> **Inception的啟示**: 不要糾結於單一選擇,讓網路自己學習最優組合。這種「集成思維」在化工優化中也很有用。

---

### 2.5 ResNet (2015) - 突破深度極限

**提出者**: Kaiming He et al., Microsoft Research

**歷史地位**: ImageNet 2015冠軍,首次訓練超過100層的網路

**核心問題**: 為什麼更深的網路反而表現更差?

**退化問題 (Degradation Problem)**:

```
訓練誤差
    │
    │     ┌─── 56層網路
    │    ╱
    │   ╱
    │  ╱  ┌─── 20層網路
    │ ╱  ╱
    │╱  ╱
    └────────────→ Epoch
    
理論上56層應該至少和20層一樣好
(可以把多餘的層設為恆等映射)
但實際上訓練誤差反而更高!
```

**原因**: 梯度消失/爆炸,深層網路難以訓練

**ResNet的解決方案: 殘差連接 (Residual Connection)**

**殘差塊 (Residual Block)**:

```
        Input (x)
          │
          ├──────────────┐ (跳躍連接)
          │              │
      Conv 3×3           │
          │              │
        ReLU             │
          │              │
      Conv 3×3           │
          │              │
          └──────(+)─────┘
                 │
               ReLU
                 │
              Output
```

**數學表示**:

$$
y = F(x, \{W_i\}) + x
$$

其中:
- $x$ : 輸入
- $F(x, \{W_i\})$ : 殘差映射(要學習的部分)
- $y$ : 輸出

**直覺理解**:

**傳統網路**: 學習 $H(x)$ (直接映射)
**ResNet**: 學習 $F(x) = H(x) - x$ (殘差)

**為什麼更容易?**

如果最優映射接近恆等映射 $H(x) = x$:
- 傳統網路: 需要學習 $H(x) = x$ (困難)
- ResNet: 只需學習 $F(x) = 0$ (容易,權重趨近0即可)

**化工類比**:

想像調整反應器溫度:
- **傳統方式**: 每次從頭計算最優溫度
- **殘差方式**: 在當前溫度基礎上微調(+2°C或-1°C)

後者顯然更容易!

**ResNet變體**:

| 模型 | 層數 | 參數量 | Top-5錯誤率 | 特點 |
|------|------|--------|------------|------|
| ResNet-18 | 18 | 11.7M | 10.2% | 輕量,快速 |
| ResNet-34 | 34 | 21.8M | 8.6% | 平衡 |
| ResNet-50 | 50 | 25.6M | 7.1% | 常用 |
| ResNet-101 | 101 | 44.5M | 6.5% | 高精度 |
| ResNet-152 | 152 | 60.2M | 6.2% | 極深 |

**核心優勢**:

1. **可以訓練極深網路** (1000+層都可以)
2. **梯度流動順暢** (跳躍連接提供直接路徑)
3. **性能優異** (深度帶來更強表達能力)
4. **遷移學習效果好** (廣泛用於各種任務)

**化工應用**:

**適合場景**:
- 需要高精度的影像分析
- 複雜的多尺度特徵提取
- 遷移學習的基礎模型

> [!IMPORTANT]
> **ResNet的革命性意義**: 證明了「深度」不是問題,關鍵是「如何訓練深度網路」。殘差連接成為現代深度學習的標準組件。

---

### 2.6 MobileNet (2017) - 輕量化革命

**提出者**: Google

**設計目標**: 在移動設備和嵌入式系統上運行CNN

**核心創新: 深度可分離卷積 (Depthwise Separable Convolution)**

**傳統卷積 vs 深度可分離卷積**:

**傳統卷積**:
```
Input: H×W×C_in
Filter: K×K×C_in×C_out
Output: H×W×C_out

參數量 = K×K×C_in×C_out
```

**深度可分離卷積** = Depthwise + Pointwise:

**步驟1: Depthwise卷積** (逐通道卷積)
```
Input: H×W×C_in
Filter: K×K×1 (每個通道一個)
Output: H×W×C_in

參數量 = K×K×C_in
```

**步驟2: Pointwise卷積** (1×1卷積)
```
Input: H×W×C_in
Filter: 1×1×C_in×C_out
Output: H×W×C_out

參數量 = 1×1×C_in×C_out
```

**總參數量**:

$$
\text{Depthwise Separable} = K×K×C_{in} + C_{in}×C_{out}
$$

**參數量對比**:

```
假設: K=3, C_in=128, C_out=256

傳統卷積: 3×3×128×256 = 294,912
深度可分離: 3×3×128 + 128×256 = 1,152 + 32,768 = 33,920

減少倍數 = 294,912 / 33,920 ≈ 8.7倍!
```

**一般化公式**:

$$
\text{減少倍數} = \frac{K×K×C_{in}×C_{out}}{K×K×C_{in} + C_{in}×C_{out}} \approx \frac{1}{C_{out}} + \frac{1}{K^2}
$$

對於3×3卷積: $\frac{1}{C_{out}} + \frac{1}{9} \approx \frac{1}{9}$ (當 $C_{out}$ 很大時)

**MobileNet性能**:

| 模型 | 參數量 | 計算量 | Top-1準確率 | 推論速度 |
|------|--------|--------|------------|---------|
| VGG-16 | 138M | 15.5B | 71.5% | 慢 |
| ResNet-50 | 25.6M | 3.9B | 76.0% | 中 |
| MobileNet | 4.2M | 569M | 70.6% | 快 |

**化工應用場景**:

**邊緣設備部署**:
- 產線即時檢測(嵌入式相機)
- 移動端品質檢測App
- 資源受限的工業控制器

**實際案例**:
```
場景: 產線上的即時缺陷檢測
硬體: Raspberry Pi 4 (ARM處理器)
需求: 推論時間 < 100ms

方案選擇:
❌ ResNet-50: 推論時間 ~500ms (太慢)
✅ MobileNetV2: 推論時間 ~50ms (符合需求)
```

> [!TIP]
> **選擇MobileNet的時機**:
> - 部署在移動設備或嵌入式系統
> - 需要即時推論(毫秒級)
> - 計算資源受限
> - 可以接受略低的準確率(通常降低2-5%)

---

### 2.7 EfficientNet (2019) - 系統化優化

**提出者**: Google (Mingxing Tan, Quoc V. Le)

**核心問題**: 如何系統化地擴展CNN?

**傳統擴展方法的問題**:

```
方法1: 加深網路 (增加層數)
方法2: 加寬網路 (增加通道數)
方法3: 提高解析度 (更大的輸入影像)

問題: 這三個維度該如何平衡?
```

**EfficientNet的答案: 複合縮放 (Compound Scaling)**

**複合縮放公式**:

$$
\begin{aligned}
\text{depth:} \quad & d = \alpha^\phi \\
\text{width:} \quad & w = \beta^\phi \\
\text{resolution:} \quad & r = \gamma^\phi \\
\text{subject to:} \quad & \alpha \cdot \beta^2 \cdot \gamma^2 \approx 2 \\
& \alpha \geq 1, \beta \geq 1, \gamma \geq 1
\end{aligned}
$$

其中:
- $\phi$ : 複合係數(控制總資源)
- $\alpha, \beta, \gamma$ : 深度、寬度、解析度的縮放係數

**直覺理解**:

```
φ=0: EfficientNet-B0 (基準)
φ=1: EfficientNet-B1 (2倍資源)
φ=2: EfficientNet-B2 (4倍資源)
...
φ=7: EfficientNet-B7 (最大)
```

**為什麼是 $\beta^2 \cdot \gamma^2$?**

計算量 (FLOPs) 與寬度和解析度的平方成正比:
- 寬度加倍 → 計算量×4
- 解析度加倍 → 計算量×4

**EfficientNet性能**:

| 模型 | 參數量 | FLOPs | Top-1準確率 | vs ResNet-50 |
|------|--------|-------|------------|-------------|
| ResNet-50 | 26M | 4.1B | 76.0% | 基準 |
| EfficientNet-B0 | 5.3M | 0.39B | 77.1% | +1.1%, 10倍快 |
| EfficientNet-B1 | 7.8M | 0.70B | 79.1% | +3.1%, 6倍快 |
| EfficientNet-B7 | 66M | 37B | 84.3% | +8.3% |

**核心優勢**:

1. **參數效率極高**: 相同準確率下,參數量和計算量最少
2. **系統化設計**: 不是靠運氣,而是有理論指導
3. **可擴展性強**: 從B0到B7,適應不同資源需求

**化工應用選擇**:

| 場景 | 推薦模型 | 理由 |
|------|---------|------|
| **雲端高精度分析** | EfficientNet-B5/B6 | 準確率最高 |
| **邊緣設備部署** | EfficientNet-B0/B1 | 輕量快速 |
| **平衡方案** | EfficientNet-B3/B4 | 性價比最高 |

> [!IMPORTANT]
> **EfficientNet的啟示**: 優化不是單一維度的,而是多維度的平衡。這種系統化思維在化工過程優化中同樣適用。

---

### 2.8 架構選擇指南

**決策流程圖**:

```
開始選擇CNN架構
    │
    ├─ 需要最高準確率? (不計成本)
    │   └─ 是 → EfficientNet-B7 或 ResNet-152
    │
    ├─ 需要部署到移動/嵌入式設備?
    │   └─ 是 → MobileNetV2/V3 或 EfficientNet-B0
    │
    ├─ 需要遷移學習? (數據量少)
    │   └─ 是 → ResNet-50 或 EfficientNet-B3
    │
    ├─ 需要可解釋性? (視覺化特徵)
    │   └─ 是 → VGG-16
    │
    └─ 平衡性能與效率?
        └─ 是 → EfficientNet-B1~B4
```

**架構對比總表**:

| 架構 | 年份 | 參數量 | 準確率 | 速度 | 適用場景 |
|------|------|--------|--------|------|---------|
| LeNet | 1998 | 60K | 低 | 極快 | 簡單任務,教學 |
| AlexNet | 2012 | 60M | 中 | 慢 | 歷史研究 |
| VGGNet | 2014 | 138M | 中高 | 慢 | 遷移學習,特徵提取 |
| GoogLeNet | 2014 | 5M | 中高 | 快 | 多尺度特徵 |
| ResNet | 2015 | 26M | 高 | 中 | 通用,遷移學習 |
| MobileNet | 2017 | 4M | 中 | 極快 | 移動端,嵌入式 |
| EfficientNet | 2019 | 5-66M | 極高 | 快 | 新項目首選 |

**化工應用推薦**:

| 應用場景 | 推薦架構 | 理由 |
|---------|---------|------|
| **產品缺陷檢測** | EfficientNet-B1, MobileNetV2 | 平衡準確率與速度 |
| **顯微影像分析** | ResNet-50, EfficientNet-B3 | 需要深層特徵提取 |
| **即時監控** | MobileNetV3, EfficientNet-B0 | 推論速度快 |
| **高精度分類** | EfficientNet-B5, ResNet-101 | 準確率優先 |
| **遷移學習** | ResNet-50, VGG-16 | 預訓練模型豐富 |

**實用建議**:

1. **從簡單開始**: 先用EfficientNet-B0或MobileNetV2建立基準
2. **逐步優化**: 根據性能需求調整模型大小
3. **考慮部署**: 訓練時的模型不一定是部署時的模型(可以用知識蒸餾)
4. **實驗驗證**: 不同數據集最優架構可能不同,需要實驗對比

**本章小結**

恭喜!您已經掌握了CNN架構演進的核心知識:

✅ **演進歷程**: 從LeNet到EfficientNet的發展脈絡  
✅ **核心創新**: 每個架構的關鍵突破(ReLU, Dropout, 殘差連接等)  
✅ **選擇指南**: 根據應用場景選擇合適架構  
✅ **化工應用**: 了解各架構在化工領域的適用性  

**關鍵要點回顧**:

| 架構 | 核心貢獻 | 一句話總結 |
|------|---------|-----------|
| LeNet | 開創CNN | 證明CNN可行 |
| AlexNet | ReLU+Dropout | 引爆深度學習 |
| VGGNet | 小卷積核堆疊 | 深度的力量 |
| GoogLeNet | Inception模組 | 寬度的智慧 |
| ResNet | 殘差連接 | 突破深度極限 |
| MobileNet | 深度可分離卷積 | 輕量化革命 |
| EfficientNet | 複合縮放 | 系統化優化 |

> [!IMPORTANT]
> **記住**: 沒有「最好」的架構,只有「最適合」的架構。根據實際需求(準確率、速度、資源)選擇,並通過實驗驗證!

---

## 3. CNN應用場景

### 本章學習地圖

> [!IMPORTANT]
> **本章核心問題**: 什麼時候該用CNN?如何判斷CNN是否適合我的化工問題?

**學習目標**:
1. 🎯 **識別適用場景**: 知道何時應該使用CNN而非DNN或傳統方法
2. 🏭 **掌握化工應用**: 了解CNN在化工領域的6大典型應用
3. ⚖️ **權衡優劣**: 清楚CNN的優勢與限制
4. 🧭 **建立決策框架**: 學會系統化地選擇合適的模型

**為什麼化工人需要了解CNN應用場景?**

在化工領域,我們經常面臨各種數據分析任務:
- 有時需要分析影像(產品外觀、顯微結構)
- 有時需要分析時間序列(感測器數據)
- 有時需要分析表格數據(製程參數)

**選錯模型的代價**:
- ❌ 用CNN處理表格數據 → 過度複雜,效果不佳
- ❌ 用DNN處理影像數據 → 參數爆炸,訓練困難
- ❌ 用傳統方法處理複雜影像 → 特徵工程困難,準確度低

**本章架構**:

```
CNN適用性判斷 (3.1)
    ↓
化工領域應用案例 (3.2)
    ├─ 產品品質檢測
    ├─ 顯微影像分析
    ├─ 製程監控與異常檢測
    ├─ 光譜影像分析
    ├─ 安全監控
    └─ 材料結構分析
    ↓
CNN vs DNN vs 傳統方法 (3.3)
    ↓
優勢與限制 (3.4)
    ↓
決策框架 (3.5)
```

> [!TIP]
> 學習建議:重點理解「為什麼」要用CNN,而不是死記應用場景。理解原理後,你就能判斷新問題是否適合用CNN。

---

### 3.1 CNN適用性判斷

**核心原則**: CNN專為**具有空間結構或局部相關性**的數據設計

#### 3.1.1 CNN的三大適用特徵

**特徵1: 數據具有空間結構** 🗺️

**定義**: 數據點之間的相對位置有意義

**適合CNN的數據類型**:
- ✅ **2D影像**: 像素之間的空間關係重要
- ✅ **3D體積數據**: 如CT掃描、3D材料結構
- ✅ **時間序列**: 可視為1D空間數據
- ✅ **光譜影像**: 空間+光譜維度

**不適合CNN的數據類型**:
- ❌ **表格數據**: 特徵順序可任意調換
- ❌ **獨立測量值**: 沒有空間或時間關聯

**化工實例對比**:

| 數據類型 | 是否適合CNN | 原因 |
|---------|-----------|------|
| 產品表面影像 | ✅ 適合 | 缺陷位置和形狀有空間意義 |
| 顯微鏡照片 | ✅ 適合 | 晶體結構有空間排列 |
| 溫度場分布圖 | ✅ 適合 | 溫度梯度有空間相關性 |
| 光譜數據(單點) | ❌ 不適合 | 波長順序雖固定,但用1D CNN或DNN更好 |
| 製程參數表 | ❌ 不適合 | 溫度、壓力、流量等順序無關 |

**特徵2: 局部模式重要** 🔍

**定義**: 重要特徵存在於局部區域,且可能在不同位置重複出現

**化工範例**:
- ✅ **缺陷檢測**: 裂紋、氣泡、污點可能出現在任何位置
- ✅ **晶體識別**: 特定晶型的局部特徵
- ✅ **紋理分析**: 表面粗糙度的局部模式

**為什麼CNN有效?**
- **卷積核**: 像「特徵檢測器」,掃描整張影像
- **參數共享**: 同一個檢測器可以找到任何位置的特徵
- **平移不變性**: 缺陷在左上角或右下角都能被識別

**特徵3: 具有層次結構** 📊

**定義**: 複雜特徵由簡單特徵組合而成

**視覺化理解**:
```
原始影像
    ↓
第一層: 檢測邊緣、線條
    ↓
第二層: 組合成角點、簡單形狀
    ↓
第三層: 組合成複雜物體部件
    ↓
第四層: 識別完整物體
```

**化工實例**:
```
產品表面影像
    ↓
第一層: 檢測邊緣、紋理
    ↓
第二層: 識別局部缺陷(小裂紋、氣泡)
    ↓
第三層: 組合成缺陷模式
    ↓
第四層: 判斷整體品質等級
```

---

#### 3.1.2 適用場景快速判斷表

| 判斷標準 | 適合CNN | 說明 |
|---------|--------|------|
| **數據類型** | 影像、視頻、空間數據 | 具有2D/3D結構 |
| **數據量** | 數百張以上 | 數據越多,CNN優勢越明顯 |
| **空間相關性** | 鄰近像素相關 | 局部區域有意義 |
| **平移不變性** | 特徵位置不固定 | 同一特徵可能出現在任何位置 |
| **特徵複雜度** | 難以手動設計 | 自動學習特徵更有效 |
| **計算資源** | 有GPU支持 | CNN訓練需要較多計算資源 |

**詳細情境分析**:

#### 情境1: 影像數據分析 ✅

**特徵**: 輸入為2D影像(灰階或彩色)

**化工範例**:
- 產品外觀檢測(表面缺陷、顏色均勻度)
- 顯微影像分析(晶體形態、粒徑分布)
- 熱成像分析(溫度場分布、熱點檢測)
- 光學檢測(透明度、雜質檢測)

**為什麼CNN有效?**
- 自動提取空間特徵(邊緣、紋理、形狀)
- 不需要手動設計特徵提取器
- 對光照變化、輕微旋轉有一定魯棒性

**實例對比**:
```python
# 傳統方法: 需要手動設計特徵
features = [
    '平均灰度值',
    '標準差',
    '邊緣密度',
    '紋理特徵(GLCM)',
    '形狀特徵'
]
# 需要領域專家設計,耗時且可能遺漏重要特徵

# CNN方法: 自動學習特徵
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(2, activation='softmax')  # 正常/缺陷
])
# 端到端學習,自動發現最有用的特徵
```

#### 情境2: 空間模式識別 ✅

**特徵**: 需要識別特定的空間模式或紋理

**化工範例**:
- 材料表面紋理分類(光滑、粗糙、波紋)
- 結晶形態識別(針狀、片狀、塊狀)
- 流體流動模式(層流、紊流、氣泡流)
- 腐蝕類型識別(均勻腐蝕、點蝕、應力腐蝕)

**為什麼CNN有效?**
- 卷積核自動學習紋理特徵
- 池化層提供一定的尺度不變性
- 多層結構捕捉不同尺度的模式

#### 情境3: 大量影像數據可用 ✅

**特徵**: 有足夠的標註影像數據支持訓練

**數據量指南**:
| 數據規模 | 建議方法 | 說明 |
|---------|---------|------|
| < 100張 | 傳統機器學習 + 手工特徵 | CNN容易過擬合 |
| 100-500張 | 遷移學習(預訓練CNN微調) | 利用預訓練權重 |
| 500-5000張 | CNN + 數據增強 | 可以訓練較小的CNN |
| > 5000張 | 深層CNN | 充分發揮CNN潛力 |

**化工實例**:
- ✅ **適合**: 連續生產線的產品影像(每小時數百張)
- ✅ **適合**: 顯微鏡影像庫(數千張標註樣本)
- ⚠️ **需遷移學習**: 實驗室小批次樣本(數百張)
- ❌ **不適合**: 罕見故障案例(幾十張)

#### 情境4: 需要端到端學習 ✅

**特徵**: 難以手動設計有效的特徵提取器

**化工範例**:
- 複雜背景下的目標檢測
- 多類別缺陷同時識別
- 細微差異的品質分級
- 多模態影像融合分析

**為什麼CNN有效?**
- **自動特徵學習**: 不需要人工設計特徵
- **端到端優化**: 從原始影像直接到預測結果
- **適應性強**: 可以學習領域專家難以描述的特徵

**對比**:
```
傳統方法:
  原始影像 → [手工特徵工程] → 分類器 → 預測
  (需要領域專家,耗時,可能次優)

CNN方法:
  原始影像 → CNN → 預測
  (自動學習最優特徵組合)
```

---

### 3.2 化工領域應用案例

#### 3.2.1 產品品質檢測 🏭

**應用場景**: 自動檢測產品表面缺陷,替代人工目視檢查

**問題描述**:
- **輸入**: 產品表面影像(可見光、紅外、X光等)
- **輸出**: 缺陷類型分類或缺陷位置定位
- **目標**: 提高檢測速度和準確度,降低人力成本

**典型缺陷類型**:
- 裂紋(Crack)
- 劃痕(Scratch)
- 氣泡/孔洞(Bubble/Hole)
- 污點/雜質(Stain/Inclusion)
- 變形/凹陷(Deformation/Dent)
- 顏色不均(Color Variation)

**為什麼用CNN?**
- ✅ 缺陷可能出現在任何位置(平移不變性)
- ✅ 缺陷形態複雜,難以用規則描述
- ✅ 需要同時檢測多種缺陷類型
- ✅ 可以達到或超越人類檢測員的準確度

**實際案例**:

**案例A: 鋼板表面缺陷檢測**
- **輸入**: 1920×1080 灰階影像
- **輸出**: 6類缺陷分類 + 缺陷位置
- **模型**: ResNet-50 + FPN(特徵金字塔網路)
- **效果**: 準確率95%, 檢測速度0.1秒/張
- **效益**: 替代3名檢測員,漏檢率從5%降至0.5%

**案例B: 玻璃瓶缺陷檢測**
- **輸入**: 512×512 RGB影像(多角度拍攝)
- **輸出**: 正常/缺陷 二元分類
- **模型**: MobileNetV2(輕量化,適合邊緣部署)
- **效果**: 準確率98%, 速度50張/秒
- **效益**: 部署在產線邊緣設備,即時檢測

**案例C: 半導體晶圓缺陷檢測**
- **輸入**: 高解析度晶圓表面影像
- **輸出**: 像素級缺陷分割
- **模型**: U-Net(語義分割網路)
- **效果**: IoU=0.92, 可定位微米級缺陷
- **效益**: 提高良率,減少報廢

**實現範例**:

```python
# 產品缺陷檢測模型
from tensorflow.keras import models, layers

def build_defect_detector(input_shape=(512, 512, 1), num_classes=6):
    """
    建立產品缺陷檢測模型
    
    Args:
        input_shape: 輸入影像尺寸
        num_classes: 缺陷類別數(含正常類)
    """
    model = models.Sequential([
        # 第一個卷積塊: 提取低階特徵
        layers.Conv2D(32, (3, 3), activation='relu', 
                      padding='same', input_shape=input_shape),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),  # 256×256
        
        # 第二個卷積塊
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),  # 128×128
        
        # 第三個卷積塊
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),  # 64×64
        
        # 第四個卷積塊
        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),  # 32×32
        
        # 分類頭
        layers.GlobalAveragePooling2D(),  # 替代Flatten,減少參數
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ], name='DefectDetector')
    
    return model

# 建立模型
model = build_defect_detector()

# 編譯
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()
```

**實際效益**:
- 📈 檢測準確率提升: 人工85% → CNN 95%+
- ⏱️ 檢測速度: 人工5秒/件 → CNN 0.1秒/件
- 💰 成本節省: 減少人力成本50-80%
- 🎯 一致性: 消除人為主觀判斷差異

---

#### 3.2.2 顯微影像分析 🔬

**應用場景**: 分析顯微鏡下的材料微觀結構

**問題描述**:
- **輸入**: 光學顯微鏡、電子顯微鏡(SEM/TEM)影像
- **輸出**: 晶體形態分類、粒徑分布、相組成分析
- **目標**: 自動化微觀結構分析,替代人工測量

**典型分析任務**:
- 晶體形態識別(針狀、片狀、球狀、不規則)
- 粒徑分布統計
- 孔隙率測量
- 相分離檢測
- 晶界識別
- 缺陷計數

**為什麼用CNN?**
- ✅ 微觀結構複雜,難以用簡單規則描述
- ✅ 需要識別不同尺度的特徵
- ✅ 可以處理不同成像條件的影像
- ✅ 自動化分析,提高效率和客觀性

**實際案例**:

**案例A: 聚合物結晶形態分類**
- **輸入**: 偏光顯微鏡影像(512×512)
- **輸出**: 4類晶型(球晶、柱晶、片晶、無定形)
- **模型**: VGG-16遷移學習
- **數據**: 2000張標註影像
- **效果**: 準確率93%
- **效益**: 快速評估結晶條件對晶型的影響

**案例B: 金屬顯微組織分析**
- **輸入**: 金相顯微鏡影像
- **輸出**: 相組成比例(鐵素體、珠光體、麻田散鐵)
- **模型**: U-Net語義分割
- **效果**: 與人工測量相關係數R²=0.98
- **效益**: 自動化金相分析,節省90%時間

**案例C: 催化劑顆粒粒徑分布**
- **輸入**: SEM影像
- **輸出**: 每個顆粒的輪廓和粒徑
- **模型**: Mask R-CNN(實例分割)
- **效果**: 可準確分割重疊顆粒
- **效益**: 精確統計粒徑分布,優化製備條件

**實現範例**:

```python
# 晶體形態分類模型(使用遷移學習)
from tensorflow.keras.applications import VGG16
from tensorflow.keras import models, layers

def build_crystal_classifier(num_classes=4):
    """
    建立晶體形態分類模型(遷移學習)
    
    Args:
        num_classes: 晶型類別數
    """
    # 載入預訓練的VGG16(不含頂層)
    base_model = VGG16(
        weights='imagenet',
        include_top=False,
        input_shape=(224, 224, 3)
    )
    
    # 凍結預訓練層
    base_model.trainable = False
    
    # 建立新模型
    model = models.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ], name='CrystalClassifier')
    
    return model

# 建立模型
model = build_crystal_classifier()

# 編譯
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
```

**化工應用價值**:
- 🔬 自動化微觀分析,提高效率
- 📊 客觀量化,消除人為誤差
- 🔄 快速篩選最佳製備條件
- 📈 建立微觀結構與性能的關聯

---

#### 3.2.3 製程監控與異常檢測 ⚠️

**應用場景**: 透過視覺監控檢測製程異常

**問題描述**:
- **輸入**: 製程監控影像(反應器視窗、產線攝影機)
- **輸出**: 正常/異常分類,或異常類型識別
- **目標**: 即時檢測異常,預防事故

**典型監控對象**:
- 反應器內部狀態(起泡、分層、變色)
- 流體流動狀態(堵塞、洩漏、氣泡)
- 設備運轉狀態(振動、磨損、過熱)
- 產品外觀變化(顏色、形狀、尺寸)

**為什麼用CNN?**
- ✅ 異常模式複雜,難以用閾值判斷
- ✅ 需要即時處理視頻流
- ✅ 可以學習正常狀態的視覺特徵
- ✅ 對光照變化、角度變化有魯棒性

**實際案例**:

**案例A: 反應器起泡檢測**
- **輸入**: 反應器視窗攝影機(640×480, 30fps)
- **輸出**: 起泡程度(正常/輕微/嚴重)
- **模型**: 3D CNN(處理時間序列影像)
- **效果**: 準確率96%, 延遲<0.5秒
- **效益**: 提前預警,避免溢料事故

**案例B: 管道洩漏檢測**
- **輸入**: 紅外熱成像影像
- **輸出**: 洩漏位置定位
- **模型**: YOLO v5(目標檢測)
- **效果**: 可檢測微小洩漏(ΔT>2°C)
- **效益**: 早期發現洩漏,減少損失

**案例C: 結晶過程監控**
- **輸入**: 結晶器內部影像
- **輸出**: 晶體粒徑分布變化趨勢
- **模型**: CNN + LSTM(時序預測)
- **效果**: 提前10分鐘預測終點
- **效益**: 優化結晶時間,提高產品品質

**實現範例**:

```python
# 製程異常檢測模型
def build_anomaly_detector(input_shape=(224, 224, 3)):
    """
    建立製程異常檢測模型
    
    Args:
        input_shape: 輸入影像尺寸
    """
    model = models.Sequential([
        # 特徵提取
        layers.Conv2D(32, (3, 3), activation='relu', 
                      padding='same', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        
        # 分類
        layers.GlobalAveragePooling2D(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(3, activation='softmax')  # 正常/輕微異常/嚴重異常
    ], name='AnomalyDetector')
    
    return model

# 建立模型
model = build_anomaly_detector()

# 編譯(使用類別權重處理不平衡數據)
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy', 'precision', 'recall']
)
```

**實際效益**:
- 🛡️ 提前預警,避免事故
- ⏱️ 即時監控,24/7不間斷
- 💰 減少停機損失
- 📊 數據記錄,可追溯分析

---

#### 3.2.4 光譜影像分析 🌈

**應用場景**: 分析高光譜/多光譜影像,進行成分分析

**問題描述**:
- **輸入**: 高光譜影像(空間維度 + 光譜維度)
- **輸出**: 成分分布圖、濃度預測
- **目標**: 非破壞性成分分析

**光譜影像特點**:
- 每個像素包含完整光譜(數百個波長)
- 同時具有空間資訊和光譜資訊
- 數據維度高(如 512×512×200)

**為什麼用CNN?**
- ✅ 可以同時利用空間和光譜資訊
- ✅ 自動學習光譜特徵,無需手動選擇波長
- ✅ 可以檢測空間分布模式
- ✅ 端到端預測,簡化分析流程

**實際案例**:

**案例A: 藥品成分均勻度檢測**
- **輸入**: 近紅外高光譜影像(NIR-HSI)
- **輸出**: 活性成分濃度分布圖
- **模型**: 3D CNN(空間+光譜)
- **效果**: 濃度預測RMSE<1%
- **效益**: 非破壞檢測,確保藥品品質

**案例B: 食品摻假檢測**
- **輸入**: 可見光-近紅外高光譜影像
- **輸出**: 摻假物質識別和定位
- **模型**: CNN + SVM混合模型
- **效果**: 檢測限<0.5%
- **效益**: 快速篩查,保障食品安全

**案例C: 礦石成分分析**
- **輸入**: 短波紅外高光譜影像
- **輸出**: 礦物組成分布
- **模型**: ResNet-based 3D CNN
- **效果**: 分類準確率92%
- **效益**: 即時分析,優化選礦流程

**實現範例**:

```python
# 高光譜影像分析模型
def build_hyperspectral_model(input_shape=(64, 64, 200), num_classes=5):
    """
    建立高光譜影像分析模型
    
    Args:
        input_shape: (H, W, Bands) 空間尺寸 + 光譜波段數
        num_classes: 成分類別數
    """
    model = models.Sequential([
        # 光譜維度降維
        layers.Conv2D(64, (1, 1), activation='relu', input_shape=input_shape),
        
        # 空間特徵提取
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        
        # 分類
        layers.GlobalAveragePooling2D(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ], name='HyperspectralClassifier')
    
    return model
```

**化工應用價值**:
- 🔬 非破壞性成分分析
- 📊 空間分布可視化
- ⏱️ 快速檢測(秒級)
- 💰 減少化學分析成本

---

#### 3.2.5 安全監控 🔒

**應用場景**: 化工廠區安全監控,檢測違規行為和危險狀況

**問題描述**:
- **輸入**: 監控攝影機影像/視頻
- **輸出**: 安全事件檢測和報警
- **目標**: 提高安全管理水平,預防事故

**典型監控任務**:
- 人員未穿戴防護裝備(安全帽、防護服、口罩)
- 人員進入危險區域
- 煙霧/火焰檢測
- 洩漏物檢測
- 異常行為識別(跌倒、打鬥)

**為什麼用CNN?**
- ✅ 可以識別複雜的視覺模式
- ✅ 對遮擋、角度變化有魯棒性
- ✅ 可以即時處理多路視頻流
- ✅ 減少人力監控成本

**實際案例**:

**案例A: 安全帽佩戴檢測**
- **輸入**: 廠區監控視頻(1080p, 25fps)
- **輸出**: 人員位置 + 是否佩戴安全帽
- **模型**: YOLOv5(目標檢測)
- **效果**: 準確率98%, 速度30fps
- **效益**: 自動監控,違規即時報警

**案例B: 煙霧火焰檢測**
- **輸入**: 多點監控攝影機
- **輸出**: 煙霧/火焰位置和嚴重程度
- **模型**: Faster R-CNN
- **效果**: 檢測延遲<2秒, 誤報率<1%
- **效益**: 早期預警,爭取滅火時間

**案例C: 危險區域入侵檢測**
- **輸入**: 重點區域監控視頻
- **輸出**: 人員入侵報警
- **模型**: CNN + 光流法(動態檢測)
- **效果**: 檢測率99%, 誤報率<0.5%
- **效益**: 防止無關人員進入危險區域

**實現範例**:

```python
# 安全帽檢測模型(簡化版)
def build_safety_helmet_detector(input_shape=(416, 416, 3)):
    """
    建立安全帽檢測模型
    
    實際應用建議使用YOLO或Faster R-CNN等目標檢測框架
    這裡展示簡化的分類版本
    """
    model = models.Sequential([
        # 特徵提取(使用預訓練模型)
        layers.Conv2D(32, (3, 3), activation='relu', 
                      padding='same', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        
        # 分類
        layers.GlobalAveragePooling2D(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(2, activation='softmax')  # 佩戴/未佩戴
    ], name='HelmetDetector')
    
    return model
```

**實際效益**:
- 🛡️ 提高安全管理水平
- 👁️ 24/7不間斷監控
- ⚡ 即時報警,快速響應
- 💰 減少安全事故損失

---

#### 3.2.6 材料結構分析 🧱

**應用場景**: 分析材料的微觀或介觀結構

**問題描述**:
- **輸入**: CT掃描、X光影像、3D重建影像
- **輸出**: 結構特徵量化、缺陷檢測
- **目標**: 理解結構-性能關係

**典型分析任務**:
- 孔隙結構分析(孔隙率、連通性、孔徑分布)
- 纖維取向分析(複合材料)
- 裂紋擴展追蹤
- 相分布分析(多相材料)
- 3D結構重建

**為什麼用CNN?**
- ✅ 可以處理3D體積數據
- ✅ 自動提取複雜的結構特徵
- ✅ 可以學習結構-性能關聯
- ✅ 加速材料設計流程

**實際案例**:

**案例A: 多孔材料孔隙分析**
- **輸入**: X-ray CT 3D影像
- **輸出**: 孔隙率、孔徑分布、連通性
- **模型**: 3D U-Net(體積分割)
- **效果**: 分割準確率95%
- **效益**: 自動化孔隙分析,優化材料設計

**案例B: 複合材料纖維取向**
- **輸入**: 顯微CT影像
- **輸出**: 纖維取向分布
- **模型**: 3D CNN + 方向預測
- **效果**: 角度預測誤差<5°
- **效益**: 預測機械性能,優化製程

**案例C: 焊縫缺陷檢測**
- **輸入**: X光檢測影像
- **輸出**: 缺陷類型(氣孔、夾渣、裂紋)和位置
- **模型**: Mask R-CNN
- **效果**: 檢測準確率97%
- **效益**: 自動化無損檢測,提高效率

**實現範例**:

```python
# 3D材料結構分析模型
from tensorflow.keras import layers, models

def build_3d_structure_analyzer(input_shape=(64, 64, 64, 1)):
    """
    建立3D材料結構分析模型
    
    Args:
        input_shape: (D, H, W, C) 3D體積數據
    """
    model = models.Sequential([
        # 3D卷積層
        layers.Conv3D(32, (3, 3, 3), activation='relu', 
                      padding='same', input_shape=input_shape),
        layers.MaxPooling3D((2, 2, 2)),
        
        layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same'),
        layers.MaxPooling3D((2, 2, 2)),
        
        layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same'),
        layers.MaxPooling3D((2, 2, 2)),
        
        # 全局特徵
        layers.GlobalAveragePooling3D(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(1)  # 回歸輸出(如孔隙率)
    ], name='3DStructureAnalyzer')
    
    return model
```

**化工應用價值**:
- 🔬 深入理解材料結構
- 📊 量化結構參數
- 🔄 加速材料開發
- 💡 建立結構-性能關聯

---

### 3.3 CNN vs DNN vs 傳統方法

**全面對比表**:

| 特性 | CNN | DNN | 傳統機器學習 | 傳統影像處理 |
|------|-----|-----|------------|------------|
| **適用數據** | 影像、空間數據 | 表格數據 | 表格數據 | 影像 |
| **特徵提取** | 自動學習 | 自動學習 | 手動設計 | 手動設計 |
| **參數量** | 中等(參數共享) | 大(全連接) | 小 | 無(規則based) |
| **訓練數據需求** | 數百-數千張 | 數百-數千筆 | 數十-數百筆 | 無需訓練 |
| **訓練時間** | 小時-天(需GPU) | 分鐘-小時 | 秒-分鐘 | 無 |
| **推理速度** | 快(毫秒級) | 快(毫秒級) | 快 | 快 |
| **準確度** | 高 | 高 | 中-高 | 低-中 |
| **可解釋性** | 低 | 低 | 中-高 | 高 |
| **泛化能力** | 強 | 強 | 中 | 弱 |
| **對新場景適應** | 需重訓練 | 需重訓練 | 需重訓練 | 需重新設計規則 |

**化工應用選擇指南**:

| 應用場景 | 推薦方法 | 原因 |
|---------|---------|------|
| **產品外觀檢測** | CNN ✅ | 影像數據,缺陷模式複雜 |
| **顯微結構分析** | CNN ✅ | 影像數據,需要多尺度特徵 |
| **製程參數優化** | DNN ✅ | 表格數據,非線性關係 |
| **品質預測(表格數據)** | DNN或RF | 取決於數據量和非線性程度 |
| **簡單閾值檢測** | 傳統影像處理 ✅ | 規則明確,無需訓練 |
| **小數據集分類** | 傳統ML(RF, SVM) ✅ | 數據少,CNN易過擬合 |
| **即時邊緣計算** | MobileNet(輕量CNN) ✅ | 需要平衡準確度和速度 |
| **高可解釋性需求** | 傳統ML + 特徵工程 ✅ | 需要理解決策過程 |

**決策樹**:

```
開始評估問題
    │
    ├─ 數據類型是什麼?
    │   ├─ 影像/視頻 → 繼續
    │   └─ 表格數據 → 使用 DNN 或傳統ML
    │
    ├─ 影像數據量是否充足 (>200張)?
    │   ├─ 否 → 遷移學習 或 傳統影像處理
    │   └─ 是 → 繼續
    │
    ├─ 特徵是否複雜,難以手動設計?
    │   ├─ 否 → 傳統影像處理 + 傳統ML
    │   └─ 是 → 繼續
    │
    ├─ 是否需要高準確度?
    │   ├─ 否 → 考慮簡單方法
    │   └─ 是 → 繼續
    │
    ├─ 計算資源是否充足?
    │   ├─ 否 → 輕量級CNN(MobileNet)
    │   └─ 是 → 使用 CNN ✅
```

---

### 3.4 CNN的優勢與限制

**優勢** ✅:

| 優勢 | 說明 | 化工應用價值 |
|-----|------|------------|
| **自動特徵學習** | 不需要手動設計特徵提取器 | 減少領域知識依賴,加速開發 |
| **平移不變性** | 特徵位置改變不影響識別 | 適合缺陷檢測(缺陷可能在任何位置) |
| **參數共享** | 同一濾波器掃描全圖,參數少 | 相比DNN減少100-1000倍參數 |
| **層次特徵** | 自動學習從低階到高階特徵 | 可以識別複雜的視覺模式 |
| **強大的表示能力** | 可以逼近複雜的視覺函數 | 適合複雜影像分析任務 |
| **遷移學習** | 可以利用預訓練模型 | 小數據集也能獲得好效果 |
| **端到端學習** | 從原始影像到預測結果 | 簡化分析流程 |

**限制** ❌:

| 限制 | 說明 | 應對策略 |
|-----|------|---------| | **需要大量標註數據** | 通常需要數百到數千張標註影像 | 數據增強、遷移學習、主動學習 |
| **計算資源需求高** | 訓練需要GPU,時間長 | 使用雲端GPU、輕量化模型 |
| **黑盒模型** | 難以解釋為什麼做出某個預測 | 使用CAM、Grad-CAM等可視化工具 |
| **對數據品質敏感** | 標註錯誤、影像品質差會影響性能 | 嚴格的數據清洗和品質控制 |
| **過擬合風險** | 小數據集容易過擬合 | Dropout、數據增強、正則化 |
| **對抗樣本脆弱** | 微小擾動可能導致錯誤預測 | 對抗訓練、集成方法 |
| **訓練不穩定** | 超參數敏感,可能陷入局部最優 | 多次訓練、自動調參 |
| **部署成本** | 模型大,推理可能需要GPU | 模型壓縮、量化、剪枝 |

**何時不該用CNN?**

❌ **影像數據太少** (<100張,且無法遷移學習)
- 改用: 傳統影像處理 + 傳統機器學習

❌ **問題可用簡單規則解決**
- 改用: 傳統影像處理(閾值、邊緣檢測等)

❌ **數據不是影像**
- 改用: DNN(表格數據)、RNN(時間序列)

❌ **需要強可解釋性**
- 改用: 傳統機器學習 + 手工特徵

❌ **即時性要求極高且資源受限** (微秒級,無GPU)
- 改用: 簡單模型或查表法

❌ **標註成本過高**
- 考慮: 無監督學習、弱監督學習

---

### 3.5 決策框架:該用CNN還是其他方法?

**系統化決策流程**:

```
第1步: 評估數據類型
    │
    ├─ 是否為影像/視頻/空間數據?
    │   ├─ 否 → 不適合CNN,考慮DNN或傳統ML
    │   └─ 是 → 進入第2步
    │
第2步: 評估數據量
    │
    ├─ 標註影像數量?
    │   ├─ < 100張 → 考慮遷移學習或傳統方法
    │   ├─ 100-500張 → 使用遷移學習 + 數據增強
    │   ├─ 500-5000張 → 可以訓練CNN
    │   └─ > 5000張 → 充分發揮CNN潛力
    │
第3步: 評估問題複雜度
    │
    ├─ 特徵是否複雜,難以手動設計?
    │   ├─ 否 → 傳統影像處理可能更簡單
    │   └─ 是 → 進入第4步
    │
第4步: 評估資源約束
    │
    ├─ 是否有GPU用於訓練?
    │   ├─ 否 → 考慮輕量級模型或雲端訓練
    │   └─ 是 → 進入第5步
    │
第5步: 評估部署需求
    │
    ├─ 推理速度要求?
    │   ├─ 即時(>30fps) → 使用輕量級CNN(MobileNet)
    │   ├─ 快速(1-10fps) → 標準CNN
    │   └─ 批次處理 → 可用深層CNN
    │
第6步: 評估可解釋性需求
    │
    ├─ 是否需要強可解釋性?
    │   ├─ 是 → 考慮傳統ML + 可視化工具
    │   └─ 否 → 使用 CNN ✅
```

**實用建議**:

1. **先簡單後複雜**:
   ```
   傳統影像處理 → 傳統ML + 手工特徵 → 遷移學習 → 從頭訓練CNN
   ```
   建立基準線(baseline),逐步提升

2. **對比實驗**:
   ```python
   # 同時嘗試多種方法
   methods = {
       'Traditional': traditional_method(),
       'Transfer Learning': vgg16_transfer(),
       'Custom CNN': custom_cnn()
   }
   # 比較性能,選擇最佳
   ```

3. **考慮實際部署**:
   - 訓練時間是否可接受?
   - 推理速度是否滿足需求?
   - 模型大小是否適合部署環境?
   - 是否需要邊緣設備部署?

4. **數據增強策略**:
   ```python
   # 小數據集必備
   from tensorflow.keras.preprocessing.image import ImageDataGenerator
   
   datagen = ImageDataGenerator(
       rotation_range=20,
       width_shift_range=0.2,
       height_shift_range=0.2,
       horizontal_flip=True,
       zoom_range=0.2
   )
   ```

5. **遷移學習優先**:
   ```python
   # 數據量<1000時,優先使用遷移學習
   base_model = VGG16(weights='imagenet', include_top=False)
   base_model.trainable = False  # 凍結預訓練層
   ```

---

**本章小結**

恭喜!您已經掌握了CNN應用場景的核心知識:

✅ **識別適用場景**: 知道何時該用CNN(影像數據、空間結構、局部模式)  
✅ **化工應用案例**: 了解6大典型應用(品質檢測、顯微分析、製程監控、光譜分析、安全監控、材料分析)  
✅ **權衡優劣**: 清楚CNN的優勢(自動特徵學習、平移不變性)與限制(數據需求、計算成本)  
✅ **決策框架**: 建立了選擇模型的系統化方法  

**關鍵要點回顧**:

| 應用領域 | 典型問題 | CNN優勢 | 數據需求 |
|---------|---------|---------|---------|
| 品質檢測 | 產品缺陷識別 | 自動特徵提取,平移不變 | 數百-數千張 |
| 顯微分析 | 晶體形態分類 | 多尺度特徵學習 | 數百張(可遷移學習) |
| 製程監控 | 異常狀態檢測 | 即時處理,魯棒性強 | 數千張 |
| 光譜分析 | 成分分布預測 | 空間+光譜聯合分析 | 數百張 |
| 安全監控 | 違規行為檢測 | 目標檢測,即時性好 | 數千張 |
| 材料分析 | 3D結構量化 | 處理體積數據 | 數百個3D樣本 |

> [!IMPORTANT]
> **記住三個原則**:
> 1. **先評估再選擇**: 不要盲目使用CNN,先判斷是否適合
> 2. **建立基準線**: 先用簡單方法,再考慮CNN
> 3. **實用為王**: 最好的模型是能解決實際問題的模型,不一定是最複雜的

---

## 4. 使用Keras建立CNN模型

### 本章學習地圖

> [!IMPORTANT]
> **本章核心問題**: 如何使用Keras快速建立和配置CNN模型?

**學習目標**:
1. 🎯 **掌握Keras層**: 了解CNN常用層的功能和參數
2. 🔧 **學會建立模型**: 掌握Sequential和Functional API
3. 📊 **理解參數計算**: 知道如何計算和優化模型複雜度
4. 🏭 **應用於化工**: 將理論轉化為實際化工影像分析代碼

**為什麼學習Keras?**

Keras是TensorFlow的高階API,具有以下優勢:
- ✅ **簡潔易用**: 幾行代碼就能建立複雜模型
- ✅ **模組化設計**: 像堆積木一樣組合層
- ✅ **功能強大**: 支援各種進階功能
- ✅ **社群活躍**: 豐富的預訓練模型和教程

**本章架構**:

```
導入模組 (4.1)
    ↓
CNN常用層詳解 (4.2)
    ├─ Conv2D (卷積層)
    ├─ MaxPooling2D (池化層)
    ├─ Flatten (展平層)
    ├─ Dense (全連接層)
    ├─ Dropout (正則化)
    └─ BatchNormalization (批次正規化)
    ↓
建立模型 (4.3)
    ├─ Sequential API (簡單)
    ├─ Functional API (靈活)
    └─ 參數計算 (優化)
```

> [!TIP]
> 學習建議:先理解每個層的作用,再學習如何組合它們。動手實踐是最好的學習方式!

---

### 4.1 導入必要的模組

**基本導入**:

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models

# 常用層的直接導入
from tensorflow.keras.layers import (
    Conv2D, MaxPooling2D, AveragePooling2D,
    Flatten, Dense, Dropout, BatchNormalization
)

# 檢查TensorFlow版本
print(f"TensorFlow版本: {tf.__version__}")

# 檢查GPU可用性
print(f"GPU可用: {tf.config.list_physical_devices('GPU')}")
```

**化工應用常用的額外模組**:

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 影像處理
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 模型評估
from sklearn.metrics import classification_report, confusion_matrix
```

---

### 4.2 CNN常用的層 (Layers)

#### 4.2.1 卷積層 (Conv2D)

**功能**: 對輸入進行二維卷積運算,提取空間特徵

**主要參數**:

| 參數 | 說明 | 常用值 | 化工應用建議 |
|------|------|--------|------------|
| ` | 卷積核數量 | 32, 64, 128 | 影像複雜度決定 |
| ` | 卷積核尺寸 | (3,3), (5,5) | 3×3最常用 |
| ` | 步長 | (1,1), (2,2) | 預設(1,1) |
| ` | 填充方式 | 'valid', 'same' | 'same'保留尺寸 |
| ` | 激活函數 | 'relu' | 隱藏層用relu |
| ` | 輸入形狀 | (H, W, C) | 僅第一層需要 |

**使用範例**:

```python
# 第一個卷積層 (必須指定input_shape)
layers.Conv2D(
    filters=32,                    # 32個濾波器
    kernel_size=(3, 3),            # 3×3卷積核
    activation='relu',             # ReLU激活
    padding='same',                # 保持尺寸
    input_shape=(224, 224, 3)      # 輸入: 224×224 RGB影像
)

# 後續卷積層 (自動推斷輸入形狀)
layers.Conv2D(64, (3, 3), activation='relu', padding='same')
```

**輸出形狀計算**:

$$
O = \begin{cases}
\lfloor \frac{W - K}{S} \rfloor + 1 & \text{if padding='valid'} \\
\lceil \frac{W}{S} \rceil & \text{if padding='same'}
\end{cases}
$$

**計算範例**:
```python
# 範例: 224×224 輸入, 3×3卷積核
# padding='same', stride=1
# 輸出: 224×224 (尺寸不變)

# padding='valid', stride=1
# 輸出: (224-3)/1 + 1 = 222×222

# padding='same', stride=2
# 輸出: 224/2 = 112×112
```

**化工應用示例**:

```python
# 產品表面缺陷檢測
# 輸入: 512×512 灰階影像
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', 
                  padding='same', input_shape=(512, 512, 1)),
    # 輸出: 512×512×32 (32個特徵圖)
])
```

> [!TIP]
> **Padding選擇建議**:
> - 影像邊緣有重要資訊(如缺陷可能在邊緣) → 使用 `
> - 想要快速降維 → 使用 `
> - 不確定時 → 使用 ` (現代網路的標準做法)

**常見錯誤與解決方案**:

> [!WARNING]
> **錯誤1: 輸入形狀不匹配**
> ```python
> # 錯誤: 忘記指定input_shape
> layers.Conv2D(32, (3, 3), activation='relu')  # 第一層會報錯!
> 
> # 正確: 第一層必須指定input_shape
> layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3))
> ```

> [!WARNING]
> **錯誤2: 通道數不匹配**
> ```python
> # 化工案例: 灰階影像但指定3通道
> # 錯誤: 灰階影像應該是1通道,不是3通道
> model.fit(grayscale_images, ...)  # 影像shape=(N, 224, 224, 1)
> # 但模型期望input_shape=(224, 224, 3)
> 
> # 解決: 確保輸入通道數與模型一致
> input_shape=(224, 224, 1)  # 灰階影像
> # 或
> input_shape=(224, 224, 3)  # RGB影像
> ```

> [!CAUTION]
> **錯誤3: 濾波器數量過多導致過擬合**
> 
> 化工小數據集常見問題:
> ```python
> # 不好: 數據只有200張,但使用太多濾波器
> layers.Conv2D(256, (3, 3), ...)  # 參數太多!
> 
> # 更好: 小數據集使用較少濾波器
> layers.Conv2D(32, (3, 3), ...)   # 從小開始
> ```

---

#### 4.2.2 池化層 (MaxPooling2D / AveragePooling2D)

**功能**: 降低特徵圖的空間維度,減少參數量

**MaxPooling2D (最大池化)**:

```python
layers.MaxPooling2D(
    pool_size=(2, 2),    # 池化窗口大小
    strides=None,        # 預設與pool_size相同
    padding='valid'      # 預設不填充
)
```

**效果**: 2×2池化窗口 → 特徵圖尺寸減半

**AveragePooling2D (平均池化)**:

```python
layers.AveragePooling2D(pool_size=(2, 2))
```

**對比表**:

| 特性 | MaxPooling | AveragePooling | 化工應用場景 |
|------|-----------|----------------|------------|
| **保留資訊** | 最強特徵 | 平均特徵 | - |
| **適用任務** | 分類 | 需要平滑輸出 | - |
| **對雜訊** | 可能選中雜訊 | 平均化雜訊 | - |
| **化工實例** | 缺陷檢測(找最嚴重的) | 溫度場分析(區域平均) | 根據任務選擇 |

**使用範例**:

```python
# 標準做法: 卷積後接池化
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),  # 224×224 → 112×112
    
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),  # 112×112 → 56×56
])
```

> [!WARNING]
> **池化的代價**: 會丟失空間細節
> - 如果任務需要精確定位(如像素級分割) → 謹慎使用池化
> - 現代架構傾向用步長卷積(strided convolution)替代池化

---

#### 4.2.3 展平層 (Flatten)

**功能**: 將多維特徵圖展平為一維向量,連接卷積層和全連接層

**使用範例**:

```python
layers.Flatten()
```

**形狀轉換**:
```
輸入: (batch_size, 7, 7, 64)
輸出: (batch_size, 3136)
計算: 7 × 7 × 64 = 3136
```

**完整範例**:

```python
model = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),  # 14×14×64
    layers.Conv2D(64, (3, 3), activation='relu'),  # 12×12×64
    layers.MaxPooling2D((2, 2)),  # 6×6×64
    
    layers.Flatten(),  # 6×6×64 = 2304
    layers.Dense(128, activation='relu'),
    layers.Dense(10, activation='softmax')
])
```

---

#### 4.2.4 全連接層 (Dense)

**功能**: 標準的全連接神經網路層

**主要參數**:

```python
layers.Dense(
    units=128,           # 神經元數量
    activation='relu',   # 激活函數
    use_bias=True        # 是否使用偏差項(預設True)
)
```

**激活函數選擇**:

| 層類型 | 激活函數 | 說明 |
|--------|---------|------|
| 隱藏層 | ` | 標準選擇 |
| 二元分類輸出 | ` | 輸出0~1機率 |
| 多類別輸出 | ` | 輸出機率分布 |
| 回歸輸出 | ` 或 ` | 輸出任意實數 |

**化工應用範例**:

```python
# 產品品質三分類 (A/B/C級)
model = models.Sequential([
    # ... 卷積層 ...
    layers.Flatten(),
    layers.Dense(128, activation='relu'),  # 隱藏層
    layers.Dense(3, activation='softmax')  # 3類別輸出
])

# 產品參數回歸預測
model = models.Sequential([
    # ... 卷積層 ...
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)  # 回歸輸出 (如預測溫度)
])
```

---

#### 4.2.5 Dropout層

**功能**: 隨機丟棄神經元,防止過擬合

**使用範例**:

```python
layers.Dropout(rate=0.5)  # 丟棄50%神經元
```

**放置位置**: 通常放在全連接層之間

```python
model = models.Sequential([
    # ... 卷積層 ...
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),  # 第一個Dropout
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),  # 第二個Dropout (可以用不同比例)
    layers.Dense(10, activation='softmax')
])
```

**Dropout比例建議**:

| 數據量 | 建議Dropout率 | 說明 |
|--------|--------------|------|
| 大數據集 (>10000) | 0.2-0.3 | 輕度正則化 |
| 中數據集 (1000-10000) | 0.3-0.5 | 標準正則化 |
| 小數據集 (<1000) | 0.5-0.7 | 強正則化 |

> [!NOTE]
> **Dropout的工作機制**:
> - 訓練時: 隨機丟棄指定比例的神經元
> - 預測時: 使用所有神經元,但輸出會自動縮放
> - Keras會自動處理這個切換,無需手動設置

---

#### 4.2.6 批次正規化層 (BatchNormalization)

**功能**: 對每個批次的數據進行正規化,加速訓練

**使用範例**:

```python
layers.BatchNormalization()
```

**放置位置**: 通常放在卷積/全連接層之後,激活函數之前

```python
# 標準做法
model = models.Sequential([
    layers.Conv2D(32, (3, 3), padding='same', input_shape=(224, 224, 3)),
    layers.BatchNormalization(),  # 在激活前
    layers.Activation('relu'),
    layers.MaxPooling2D((2, 2)),
])

# 簡化寫法 (激活函數寫在Conv2D裡)
model = models.Sequential([
    layers.Conv2D(32, (3, 3), padding='same', input_shape=(224, 224, 3)),
    layers.BatchNormalization(),
    layers.Activation('relu'),  # 或直接在Conv2D中指定activation
    layers.MaxPooling2D((2, 2)),
])
```

**優點**:
- ✅ 加速收斂 (可以使用更大的學習率)
- ✅ 減少對初始化的敏感性
- ✅ 具有一定的正則化效果
- ✅ 允許訓練更深的網路

---

### 4.3 建立CNN模型

#### 4.3.1 使用Sequential API

**適用場景**: 線性堆疊的模型(最常見)

**完整範例: MNIST手寫數字識別**

```python
from tensorflow.keras import models, layers

model = models.Sequential([
    # 第一個卷積塊: 提取低階特徵
    layers.Conv2D(32, (3, 3), activation='relu', 
                  input_shape=(28, 28, 1), padding='same'),
    layers.MaxPooling2D((2, 2)),  # 28×28 → 14×14
    
    # 第二個卷積塊: 提取中階特徵
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2)),  # 14×14 → 7×7
    
    # 第三個卷積塊: 提取高階特徵
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    
    # 分類頭
    layers.Flatten(),  # 7×7×64 = 3136
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(10, activation='softmax')  # 10類別
])

# 查看模型結構
model.summary()
```

**化工應用範例: 產品缺陷檢測**

```python
# 輸入: 512×512 灰階影像
# 輸出: 二元分類 (正常/缺陷)

model = models.Sequential([
    # 卷積塊1
    layers.Conv2D(32, (3, 3), activation='relu', 
                  input_shape=(512, 512, 1), padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),  # 256×256
    
    # 卷積塊2
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),  # 128×128
    
    # 卷積塊3
    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),  # 64×64
    
    # 卷積塊4
    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),  # 32×32
    
    # 分類頭
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(1, activation='sigmoid')  # 二元分類
], name='DefectDetector')

model.summary()
```

---

#### 4.3.2 使用Functional API

**適用場景**: 複雜模型(多輸入、多輸出、殘差連接)

**基本範例**:

```python
from tensorflow import keras
from tensorflow.keras import layers

# 定義輸入
inputs = keras.Input(shape=(28, 28, 1))

# 構建網路
x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
x = layers.MaxPooling2D((2, 2))(x)

x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)
x = layers.MaxPooling2D((2, 2))(x)

x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)

x = layers.Flatten()(x)
x = layers.Dense(64, activation='relu')(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(10, activation='softmax')(x)

# 創建模型
model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')

model.summary()
```

**進階範例: 殘差連接**

```python
def residual_block(x, filters):
    """殘差塊"""
    # 主路徑
    fx = layers.Conv2D(filters, (3, 3), padding='same')(x)
    fx = layers.BatchNormalization()(fx)
    fx = layers.Activation('relu')(fx)
    
    fx = layers.Conv2D(filters, (3, 3), padding='same')(fx)
    fx = layers.BatchNormalization()(fx)
    
    # 跳躍連接
    out = layers.Add()([fx, x])  # 殘差連接
    out = layers.Activation('relu')(out)
    
    return out

# 使用殘差塊建立模型
inputs = keras.Input(shape=(224, 224, 3))

x = layers.Conv2D(64, (7, 7), strides=2, padding='same')(inputs)
x = layers.BatchNormalization()(x)
x = layers.Activation('relu')(x)
x = layers.MaxPooling2D((3, 3), strides=2, padding='same')(x)

# 堆疊殘差塊
x = residual_block(x, 64)
x = residual_block(x, 64)
x = residual_block(x, 64)

x = layers.GlobalAveragePooling2D()(x)
outputs = layers.Dense(1000, activation='softmax')(x)

model = keras.Model(inputs=inputs, outputs=outputs, name='resnet_like')
```

---

#### 4.3.3 參數計算詳解

**為什麼要關心參數量?**

1. **過擬合風險**: 參數越多,越容易過擬合
2. **訓練時間**: 參數越多,訓練越慢
3. **部署成本**: 參數越多,模型越大,推論越慢

**卷積層參數公式**:

$$
\text{Params} = (K_h \times K_w \times C_{\text{in}} + 1) \times C_{\text{out}}
$$

**全連接層參數公式**:

$$
\text{Params} = (N_{\text{in}} + 1) \times N_{\text{out}}
$$

**實際計算範例**:

```python
# 建立模型
model = models.Sequential([
    layers.Conv2D(32, (3, 3), input_shape=(28, 28, 1)),  # Layer 1
    layers.MaxPooling2D((2, 2)),                          # Layer 2
    layers.Conv2D(64, (3, 3)),                            # Layer 3
    layers.MaxPooling2D((2, 2)),                          # Layer 4
    layers.Flatten(),                                     # Layer 5
    layers.Dense(128),                                    # Layer 6
    layers.Dense(10)                                      # Layer 7
])

model.summary()
```

**輸出解讀**:

```
Layer 1 (Conv2D):
  參數 = (3×3×1 + 1) × 32 = 320

Layer 2 (MaxPooling2D):
  參數 = 0 (池化層沒有可學習參數)

Layer 3 (Conv2D):
  參數 = (3×3×32 + 1) × 64 = 18,496

Layer 4 (MaxPooling2D):
  參數 = 0

Layer 5 (Flatten):
  參數 = 0

Layer 6 (Dense):
  輸入 = 5×5×64 = 1600
  參數 = (1600 + 1) × 128 = 204,928

Layer 7 (Dense):
  參數 = (128 + 1) × 10 = 1,290

總參數 = 320 + 18,496 + 204,928 + 1,290 = 225,034
```

**關鍵觀察**:

| 層類型 | 參數量 | 佔比 | 啟示 |
|--------|--------|------|------|
| Conv2D | 18,816 | 8.4% | 卷積層參數少 |
| Dense | 206,218 | 91.6% | 全連接層佔主導 |

**優化策略**:

1. **減少全連接層**: 使用Global Average Pooling替代Flatten+Dense
2. **使用深度可分離卷積**: 參數量減少8-9倍
3. **減少濾波器數量**: 在保證性能的前提下減少filters

---

### 4.4 化工應用完整範例

#### 4.4.1 產品缺陷檢測系統

**應用場景**: 建立一個完整的產品表面缺陷檢測系統

**問題定義**:
- **輸入**: 512×512 灰階影像
- **輸出**: 5類別分類(正常、裂紋、劃痕、氣泡、污點)
- **數據**: 1000張標註影像
- **目標**: 準確率>95%, 推理速度<100ms

**完整實現**:

```python
import tensorflow as tf
from tensorflow.keras import models, layers
import numpy as np
import matplotlib.pyplot as plt

# ========== 1. 數據準備 ==========
def load_and_preprocess_data():
    """
    載入和預處理化工產品影像數據
    """
    # 假設數據已經載入
    # X_train shape: (800, 512, 512, 1)
    # y_train shape: (800, 5) - one-hot encoded
    # X_val shape: (100, 512, 512, 1)
    # y_val shape: (100, 5)
    # X_test shape: (100, 512, 512, 1)
    # y_test shape: (100, 5)
    
    # 數據正規化 (重要!)
    X_train = X_train.astype('float32') / 255.0
    X_val = X_val.astype('float32') / 255.0
    X_test = X_test.astype('float32') / 255.0
    
    return (X_train, y_train), (X_val, y_val), (X_test, y_test)

# ========== 2. 建立模型 ==========
def build_defect_detector():
    """
    建立產品缺陷檢測CNN模型
    
    設計考量:
    - 小數據集(1000張) → 使用較少濾波器,加強正則化
    - 高解析度(512×512) → 使用多層池化降維
    - 5類別 → 使用softmax輸出
    """
    model = models.Sequential([
        # ===== 第一個卷積塊: 提取低階特徵(邊緣、紋理) =====
        layers.Conv2D(32, (3, 3), activation='relu', 
                      padding='same', input_shape=(512, 512, 1)),
        layers.BatchNormalization(),  # 加速訓練
        layers.MaxPooling2D((2, 2)),  # 512→256
        
        # ===== 第二個卷積塊: 提取中階特徵(局部模式) =====
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),  # 256→128
        
        # ===== 第三個卷積塊: 提取高階特徵(缺陷模式) =====
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),  # 128→64
        
        # ===== 第四個卷積塊: 深層特徵 =====
        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),  # 64→32
        
        # ===== 分類頭 =====
        layers.GlobalAveragePooling2D(),  # 替代Flatten,減少參數
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.5),  # 防止過擬合
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(5, activation='softmax')  # 5類別輸出
    ], name='DefectDetector')
    
    return model

# ========== 3. 編譯模型 ==========
model = build_defect_detector()

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy', 'precision', 'recall']
)

# 查看模型結構
model.summary()

# ========== 4. 數據增強 (小數據集必備!) ==========
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rotation_range=20,        # 旋轉±20度
    width_shift_range=0.2,    # 水平平移20%
    height_shift_range=0.2,   # 垂直平移20%
    horizontal_flip=True,     # 水平翻轉
    zoom_range=0.2,           # 縮放±20%
    brightness_range=[0.8, 1.2]  # 亮度調整
)

# 驗證集不做增強
val_datagen = ImageDataGenerator()

# ========== 5. 訓練模型 ==========
# 設置callbacks
callbacks = [
    # 早停: 驗證損失10個epoch不下降就停止
    tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True
    ),
    
    # 學習率衰減: 驗證損失5個epoch不下降就降低學習率
    tf.keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7
    ),
    
    # 模型檢查點: 保存最佳模型
    tf.keras.callbacks.ModelCheckpoint(
        'best_defect_detector.h5',
        monitor='val_accuracy',
        save_best_only=True
    )
]

# 訓練
history = model.fit(
    train_datagen.flow(X_train, y_train, batch_size=32),
    validation_data=val_datagen.flow(X_val, y_val, batch_size=32),
    epochs=100,
    callbacks=callbacks,
    verbose=1
)

# ========== 6. 評估模型 ==========
test_loss, test_acc, test_prec, test_rec = model.evaluate(X_test, y_test)
print(f"\n測試集結果:")
print(f"準確率: {test_acc:.4f}")
print(f"精確率: {test_prec:.4f}")
print(f"召回率: {test_rec:.4f}")

# ========== 7. 視覺化訓練過程 ==========
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='訓練準確率')
plt.plot(history.history['val_accuracy'], label='驗證準確率')
plt.xlabel('Epoch')
plt.ylabel('準確率')
plt.legend()
plt.title('模型準確率')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='訓練損失')
plt.plot(history.history['val_loss'], label='驗證損失')
plt.xlabel('Epoch')
plt.ylabel('損失')
plt.legend()
plt.title('模型損失')

plt.tight_layout()
plt.savefig('training_history.png')
plt.show()

# ========== 8. 預測新影像 ==========
def predict_defect(image_path):
    """
    預測單張影像的缺陷類型
    """
    # 載入影像
    img = tf.keras.preprocessing.image.load_img(
        image_path, 
        color_mode='grayscale',
        target_size=(512, 512)
    )
    
    # 預處理
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = img_array / 255.0
    img_array = np.expand_dims(img_array, axis=0)  # 添加batch維度
    
    # 預測
    predictions = model.predict(img_array)
    class_names = ['正常', '裂紋', '劃痕', '氣泡', '污點']
    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = np.max(predictions[0])
    
    print(f"預測結果: {predicted_class}")
    print(f"信心度: {confidence:.2%}")
    
    return predicted_class, confidence

# 使用範例
# predict_defect('new_product_image.jpg')
```

**關鍵設計決策說明**:

| 設計選擇 | 原因 | 化工應用考量 |
|---------|------|------------|
| **灰階影像(1通道)** | 產品表面通常不需要顏色資訊 | 減少計算量,聚焦於紋理和形狀 |
| **4層卷積塊** | 512×512高解析度需要足夠深度 | 逐步提取從邊緣到缺陷的層次特徵 |
| **32→64→128→256濾波器** | 逐層增加特徵複雜度 | 符合特徵提取的層次結構 |
| **GlobalAveragePooling** | 減少參數量,防止過擬合 | 小數據集(1000張)的最佳選擇 |
| **Dropout 0.5, 0.3** | 強正則化 | 化工數據集通常較小,需要防過擬合 |
| **數據增強** | 擴充訓練集 | 模擬實際生產中的位置、角度、光照變化 |
| **EarlyStopping** | 避免過度訓練 | 節省訓練時間,自動找到最佳epoch |

---

#### 4.4.2 模型優化技巧

**技巧1: 遷移學習(數據<500張時)**

```python
from tensorflow.keras.applications import VGG16

# 載入預訓練模型
base_model = VGG16(
    weights='imagenet',
    include_top=False,
    input_shape=(224, 224, 3)  # VGG16需要RGB輸入
)

# 凍結預訓練層
base_model.trainable = False

# 建立新模型
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(5, activation='softmax')
])
```

> [!TIP]
> **何時使用遷移學習?**
> - 數據量 < 500張
> - 缺陷特徵與自然影像相似(邊緣、紋理)
> - 訓練時間有限

**技巧2: 輕量化模型(邊緣部署)**

```python
from tensorflow.keras.applications import MobileNetV2

# 使用MobileNetV2作為backbone
base_model = MobileNetV2(
    weights='imagenet',
    include_top=False,
    input_shape=(224, 224, 3),
    alpha=0.5  # 寬度乘數,0.5表示減半參數量
)

# 模型大小: ~2MB (vs VGG16 ~500MB)
# 推理速度: ~10ms (vs VGG16 ~50ms)
```

**技巧3: 類別不平衡處理**

```python
# 化工常見問題: 缺陷樣本遠少於正常樣本
# 正常:800張, 裂紋:50張, 劃痕:30張, 氣泡:20張, 污點:100張

# 方法1: 類別權重
from sklearn.utils.class_weight import compute_class_weight

class_weights = compute_class_weight(
    'balanced',
    classes=np.unique(y_train_labels),
    y=y_train_labels
)
class_weight_dict = dict(enumerate(class_weights))

# 訓練時使用
model.fit(
    X_train, y_train,
    class_weight=class_weight_dict,  # 自動平衡類別
    ...
)

# 方法2: 過採樣少數類
from imblearn.over_sampling import SMOTE

# 注意: SMOTE需要先Flatten影像
X_train_flat = X_train.reshape(X_train.shape[0], -1)
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_flat, y_train_labels)
X_train_balanced = X_train_balanced.reshape(-1, 512, 512, 1)
```

---

### 4.5 常見問題與解決方案

#### 問題1: 模型訓練很慢

**症狀**: 每個epoch需要很長時間

**可能原因與解決方案**:

| 原因 | 解決方案 |
|------|---------|
| 影像解析度太高 | 降低輸入尺寸(512→256或224) |
| Batch size太小 | 增加batch size(如果GPU記憶體允許) |
| 沒有使用GPU | 檢查` |
| 數據增強太複雜 | 簡化ImageDataGenerator參數 |

```python
# 檢查GPU
print("GPU可用:", tf.config.list_physical_devices('GPU'))

# 如果沒有GPU,考慮使用Google Colab或雲端服務
```

#### 問題2: 驗證準確率遠低於訓練準確率

**症狀**: 訓練準確率95%, 驗證準確率60%

**診斷**: 嚴重過擬合!

**解決方案**:

```python
# 1. 增加Dropout
layers.Dropout(0.5)  # 原本0.3 → 0.5

# 2. 添加L2正則化
layers.Dense(256, activation='relu', 
             kernel_regularizer=tf.keras.regularizers.l2(0.01))

# 3. 減少模型複雜度
# 原本: Conv2D(256, ...)
# 改為: Conv2D(128, ...)

# 4. 增加數據增強
train_datagen = ImageDataGenerator(
    rotation_range=30,  # 增加旋轉範圍
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.2,  # 添加剪切變換
    zoom_range=0.3,
    horizontal_flip=True,
    vertical_flip=True  # 添加垂直翻轉
)

# 5. 早停
callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=10)
]
```

#### 問題3: 模型準確率很低(隨機猜測水平)

**症狀**: 5類別分類,準確率~20%(隨機猜測)

**可能原因**:

```python
# 原因1: 學習率太大
# 解決: 降低學習率
optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)  # 原本0.001

# 原因2: 數據沒有正規化
# 解決: 確保數據在[0, 1]範圍
X_train = X_train.astype('float32') / 255.0

# 原因3: 標籤錯誤
# 解決: 檢查標籤格式
print("標籤形狀:", y_train.shape)  # 應該是(N, 5)
print("標籤範例:", y_train[0])     # 應該是one-hot: [0, 1, 0, 0, 0]

# 原因4: 模型太簡單
# 解決: 增加網路深度或寬度
```

#### 問題4: 推理速度太慢

**症狀**: 單張影像預測需要>1秒

**解決方案**:

```python
# 方法1: 批次預測
images_batch = np.array([img1, img2, img3, ...])  # shape: (N, 512, 512, 1)
predictions = model.predict(images_batch)  # 比逐張快很多

# 方法2: 模型量化
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

# 保存量化模型
with open('model_quantized.tflite', 'wb') as f:
    f.write(tflite_model)

# 方法3: 使用輕量級架構
# 改用MobileNetV2或EfficientNet-B0

# 方法4: 降低輸入解析度
# 512×512 → 256×256 (速度提升4倍)
```

---

**本章小結**

恭喜!您已經掌握了使用Keras建立CNN的核心技能:

✅ **常用層**: Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization  
✅ **兩種API**: Sequential (簡單) 和 Functional (靈活)  
✅ **參數計算**: 理解模型複雜度,避免過擬合  
✅ **化工應用**: 能夠為實際問題建立CNN模型  
✅ **完整範例**: 產品缺陷檢測系統從頭到尾的實現  
✅ **優化技巧**: 遷移學習、輕量化、類別不平衡處理  
✅ **問題診斷**: 常見問題的識別和解決方案  

**關鍵要點回顧**:

| 層 | 主要作用 | 化工應用場景 |
|----|---------|------------|
| Conv2D | 提取空間特徵 | 缺陷檢測、紋理分析 |
| MaxPooling2D | 降維、提取主要特徵 | 減少計算量 |
| Flatten | 連接卷積層和全連接層 | 必要的轉換步驟 |
| Dense | 分類/回歸決策 | 最終預測 |
| Dropout | 防止過擬合 | 小數據集必備 |
| BatchNormalization | 加速訓練 | 深層網路必備 |

> [!IMPORTANT]
> **實踐建議**:
> 1. 從簡單模型開始,逐步增加複雜度
> 2. 使用`檢查參數量
> 3. 先用小數據集驗證模型可以運行
> 4. 根據實際性能調整架構
> 5. 小數據集(<1000張)優先考慮遷移學習
> 6. 注意數據正規化和類別平衡問題

**下一步學習**:
- Chapter 5: 模型編譯 - 選擇優化器、損失函數、評估指標
- Chapter 6: 模型訓練 - 訓練策略、Callbacks、超參數調整
- Chapter 7: 訓練歷史與視覺化 - 診斷過擬合、調整模型

---

## 5. 模型編譯

### 本章學習地圖

> [!IMPORTANT]
> **本章核心問題**: 如何正確配置CNN模型的優化器、損失函數和評估指標?

**學習目標**:
1. 🎯 **理解編譯過程**: 知道model.compile()的三大要素
2. ⚙️ **選擇優化器**: 掌握Adam、SGD等優化器的特點和適用場景
3. 📉 **配置損失函數**: 根據任務類型選擇合適的損失函數
4. 📊 **設置評估指標**: 理解Loss和Metrics的區別,選擇合適的監控指標

**為什麼模型編譯很重要?**

建立模型只是第一步,編譯模型才能讓它真正"動起來":
- ❌ **未編譯**: 模型只是一堆層的堆疊,無法訓練
- ✅ **已編譯**: 模型知道如何學習(優化器)、學什麼(損失函數)、怎麼評估(指標)

**化工類比**:
- **建立模型** = 設計反應器結構
- **編譯模型** = 設定操作條件(溫度、壓力、催化劑)
- **訓練模型** = 實際運行反應器

**本章架構**:

```
model.compile()方法 (5.1)
    ↓
優化器選擇 (5.2)
    ├─ Adam (首選)
    ├─ SGD
    └─ 選擇決策樹
    ↓
損失函數配置 (5.3)
    ├─ 分類問題
    └─ 快速參考
    ↓
評估指標設置 (5.4)
    └─ Loss vs Metrics
    ↓
化工應用範例 (5.5)
```

> [!TIP]
> 學習建議:先理解三大要素的作用,再學習如何選擇。大多數情況下,使用標準配置即可!

---

### 5.1 model.compile() 方法

**基本語法**:

```python
model.compile(
    optimizer='adam',              # 優化器: 如何更新權重
    loss='categorical_crossentropy',  # 損失函數: 優化目標
    metrics=['accuracy']           # 評估指標: 監控性能
)
```

**三大要素**:

| 要素 | 作用 | 是否必須 | 影響訓練 |
|------|------|---------|---------|
| **optimizer** | 決定如何根據梯度更新權重 | ✅ 必須 | ✅ 是 |
| **loss** | 計算預測與真實值的差距 | ✅ 必須 | ✅ 是 |
| **metrics** | 監控模型性能 | ❌ 可選 | ❌ 否 |

**完整範例**:

```python
from tensorflow.keras import models, layers
from tensorflow.keras.optimizers import Adam

# 建立模型
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(10, activation='softmax')
])

# 編譯模型
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy', 'precision', 'recall']
)

# 查看模型配置
print(model.optimizer)
print(model.loss)
print(model.metrics_names)
```

---

### 5.2 優化器選擇

優化器決定**如何根據梯度更新權重**,是訓練過程的核心。

#### 5.2.1 Adam (Adaptive Moment Estimation) ⭐ 首選

**特點**: 自適應學習率,結合Momentum和RMSprop的優點

**使用方式**:

```python
from tensorflow.keras.optimizers import Adam

# 方法1: 使用字符串(使用預設參數)
model.compile(optimizer='adam', loss='categorical_crossentropy')

# 方法2: 自定義參數
optimizer = Adam(
    learning_rate=0.001,    # 學習率(預設0.001)
    beta_1=0.9,             # 一階矩估計的指數衰減率
    beta_2=0.999,           # 二階矩估計的指數衰減率
    epsilon=1e-07           # 數值穩定性常數
)
model.compile(optimizer=optimizer, loss='categorical_crossentropy')
```

**優點**:
- ✅ 自適應學習率,不需要手動調整
- ✅ 對超參數不敏感,魯棒性強
- ✅ 收斂速度快
- ✅ 適用於大多數問題

**缺點**:
- ❌ 可能在某些問題上泛化性能略差於SGD
- ❌ 需要較多記憶體(儲存一階和二階矩)

**化工應用建議**:
- ✅ **首選**: 產品缺陷檢測、影像分類等大多數CNN任務
- ✅ **數據量中等** (1000-10000張): Adam表現優秀
- ✅ **快速原型開發**: Adam是最佳起點

**學習率選擇**:

| 數據量 | 建議學習率 | 說明 |
|--------|-----------|------|
| 小 (<1000) | 0.0001-0.0005 | 較小學習率,防止過擬合 |
| 中 (1000-10000) | 0.001 | 預設值,通常效果好 |
| 大 (>10000) | 0.001-0.01 | 可以嘗試較大學習率 |

---

#### 5.2.2 SGD (Stochastic Gradient Descent)

**特點**: 經典優化器,配合Momentum效果好

**使用方式**:

```python
from tensorflow.keras.optimizers import SGD

optimizer = SGD(
    learning_rate=0.01,     # 學習率(通常需要較大值)
    momentum=0.9,           # 動量(建議0.9)
    nesterov=True           # 使用Nesterov動量(建議True)
)
model.compile(optimizer=optimizer, loss='categorical_crossentropy')
```

**優點**:
- ✅ 泛化性能好,測試集表現通常優於Adam
- ✅ 記憶體需求小
- ✅ 適合大數據集

**缺點**:
- ❌ 需要仔細調整學習率
- ❌ 收斂速度較慢
- ❌ 對學習率敏感

**化工應用建議**:
- ✅ **大數據集** (>10000張): 追求最佳泛化性能
- ✅ **生產部署**: 模型性能要求極高
- ⚠️ **需要調參**: 準備花時間調整學習率

---

#### 5.2.3 優化器選擇決策樹

```
開始選擇優化器
    │
    ├─ 是否為CNN影像分類任務?
    │   ├─ 是 → 繼續
    │   └─ 否 → 參考其他指南
    │
    ├─ 數據量是多少?
    │   ├─ <1000張 → 使用Adam(lr=0.0001) + 數據增強
    │   ├─ 1000-10000張 → 使用Adam(lr=0.001) ✅ 推薦
    │   └─ >10000張 → 繼續
    │
    ├─ 是否追求極致性能?
    │   ├─ 是 → SGD(lr=0.01, momentum=0.9) + 學習率調度
    │   └─ 否 → Adam(lr=0.001) ✅ 推薦
```

**快速參考表**:

| 場景 | 推薦優化器 | 學習率 | 說明 |
|------|-----------|--------|------|
| **快速原型** | Adam | 0.001 | 預設配置,快速驗證想法 |
| **小數據集** | Adam | 0.0001 | 降低學習率,防止過擬合 |
| **中等數據集** | Adam | 0.001 | 標準配置 |
| **大數據集** | Adam或SGD | 0.001-0.01 | Adam快速,SGD泛化好 |
| **生產部署** | SGD + 調參 | 0.01 | 追求最佳性能 |
| **遷移學習** | Adam | 0.0001 | 微調預訓練模型 |

> [!TIP]
> **90%的情況**: 使用 ` 就夠了!
> 
> 只有在以下情況才需要自定義:
> - 訓練不穩定(loss震盪) → 降低學習率
> - 收斂太慢 → 提高學習率
> - 追求極致性能 → 嘗試SGD

---

### 5.3 損失函數配置

損失函數定義**模型的優化目標**,直接影響訓練過程。

#### 5.3.1 分類問題損失函數

**Binary Crossentropy (二元分類)**:

```python
# 適用場景: 正常/缺陷, 合格/不合格
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',  # 二元分類
    metrics=['accuracy']
)

# 輸出層配置
layers.Dense(1, activation='sigmoid')  # 輸出0-1之間的機率
```

**標籤格式**: ` (0或1)

**化工應用**:
- 產品合格/不合格判定
- 缺陷有/無檢測
- 安全/危險狀態識別

---

**Categorical Crossentropy (多類別,one-hot標籤)**:

```python
# 適用場景: 多種缺陷類型, 多個品質等級
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',  # 多類別(one-hot)
    metrics=['accuracy']
)

# 輸出層配置
layers.Dense(5, activation='softmax')  # 5個類別
```

**標籤格式**: 
```python
# One-hot編碼
y_train = [[1, 0, 0, 0, 0],  # 類別0
           [0, 1, 0, 0, 0],  # 類別1
           [0, 0, 0, 1, 0]]  # 類別3
```

**化工應用**:
- 缺陷類型分類(裂紋、劃痕、氣泡、污點、正常)
- 產品等級分類(A級、B級、C級、不合格)
- 晶體形態識別(針狀、片狀、球狀、不規則)

---

**Sparse Categorical Crossentropy (多類別,整數標籤)**:

```python
# 功能與categorical_crossentropy相同,但標籤格式不同
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',  # 多類別(整數)
    metrics=['accuracy']
)

# 輸出層配置相同
layers.Dense(5, activation='softmax')
```

**標籤格式**:
```python
# 整數索引
y_train = [0, 1, 3, 2, 0, 4]  # 直接使用類別索引
```

**優點**: 
- 節省記憶體(不需要one-hot編碼)
- 標籤更直觀

> [!TIP]
> **何時使用sparse版本?**
> - 類別數量很多(>10個)
> - 記憶體受限
> - 標籤已經是整數格式

---

#### 5.3.2 損失函數快速參考

| 任務類型 | Keras損失函數 | 輸出層激活 | 標籤格式 | 化工應用 |
|---------|--------------|-----------|---------|---------|
| **二元分類** | ` | ` | ` | 合格/不合格 |
| **多類別(one-hot)** | ` | ` | ` | 缺陷類型(5類) |
| **多類別(整數)** | ` | ` | ` | 同上(節省記憶體) |

> [!WARNING]
> **常見錯誤: 損失函數與輸出層不匹配**
> 
> ```python
> # 錯誤: 二元分類用softmax
> layers.Dense(1, activation='softmax')  # ❌ 錯誤!
> model.compile(loss='binary_crossentropy')
> 
> # 正確: 二元分類用sigmoid
> layers.Dense(1, activation='sigmoid')  # ✅ 正確
> model.compile(loss='binary_crossentropy')
> 
> # 錯誤: 多類別用sigmoid
> layers.Dense(5, activation='sigmoid')  # ❌ 錯誤!
> model.compile(loss='categorical_crossentropy')
> 
> # 正確: 多類別用softmax
> layers.Dense(5, activation='softmax')  # ✅ 正確
> model.compile(loss='categorical_crossentropy')
> ```

---

### 5.4 評估指標設置

#### 5.4.1 Loss vs Metrics 的關鍵區別

> [!IMPORTANT]
> **常見誤解**: 許多初學者誤以為在`中添加指標會影響模型訓練。
> 
> **正確理解**:
> - ✅ **Loss Function**: 計算梯度,更新權重,**影響訓練**
> - ✅ **Metrics**: 僅用於監控和評估,**不影響訓練**

**對比表**:

| 項目 | Loss Function | Metrics |
|------|--------------|---------|
| **數量** | 必須指定1個 | 可指定0個或多個 |
| **作用** | 計算梯度,更新權重 | 僅評估性能 |
| **影響訓練** | ✅ 是 | ❌ 否 |
| **顯示** | 訓練和驗證 | 訓練和驗證 |

---

#### 5.4.2 常用評估指標

**分類問題指標**:

```python
# 基本指標
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']  # 準確率
)

# 多個指標
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy', 'precision', 'recall']
)
```

**指標說明**:

| 指標 | 說明 | 何時使用 | 化工應用 |
|------|------|---------|---------|
| **accuracy** | 準確率 | 類別平衡時 | 一般分類任務 |
| **precision** | 精確率 | 關注誤報率 | 缺陷檢測(避免誤判為缺陷) |
| **recall** | 召回率 | 關注漏報率 | 安全檢測(不能漏掉危險) |

---

### 5.5 化工應用完整範例

#### 5.5.1 產品缺陷5分類

```python
from tensorflow.keras import models, layers
from tensorflow.keras.optimizers import Adam

# 建立模型
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', 
                  padding='same', input_shape=(512, 512, 1)),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(5, activation='softmax')  # 5類別: 正常、裂紋、劃痕、氣泡、污點
])

# 編譯模型
model.compile(
    optimizer=Adam(learning_rate=0.001),  # Adam優化器,標準學習率
    loss='categorical_crossentropy',      # 多類別交叉熵
    metrics=['accuracy']                  # 監控準確率
)

model.summary()
```

---

**本章小結**

恭喜!您已經掌握了CNN模型編譯的核心知識:

✅ **編譯三要素**: optimizer, loss, metrics  
✅ **優化器選擇**: Adam首選,SGD追求極致  
✅ **損失函數**: 分類用crossentropy,注意標籤格式  
✅ **評估指標**: 理解Loss vs Metrics的區別  
✅ **化工應用**: 能夠為實際問題正確配置模型  

**關鍵要點回顧**:

| 要素 | 推薦配置 | 化工應用場景 |
|------|---------|------------|
| **優化器** | ` | 大多數CNN任務 |
| **損失函數(二元)** | ` | 合格/不合格 |
| **損失函數(多類別)** | ` | 缺陷類型分類 |
| **評估指標** | ` | 基本監控 |
| **遷移學習** | ` | 微調預訓練模型 |

> [!IMPORTANT]
> **實踐建議**:
> 1. **90%情況**: 使用 `
> 2. **檢查匹配**: 確保損失函數與輸出層激活函數匹配
> 3. **標籤格式**: 注意categorical vs sparse的區別
> 4. **學習率**: 訓練不穩定時降低學習率
> 5. **遷移學習**: 使用較小學習率(0.0001)

**下一步學習**:
- Chapter 6: 模型訓練 - 訓練策略、Callbacks、超參數調整
- Chapter 7: 訓練歷史與視覺化 - 診斷過擬合、學習曲線分析

---

## 6. 模型訓練

### 本章學習地圖

> [!IMPORTANT]
> **本章核心問題**: 如何高效訓練CNN模型?如何避免常見問題並優化訓練過程?

**學習目標**:
1. 🎯 **掌握訓練流程**: 理解model.fit()的完整訓練過程
2. ⚙️ **優化訓練參數**: 學會選擇batch_size、epochs等關鍵參數
3. 🔧 **使用Callbacks**: 掌握EarlyStopping、ModelCheckpoint等實用工具
4. 🏭 **診斷訓練問題**: 識別並解決訓練過程中的常見問題

**為什麼訓練策略很重要?**

模型訓練不是簡單地調用`就結束了:
- ❌ **盲目訓練**: 浪費時間,可能過擬合或欠擬合
- ✅ **策略訓練**: 高效、穩定、可重現

**化工類比**:
- **建立模型** = 設計反應器
- **編譯模型** = 設定操作條件
- **訓練模型** = 實際運行反應器,調整參數達到最佳產率

**本章架構**:

```
訓練流程說明 (6.1)
    ↓
訓練參數詳解 (6.2)
    ├─ epochs (訓練輪數)
    ├─ batch_size (批次大小)
    ├─ validation_split/data (驗證集)
    └─ 參數選擇指南
    ↓
Callbacks機制 (6.3)
    ├─ EarlyStopping (早停)
    ├─ ModelCheckpoint (模型保存)
    ├─ ReduceLROnPlateau (學習率衰減)
    └─ TensorBoard (視覺化)
    ↓
訓練診斷 (6.4)
    └─ 常見問題解決方案
    ↓
化工完整案例 (6.5)
```

> [!TIP]
> 學習建議:先理解訓練流程,再學習參數調整,最後掌握Callbacks的使用。實踐是最好的老師!

---

### 6.1 訓練流程完整說明

#### 6.1.1 model.fit() 基本用法

**核心方法**: `是Keras訓練模型的核心方法

**基本語法**:

```python
history = model.fit(
    x_train, y_train,           # 訓練數據
    epochs=10,                  # 訓練輪數
    batch_size=32,              # 批次大小
    validation_split=0.2,       # 驗證集比例
    verbose=1,                  # 顯示模式
    callbacks=None              # 回調函數列表
)
```

**返回值**: `物件,記錄訓練過程中的所有指標

#### 6.1.2 訓練流程視覺化

**完整訓練流程**:

```
開始訓練
    ↓
Epoch 1 開始
    ├─ Batch 1: 取32張影像 → 前向傳播 → 計算loss → 反向傳播 → 更新權重
    ├─ Batch 2: 取32張影像 → 前向傳播 → 計算loss → 反向傳播 → 更新權重
    ├─ ...
    ├─ Batch N: 最後一批 → 前向傳播 → 計算loss → 反向傳播 → 更新權重
    ├─ 計算訓練集平均loss和accuracy
    ├─ 在驗證集上評估 → 計算val_loss和val_accuracy
    └─ 執行Callbacks (檢查是否早停、保存模型等)
    ↓
Epoch 2 開始
    ├─ (重複上述過程)
    └─ ...
    ↓
Epoch 10 結束
    ↓
返回History物件
```

**化工類比: 訓練過程像「批次反應器優化」**

| 訓練概念 | 化工類比 | 說明 |
|---------|---------|------|
| **Epoch** | 完整的反應週期 | 所有原料都反應一次 |
| **Batch** | 進料批次 | 每次進料一小批原料 |
| **Forward Pass** | 反應進行 | 原料轉化為產物 |
| **Loss Calculation** | 產率測量 | 測量產物品質 |
| **Backward Pass** | 參數調整 | 根據產率調整溫度、壓力 |
| **Validation** | 品質檢驗 | 用獨立樣本驗證產品品質 |

#### 6.1.3 訓練過程中發生了什麼?

**每個Batch的詳細步驟**:

```python
# 偽代碼,展示訓練內部邏輯
for epoch in range(epochs):
    for batch_x, batch_y in training_data:
        # 1. 前向傳播
        predictions = model(batch_x)
        
        # 2. 計算損失
        loss = loss_function(batch_y, predictions)
        
        # 3. 反向傳播 (計算梯度)
        gradients = compute_gradients(loss, model.weights)
        
        # 4. 更新權重
        optimizer.apply_gradients(gradients, model.weights)
    
    # 5. 驗證集評估
    val_loss, val_acc = model.evaluate(val_data)
    
    # 6. 執行Callbacks
    for callback in callbacks:
        callback.on_epoch_end(epoch, logs={'val_loss': val_loss})
```

---

### 6.2 訓練參數詳解

#### 6.2.1 epochs (訓練輪數)

**定義**: 整個訓練集被遍歷的次數

**直覺理解**: 
- 1 epoch = 模型看過所有訓練數據一次
- 10 epochs = 模型看過所有訓練數據10次

**數學表示**:

$$
\text{總訓練步數} = \text{epochs} \times \lceil \frac{N_{\text{train}}}{\text{batch\_size}} \rceil
$$

其中 $N_{\text{train}}$ 是訓練樣本數量。

**化工類比**: 
- **Epochs** = 反應器運行的批次數
- 每個epoch,所有原料都反應一次
- 更多epochs = 更多次優化機會,但可能過度優化(過擬合)

**選擇建議**:

| 數據量 | 建議epochs | 說明 |
|--------|-----------|------|
| 小 (<500) | 50-100 | 數據少,需要多次學習 |
| 中 (500-5000) | 20-50 | 標準範圍 |
| 大 (>5000) | 10-30 | 數據多,快速收斂 |

**實用技巧**:

```python
# 方法1: 設定較大epochs + EarlyStopping
model.fit(
    x_train, y_train,
    epochs=100,  # 設定較大值
    callbacks=[
        EarlyStopping(patience=10, restore_best_weights=True)
    ]
)
# 模型會在驗證損失10個epoch不下降時自動停止

# 方法2: 觀察學習曲線後調整
history = model.fit(x_train, y_train, epochs=20)
# 如果還在下降 → 增加epochs
# 如果已經平穩 → 減少epochs
```

> [!WARNING]
> **常見錯誤**: epochs設定過小
> - 症狀: 訓練損失還在快速下降就停止了
> - 解決: 增加epochs或使用EarlyStopping自動判斷

---

#### 6.2.2 batch_size (批次大小)

**定義**: 每次梯度更新使用的樣本數量

**直覺理解**:
- batch_size=32: 每次用32張影像計算梯度,更新一次權重
- batch_size=1: 每張影像都更新一次 (Stochastic GD)
- batch_size=N_train: 所有數據一起更新 (Batch GD)

**數學表示**:

$$
\text{每個epoch的更新次數} = \lceil \frac{N_{\text{train}}}{\text{batch\_size}} \rceil
$$

**化工類比**:
- **小batch_size** = 連續進料反應器,頻繁調整
- **大batch_size** = 批次反應器,一次處理大量原料

**batch_size對訓練的影響**:

| 特性 | 小batch (16-32) | 大batch (128-256) |
|------|----------------|------------------|
| **訓練速度** | 慢 (更新頻繁) | 快 (更新少) |
| **記憶體需求** | 低 | 高 |
| **梯度估計** | 噪聲大 | 穩定 |
| **泛化能力** | 通常較好 | 可能較差 |
| **收斂穩定性** | 震盪 | 平滑 |
| **適用場景** | 小數據集、GPU記憶體有限 | 大數據集、GPU記憶體充足 |

**選擇建議**:

```python
# 根據GPU記憶體選擇
GPU_MEMORY = 8  # GB

if GPU_MEMORY < 4:
    batch_size = 16  # 小GPU
elif GPU_MEMORY < 8:
    batch_size = 32  # 中等GPU
else:
    batch_size = 64  # 大GPU

# 化工應用建議
if dataset_size < 500:
    batch_size = 16  # 小數據集,小batch更好
elif dataset_size < 2000:
    batch_size = 32  # 標準選擇
else:
    batch_size = 64  # 大數據集
```

**實驗對比**:

```python
# 實驗: 不同batch_size的影響
batch_sizes = [16, 32, 64, 128]
results = {}

for bs in batch_sizes:
    model = build_model()
    model.compile(optimizer='adam', loss='categorical_crossentropy')
    
    history = model.fit(
        x_train, y_train,
        batch_size=bs,
        epochs=20,
        validation_split=0.2,
        verbose=0
    )
    
    results[bs] = {
        'final_val_acc': history.history['val_accuracy'][-1],
        'training_time': history.history['time_per_epoch']
    }

# 選擇準確率最高且訓練時間可接受的batch_size
```

> [!TIP]
> **經驗法則**:
> - 影像分類: batch_size=32 (最常用)
> - GPU記憶體不足: 降低batch_size或減小影像尺寸
> - 訓練不穩定: 增大batch_size

---

#### 6.2.3 validation_split / validation_data (驗證集)

**為什麼需要驗證集?**

訓練集用於學習,驗證集用於**監控過擬合**:
- 訓練集loss下降 ✅
- 驗證集loss也下降 ✅ → 模型正常學習
- 驗證集loss上升 ❌ → 過擬合!

**化工類比**:
- **訓練集** = 實驗室小試數據
- **驗證集** = 中試數據 (用於驗證小試結果是否可靠)
- **測試集** = 工廠生產數據 (最終驗證)

**方法1: validation_split (自動分割)**

```python
model.fit(
    x_train, y_train,
    validation_split=0.2,  # 20%訓練數據作為驗證集
    epochs=20
)
```

**特點**:
- ✅ 方便,一行代碼
- ❌ 從訓練數據**末尾**分割,不打亂
- ❌ 如果數據有順序(如時間序列),可能有問題

**方法2: validation_data (手動提供)**

```python
from sklearn.model_selection import train_test_split

# 手動分割,可以打亂
x_train, x_val, y_train, y_val = train_test_split(
    x_train_full, y_train_full,
    test_size=0.2,
    random_state=42,
    stratify=y_train_full  # 保持類別比例
)

model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    epochs=20
)
```

**特點**:
- ✅ 更靈活,可以打亂
- ✅ 可以使用stratify保持類別平衡
- ✅ 可以重複使用相同的驗證集

**驗證集大小建議**:

| 總數據量 | 驗證集比例 | 說明 |
|---------|-----------|------|
| <500 | 10-15% | 數據少,多留給訓練 |
| 500-2000 | 15-20% | 標準比例 |
| >2000 | 20-25% | 數據多,可以多驗證 |

**化工應用範例**:

```python
# 化工案例: 產品缺陷檢測
# 數據: 1000張影像,5個類別(正常、裂紋、劃痕、氣泡、污點)

# 方法1: 簡單分割 (不推薦,類別可能不平衡)
model.fit(x_train, y_train, validation_split=0.2)

# 方法2: 分層分割 (推薦,保持類別比例)
from sklearn.model_selection import train_test_split

x_train, x_val, y_train, y_val = train_test_split(
    images, labels,
    test_size=0.2,
    stratify=labels,  # 確保每個類別在訓練/驗證集中比例相同
    random_state=42
)

model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    epochs=50
)
```

> [!IMPORTANT]
> **類別不平衡時必須使用stratify**:
> - 如果正常樣本800張,缺陷樣本200張
> - 不用stratify: 驗證集可能只有正常樣本
> - 用stratify: 驗證集保持80%正常、20%缺陷

---

#### 6.2.4 訓練參數快速參考表

**標準配置 (90%情況適用)**:

```python
# 化工影像分類標準配置
model.fit(
    x_train, y_train,
    epochs=50,                  # 配合EarlyStopping
    batch_size=32,              # 標準選擇
    validation_split=0.2,       # 20%驗證集
    callbacks=[
        EarlyStopping(patience=10, restore_best_weights=True)
    ],
    verbose=1
)
```

**參數選擇決策樹**:

```
開始選擇訓練參數
    │
    ├─ 數據量是多少?
    │   ├─ <500張 → epochs=50-100, batch_size=16, val_split=0.15
    │   ├─ 500-2000張 → epochs=30-50, batch_size=32, val_split=0.2
    │   └─ >2000張 → epochs=20-30, batch_size=64, val_split=0.2
    │
    ├─ GPU記憶體是否足夠?
    │   ├─ 記憶體不足 → 降低batch_size或影像尺寸
    │   └─ 記憶體充足 → 可以增大batch_size
    │
    ├─ 是否有類別不平衡?
    │   ├─ 是 → 使用validation_data + stratify
    │   └─ 否 → validation_split即可
    │
    └─ 是否需要可重現結果?
        ├─ 是 → 設定random_state, 使用validation_data
        └─ 否 → validation_split即可
```

---

### 6.3 Callbacks機制

**什麼是Callbacks?**

Callbacks是在訓練過程中自動執行的函數,用於:
- 監控訓練過程
- 自動調整參數
- 保存模型
- 提前停止訓練

**化工類比**: Callbacks像「自動控制系統」
- **EarlyStopping** = 安全閥 (防止過度反應)
- **ModelCheckpoint** = 數據記錄儀 (保存最佳狀態)
- **ReduceLROnPlateau** = PID控制器 (自動調整參數)
- **TensorBoard** = 實時監控儀表板

---

#### 6.3.1 EarlyStopping (早停)

**功能**: 當驗證指標不再改善時,自動停止訓練

**為什麼需要?**

```
訓練過程:
Epoch 1-10: val_loss持續下降 ✅
Epoch 11-15: val_loss開始上升 ❌ (過擬合開始)
Epoch 16-20: val_loss繼續上升 ❌ (浪費時間)

使用EarlyStopping:
Epoch 1-10: val_loss持續下降 ✅
Epoch 11-15: val_loss開始上升,等待patience=5個epoch
Epoch 16: 觸發早停,恢復Epoch 10的權重 ✅
```

**主要參數**:

```python
from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(
    monitor='val_loss',           # 監控指標
    patience=10,                  # 容忍epoch數
    restore_best_weights=True,    # 恢復最佳權重
    verbose=1,                    # 顯示訊息
    mode='min',                   # 'min'(loss) 或 'max'(accuracy)
    min_delta=0.001               # 最小改善量
)
```

**參數詳解**:

| 參數 | 說明 | 建議值 |
|------|------|--------|
| ` | 監控的指標 | ` (最常用) |
| ` | 容忍的epoch數 | 10-20 (小數據集用大值) |
| ` | 是否恢復最佳權重 | ` (強烈建議) |
| ` | 認定為改善的最小變化 | 0.001 (預設) |
| ` | 優化方向 | ` (loss) 或 ` (accuracy) |

**使用範例**:

```python
# 基本用法
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

history = model.fit(
    x_train, y_train,
    epochs=100,  # 設定較大值,讓EarlyStopping決定何時停止
    validation_split=0.2,
    callbacks=[early_stop]
)

print(f"實際訓練了 {len(history.history['loss'])} 個epochs")
```

**化工應用範例**:

```python
# 化工案例: 顯微影像晶體分類
# 數據量小(300張),容易過擬合

early_stop = EarlyStopping(
    monitor='val_accuracy',       # 監控驗證準確率
    patience=15,                  # 小數據集,patience設大一點
    restore_best_weights=True,
    mode='max',                   # accuracy要最大化
    verbose=1
)

model.fit(
    x_train, y_train,
    epochs=200,  # 設定很大,讓早停決定
    batch_size=16,
    validation_split=0.2,
    callbacks=[early_stop]
)
```

> [!TIP]
> **patience選擇建議**:
> - 小數據集 (<500): patience=15-20
> - 中等數據集 (500-2000): patience=10-15
> - 大數據集 (>2000): patience=5-10

> [!WARNING]
> **常見錯誤**: `
> - 如果不恢復最佳權重,最終模型可能是過擬合的!
> - 務必設定 `

---

#### 6.3.2 ModelCheckpoint (模型保存)

**功能**: 在訓練過程中自動保存模型

**為什麼需要?**

- 訓練可能中斷 (停電、程序崩潰)
- 需要保存最佳模型 (不是最後一個epoch的模型)
- 需要保存多個檢查點進行對比

**主要參數**:

```python
from tensorflow.keras.callbacks import ModelCheckpoint

checkpoint = ModelCheckpoint(
    filepath='best_model.h5',     # 保存路徑
    monitor='val_accuracy',       # 監控指標
    save_best_only=True,          # 只保存最佳模型
    save_weights_only=False,      # 保存完整模型
    mode='max',                   # 優化方向
    verbose=1                     # 顯示訊息
)
```

**參數詳解**:

| 參數 | 說明 | 建議值 |
|------|------|--------|
| ` | 保存路徑,可包含變數 | ` |
| ` | 監控指標 | ` 或 ` |
| ` | 只保存最佳模型 | ` (節省空間) |
| ` | 只保存權重 | ` (保存完整模型) |
| ` | 優化方向 | ` (accuracy) 或 ` (loss) |

**使用範例**:

```python
# 方法1: 只保存最佳模型
checkpoint = ModelCheckpoint(
    filepath='best_cnn_model.h5',
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

# 方法2: 保存每個epoch (包含epoch和指標在檔名中)
checkpoint = ModelCheckpoint(
    filepath='model_ep{epoch:02d}_acc{val_accuracy:.3f}.h5',
    monitor='val_accuracy',
    save_best_only=False,  # 每個epoch都保存
    verbose=1
)

# 方法3: 只保存權重 (檔案更小)
checkpoint = ModelCheckpoint(
    filepath='weights_best.h5',
    monitor='val_loss',
    save_best_only=True,
    save_weights_only=True,  # 只保存權重
    mode='min'
)

history = model.fit(
    x_train, y_train,
    epochs=50,
    validation_split=0.2,
    callbacks=[checkpoint]
)
```

**載入保存的模型**:

```python
# 載入完整模型
from tensorflow.keras.models import load_model
model = load_model('best_cnn_model.h5')

# 載入權重 (需要先建立相同架構的模型)
model = build_model()  # 建立模型架構
model.load_weights('weights_best.h5')
```

**化工應用範例**:

```python
# 化工案例: 產品缺陷檢測
# 需求: 保存準確率最高的模型,用於生產部署

checkpoint = ModelCheckpoint(
    filepath='defect_detector_best.h5',
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

# 同時保存訓練過程中的檢查點
checkpoint_backup = ModelCheckpoint(
    filepath='checkpoints/model_epoch{epoch:02d}.h5',
    save_freq='epoch',  # 每個epoch保存一次
    verbose=0
)

model.fit(
    x_train, y_train,
    epochs=50,
    validation_split=0.2,
    callbacks=[checkpoint, checkpoint_backup]
)

# 訓練完成後,載入最佳模型
best_model = load_model('defect_detector_best.h5')
```

> [!TIP]
> **檔案命名技巧**:
> ```python
> # 包含時間戳
> import datetime
> timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
> filepath = f'model_{timestamp}_{{epoch:02d}}_{{val_accuracy:.3f}}.h5'
> 
> # 包含模型資訊
> filepath = 'cnn_defect_detector_best.h5'
> ```

---

#### 6.3.3 ReduceLROnPlateau (學習率衰減)

**功能**: 當驗證指標停止改善時,自動降低學習率

**為什麼需要?**

訓練過程中,學習率需要動態調整:
- **初期**: 大學習率,快速接近最優解
- **後期**: 小學習率,精細調整

**化工類比**: 
- 像「溫度控制」
- 反應初期: 高溫快速反應
- 反應後期: 降溫精細控制,避免副反應

**主要參數**:

```python
from tensorflow.keras.callbacks import ReduceLROnPlateau

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',           # 監控指標
    factor=0.5,                   # 學習率縮減倍數
    patience=5,                   # 容忍epoch數
    min_lr=1e-7,                  # 最小學習率
    mode='min',                   # 優化方向
    verbose=1                     # 顯示訊息
)
```

**參數詳解**:

| 參數 | 說明 | 建議值 |
|------|------|--------|
| ` | 監控指標 | ` |
| ` | 學習率縮減倍數 | 0.5 或 0.2 |
| ` | 容忍epoch數 | 5-10 |
| ` | 最小學習率 | 1e-7 或 1e-6 |
| ` | 降低學習率後等待的epoch數 | 0 (預設) |

**工作原理**:

```
初始學習率: 0.001
    ↓
Epoch 1-10: val_loss下降 ✅
Epoch 11-15: val_loss不再下降 (等待patience=5)
Epoch 16: 觸發學習率衰減
    新學習率 = 0.001 × 0.5 = 0.0005
    ↓
Epoch 17-25: val_loss繼續下降 ✅
Epoch 26-30: val_loss不再下降
Epoch 31: 再次觸發
    新學習率 = 0.0005 × 0.5 = 0.00025
    ↓
...直到達到min_lr
```

**使用範例**:

```python
# 基本用法
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-7,
    verbose=1
)

model.fit(
    x_train, y_train,
    epochs=100,
    validation_split=0.2,
    callbacks=[reduce_lr]
)
```

**與EarlyStopping組合使用**:

```python
# 推薦組合: EarlyStopping + ReduceLROnPlateau
callbacks = [
    # 學習率衰減: patience較小,先嘗試降低學習率
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1
    ),
    
    # 早停: patience較大,給學習率衰減機會
    EarlyStopping(
        monitor='val_loss',
        patience=15,  # 比ReduceLR的patience大
        restore_best_weights=True,
        verbose=1
    )
]

model.fit(
    x_train, y_train,
    epochs=100,
    validation_split=0.2,
    callbacks=callbacks
)
```

**化工應用範例**:

```python
# 化工案例: 光譜影像分析
# 需求: 精細調整模型,達到最佳性能

from tensorflow.keras.optimizers import Adam

# 初始學習率設定較大
optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# 配置學習率衰減
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,  # 每次降低到原來的20%
    patience=5,
    min_lr=1e-7,
    verbose=1
)

history = model.fit(
    x_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[reduce_lr]
)

# 視覺化學習率變化
import matplotlib.pyplot as plt
plt.plot(history.history['lr'])
plt.xlabel('Epoch')
plt.ylabel('Learning Rate')
plt.title('Learning Rate Schedule')
plt.yscale('log')
plt.show()
```

> [!TIP]
> **patience設定建議**:
> - ReduceLROnPlateau的patience < EarlyStopping的patience
> - 例如: ReduceLR patience=5, EarlyStopping patience=15
> - 這樣先嘗試降低學習率,如果還不行才早停

---

#### 6.3.4 TensorBoard (訓練視覺化)

**功能**: 將訓練過程記錄到TensorBoard,提供強大的視覺化分析

**為什麼需要?**

- 即時監控訓練過程
- 對比不同實驗
- 視覺化模型架構
- 分析權重分布

**基本用法**:

```python
from tensorflow.keras.callbacks import TensorBoard
import datetime

# 創建日誌目錄 (包含時間戳)
log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

tensorboard_callback = TensorBoard(
    log_dir=log_dir,              # 日誌目錄
    histogram_freq=1,             # 每個epoch記錄權重直方圖
    write_graph=True,             # 記錄模型圖
    write_images=False,           # 是否記錄模型權重為影像
    update_freq='epoch',          # 更新頻率
    profile_batch=0               # 性能分析 (0=關閉)
)

model.fit(
    x_train, y_train,
    epochs=50,
    validation_split=0.2,
    callbacks=[tensorboard_callback]
)
```

**啟動TensorBoard**:

```bash
# 在命令行執行
tensorboard --logdir=logs/fit

# 然後在瀏覽器打開
# http://localhost:6006
```

**TensorBoard功能**:

| 標籤頁 | 功能 | 用途 |
|--------|------|------|
| **Scalars** | 標量指標曲線 | 查看loss、accuracy變化 |
| **Graphs** | 模型架構圖 | 視覺化模型結構 |
| **Distributions** | 權重分布 | 檢查權重是否正常 |
| **Histograms** | 權重直方圖 | 分析權重變化 |
| **Images** | 影像 | 視覺化輸入/輸出 |

**化工應用範例**:

```python
# 化工案例: 對比不同模型架構

# 實驗1: 淺層CNN
log_dir_1 = "logs/fit/shallow_cnn_" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
model_1 = build_shallow_cnn()
model_1.fit(x_train, y_train, callbacks=[TensorBoard(log_dir=log_dir_1)])

# 實驗2: 深層CNN
log_dir_2 = "logs/fit/deep_cnn_" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
model_2 = build_deep_cnn()
model_2.fit(x_train, y_train, callbacks=[TensorBoard(log_dir=log_dir_2)])

# 在TensorBoard中對比兩個實驗
# tensorboard --logdir=logs/fit
```

> [!NOTE]
> TensorBoard非常強大,但對於簡單任務,直接用matplotlib繪製學習曲線可能更快速。

---

#### 6.3.5 Callbacks組合使用

**最佳實踐: 組合多個Callbacks**

```python
# 化工影像分類完整Callbacks配置
import datetime
from tensorflow.keras.callbacks import (
    EarlyStopping, ModelCheckpoint, 
    ReduceLROnPlateau, TensorBoard
)

# 1. 早停
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=15,
    restore_best_weights=True,
    verbose=1
)

# 2. 模型保存
checkpoint = ModelCheckpoint(
    filepath='best_model.h5',
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

# 3. 學習率衰減
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-7,
    verbose=1
)

# 4. TensorBoard
log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)

# 組合使用
callbacks = [early_stop, checkpoint, reduce_lr, tensorboard]

history = model.fit(
    x_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=callbacks,
    verbose=1
)
```

**Callbacks執行順序**:

```
每個Epoch結束時:
    1. ReduceLROnPlateau檢查是否需要降低學習率
    2. ModelCheckpoint檢查是否需要保存模型
    3. EarlyStopping檢查是否需要停止訓練
    4. TensorBoard記錄指標
```

---

### 6.4 訓練診斷與常見問題

#### 6.4.1 訓練過程診斷表

**症狀 → 診斷 → 解決方案**

| 症狀 | 可能原因 | 解決方案 |
|------|---------|---------|
| **訓練loss不下降** | 學習率過小 | 增大學習率 (0.001 → 0.01) |
| | 模型太簡單 | 增加層數或濾波器數量 |
| | 數據未正規化 | 檢查數據預處理 |
| **訓練loss震盪** | 學習率過大 | 降低學習率 (0.01 → 0.001) |
| | batch_size太小 | 增大batch_size |
| **訓練loss下降,驗證loss上升** | 過擬合 | 添加Dropout、數據增強、減少模型複雜度 |
| **訓練和驗證loss都很高** | 欠擬合 | 增加模型複雜度、訓練更多epochs |
| **訓練很慢** | batch_size太小 | 增大batch_size |
| | 影像尺寸太大 | 縮小影像尺寸 |
| | 模型太複雜 | 使用更輕量的架構 |
| **GPU記憶體不足** | batch_size太大 | 降低batch_size |
| | 影像尺寸太大 | 縮小影像尺寸 |
| | 模型太大 | 減少層數或濾波器 |

#### 6.4.2 訓練問題診斷流程圖

```
開始診斷
    │
    ├─ 訓練loss是否下降?
    │   ├─ 否 → 檢查學習率、數據預處理、模型架構
    │   └─ 是 → 繼續
    │
    ├─ 驗證loss是否下降?
    │   ├─ 否 → 過擬合!
    │   │   ├─ 添加Dropout
    │   │   ├─ 數據增強
    │   │   └─ 減少模型複雜度
    │   └─ 是 → 繼續
    │
    ├─ 訓練速度是否可接受?
    │   ├─ 否 → 增大batch_size、縮小影像、簡化模型
    │   └─ 是 → 繼續
    │
    └─ 準確率是否滿足需求?
        ├─ 否 → 增加數據、改進架構、調整超參數
        └─ 是 → 訓練成功! ✅
```

---

### 6.5 化工完整案例: 產品表面缺陷檢測

**任務描述**:
- 數據: 1200張產品表面影像 (512×512灰階)
- 類別: 5類 (正常、裂紋、劃痕、氣泡、污點)
- 目標: 建立自動檢測系統,準確率>95%

**完整訓練代碼**:

```python
import tensorflow as tf
from tensorflow.keras import models, layers
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt

# ========== 1. 數據準備 ==========
# 假設數據已經載入為 images (1200, 512, 512, 1), labels (1200,)

from sklearn.model_selection import train_test_split

# 分層分割 (保持類別比例)
x_train_val, x_test, y_train_val, y_test = train_test_split(
    images, labels,
    test_size=0.15,  # 15%測試集
    stratify=labels,
    random_state=42
)

x_train, x_val, y_train, y_val = train_test_split(
    x_train_val, y_train_val,
    test_size=0.18,  # ~15%驗證集 (0.85 × 0.18 ≈ 0.15)
    stratify=y_train_val,
    random_state=42
)

# 數據正規化
x_train = x_train.astype('float32') / 255.0
x_val = x_val.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# One-hot編碼
from tensorflow.keras.utils import to_categorical
y_train = to_categorical(y_train, 5)
y_val = to_categorical(y_val, 5)
y_test = to_categorical(y_test, 5)

print(f"訓練集: {x_train.shape}, 驗證集: {x_val.shape}, 測試集: {x_test.shape}")

# ========== 2. 建立模型 ==========
def build_defect_detector():
    model = models.Sequential([
        # Block 1
        layers.Conv2D(32, (3, 3), activation='relu', padding='same', 
                      input_shape=(512, 512, 1)),
        layers.BatchNormalization(),
        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Block 2
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Block 3
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Block 4
        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.GlobalAveragePooling2D(),
        
        # Classifier
        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(5, activation='softmax')
    ])
    
    return model

model = build_defect_detector()
model.summary()

# ========== 3. 編譯模型 ==========
from tensorflow.keras.optimizers import Adam

model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy', 'precision', 'recall']
)

# ========== 4. 配置Callbacks ==========
callbacks = [
    # 早停
    EarlyStopping(
        monitor='val_loss',
        patience=15,
        restore_best_weights=True,
        verbose=1
    ),
    
    # 模型保存
    ModelCheckpoint(
        filepath='best_defect_detector.h5',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    ),
    
    # 學習率衰減
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1
    )
]

# ========== 5. 數據增強 ==========
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2,
    brightness_range=[0.8, 1.2]
)

val_datagen = ImageDataGenerator()  # 驗證集不增強

# ========== 6. 訓練模型 ==========
print("開始訓練...")
history = model.fit(
    train_datagen.flow(x_train, y_train, batch_size=16),
    steps_per_epoch=len(x_train) // 16,
    epochs=100,
    validation_data=val_datagen.flow(x_val, y_val, batch_size=16),
    validation_steps=len(x_val) // 16,
    callbacks=callbacks,
    verbose=1
)

# ========== 7. 評估模型 ==========
test_loss, test_acc, test_prec, test_rec = model.evaluate(x_test, y_test)
print(f"\n測試集結果:")
print(f"準確率: {test_acc:.4f}")
print(f"精確率: {test_prec:.4f}")
print(f"召回率: {test_rec:.4f}")

# ========== 8. 視覺化訓練過程 ==========
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Loss
axes[0, 0].plot(history.history['loss'], label='訓練Loss')
axes[0, 0].plot(history.history['val_loss'], label='驗證Loss')
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('Loss')
axes[0, 0].legend()
axes[0, 0].set_title('Loss曲線')
axes[0, 0].grid(True)

# Accuracy
axes[0, 1].plot(history.history['accuracy'], label='訓練Accuracy')
axes[0, 1].plot(history.history['val_accuracy'], label='驗證Accuracy')
axes[0, 1].set_xlabel('Epoch')
axes[0, 1].set_ylabel('Accuracy')
axes[0, 1].legend()
axes[0, 1].set_title('Accuracy曲線')
axes[0, 1].grid(True)

# Learning Rate (如果有記錄)
if 'lr' in history.history:
    axes[1, 0].plot(history.history['lr'])
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('Learning Rate')
    axes[1, 0].set_title('Learning Rate變化')
    axes[1, 0].set_yscale('log')
    axes[1, 0].grid(True)

plt.tight_layout()
plt.savefig('training_history.png', dpi=300)
plt.show()

print(f"\n訓練完成! 最佳模型已保存至 'best_defect_detector.h5'")
print(f"實際訓練了 {len(history.history['loss'])} 個epochs")
```

**訓練結果分析**:

```
預期輸出:
Epoch 1/100
50/50 [==============================] - 45s - loss: 1.2345 - accuracy: 0.5234 - val_loss: 0.9876 - val_accuracy: 0.6543
...
Epoch 35/100
50/50 [==============================] - 42s - loss: 0.1234 - accuracy: 0.9654 - val_loss: 0.2345 - val_accuracy: 0.9543

Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0005.
...
Epoch 50/100
50/50 [==============================] - 42s - loss: 0.0876 - accuracy: 0.9765 - val_loss: 0.2123 - val_accuracy: 0.9612

Restoring model weights from the end of the best epoch: 45.
Epoch 00050: early stopping

測試集結果:
準確率: 0.9623
精確率: 0.9587
召回率: 0.9601

訓練完成! 最佳模型已保存至 'best_defect_detector.h5'
實際訓練了 50 個epochs
```

---

**本章小結**

恭喜!您已經掌握了CNN模型訓練的核心知識:

✅ **訓練流程**: 理解model.fit()的完整執行過程  
✅ **參數選擇**: 掌握epochs、batch_size、validation_split的選擇方法  
✅ **Callbacks機制**: 學會使用EarlyStopping、ModelCheckpoint、ReduceLROnPlateau  
✅ **問題診斷**: 能夠識別並解決訓練過程中的常見問題  
✅ **化工應用**: 完成了完整的產品缺陷檢測案例  

**關鍵要點回顧**:

| 概念 | 核心思想 | 化工類比 |
|------|---------|---------|
| Epochs | 訓練輪數 | 反應批次數 |
| Batch Size | 批次大小 | 進料批次 |
| Validation | 驗證集監控 | 中試驗證 |
| EarlyStopping | 防止過擬合 | 安全閥 |
| ModelCheckpoint | 保存最佳模型 | 數據記錄 |
| ReduceLROnPlateau | 學習率衰減 | PID控制 |

**實用配置模板**:

```python
# 化工影像分類標準訓練配置
callbacks = [
    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),
    ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)
]

history = model.fit(
    x_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=callbacks
)
```

> [!IMPORTANT]
> **記住三個原則**:
> 1. **使用Callbacks**: 不要手動監控訓練,讓Callbacks自動處理
> 2. **監控驗證集**: 訓練集準確率高不代表模型好,要看驗證集
> 3. **保存最佳模型**: 使用ModelCheckpoint保存最佳模型,不是最後一個epoch的模型

**下一步學習**:
- Chapter 7: 訓練歷史與視覺化 - 深入分析訓練曲線,診斷過擬合/欠擬合
- Chapter 8: 模型評估 - 混淆矩陣、分類報告、ROC曲線

---

## 7. 訓練歷史與視覺化

### 本章學習地圖

> [!IMPORTANT]
> **本章核心問題**: 如何通過訓練曲線診斷模型問題?如何解決過擬合和欠擬合?

**學習目標**:
1. 🎯 **理解History物件**: 掌握訓練歷史記錄的結構和使用
2. 📊 **視覺化訓練過程**: 學會繪製和解讀學習曲線
3. 🔍 **診斷模型問題**: 識別過擬合、欠擬合及其他訓練問題
4. 🛠️ **應用正則化技術**: 掌握Dropout、L2正則化、數據增強等方法

**為什麼訓練視覺化很重要?**

訓練曲線是模型的「健康檢查報告」:
- ❌ **盲目訓練**: 不知道模型是否學到東西,浪費時間
- ✅ **視覺化診斷**: 快速發現問題,針對性優化

**化工類比**:
- **訓練曲線** = 反應過程的溫度-時間曲線
- **過擬合** = 催化劑過度活化,產生副產物
- **欠擬合** = 反應溫度不足,轉化率低
- **正則化** = 添加抑制劑,控制反應選擇性

**本章架構**:

```
History物件 (7.1)
    ↓
視覺化訓練過程 (7.2)
    ├─ Loss曲線
    ├─ Accuracy曲線
    └─ 學習率曲線
    ↓
過擬合/欠擬合診斷 (7.3)
    ├─ 症狀識別
    ├─ 化工類比
    └─ 診斷決策樹
    ↓
正則化技術 (7.4)
    ├─ Dropout
    ├─ L2正則化
    ├─ 數據增強
    ├─ BatchNormalization
    └─ 技術對比表
    ↓
實際案例分析 (7.5)
```

> [!TIP]
> 學習建議:先學會繪製曲線,再學習解讀曲線,最後掌握問題解決方法。實踐中多觀察不同模型的訓練曲線!

---

### 7.1 History物件詳解

#### 7.1.1 什麼是History物件?

**定義**: `返回的`物件記錄了訓練過程中每個epoch的所有指標

**基本用法**:

```python
# 訓練模型
history = model.fit(
    x_train, y_train,
    epochs=50,
    batch_size=32,
    validation_split=0.2,
    verbose=1
)

# History物件包含什麼?
print(type(history))  # <class 'keras.callbacks.History'>
print(history.history.keys())  # dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
```

#### 7.1.2 History物件結構

**核心屬性**: ` 是一個字典,包含所有訓練指標

```python
history.history = {
    'loss': [1.234, 0.987, 0.765, ...],           # 訓練損失 (每個epoch一個值)
    'accuracy': [0.456, 0.678, 0.789, ...],       # 訓練準確率
    'val_loss': [1.345, 1.012, 0.876, ...],       # 驗證損失
    'val_accuracy': [0.445, 0.667, 0.778, ...],   # 驗證準確率
    'lr': [0.001, 0.001, 0.0005, ...],            # 學習率 (如果有ReduceLROnPlateau)
    'precision': [...],                            # 精確率 (如果有)
    'recall': [...]                                # 召回率 (如果有)
}
```

**訪問數據**:

```python
# 獲取訓練損失
train_loss = history.history['loss']
print(f"第1個epoch的訓練loss: {train_loss[0]:.4f}")
print(f"最後一個epoch的訓練loss: {train_loss[-1]:.4f}")

# 獲取驗證準確率
val_acc = history.history['val_accuracy']
best_val_acc = max(val_acc)
best_epoch = val_acc.index(best_val_acc) + 1
print(f"最佳驗證準確率: {best_val_acc:.4f}, 在第{best_epoch}個epoch")

# 計算訓練了多少個epoch
num_epochs = len(train_loss)
print(f"實際訓練了 {num_epochs} 個epochs")
```

**化工類比**:

| History概念 | 化工類比 | 說明 |
|-----------|---------|------|
| ` | 反應記錄本 | 記錄每個時間點的溫度、壓力、產率 |
| ` | 反應偏差 | 實際產率與目標產率的差距 |
| ` | 中試驗證偏差 | 在獨立樣本上的偏差 |
| ` | 產率 | 反應的轉化率 |
| ` | 反應溫度 | 控制反應速率的參數 |

---

### 7.2 視覺化訓練過程

#### 7.2.1 基本視覺化: Loss和Accuracy曲線

**標準繪圖代碼**:

```python
import matplotlib.pyplot as plt
import numpy as np

def plot_training_history(history):
    """
    繪製訓練歷史曲線
    """
    # 提取數據
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    accuracy = history.history['accuracy']
    val_accuracy = history.history['val_accuracy']
    epochs_range = range(1, len(loss) + 1)
    
    # 創建圖表
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # 左圖: Loss曲線
    axes[0].plot(epochs_range, loss, 'b-o', label='訓練Loss', linewidth=2, markersize=4)
    axes[0].plot(epochs_range, val_loss, 'r-s', label='驗證Loss', linewidth=2, markersize=4)
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].set_ylabel('Loss', fontsize=12)
    axes[0].set_title('訓練與驗證Loss', fontsize=14, fontweight='bold')
    axes[0].legend(fontsize=11)
    axes[0].grid(True, alpha=0.3)
    
    # 右圖: Accuracy曲線
    axes[1].plot(epochs_range, accuracy, 'b-o', label='訓練Accuracy', linewidth=2, markersize=4)
    axes[1].plot(epochs_range, val_accuracy, 'r-s', label='驗證Accuracy', linewidth=2, markersize=4)
    axes[1].set_xlabel('Epoch', fontsize=12)
    axes[1].set_ylabel('Accuracy', fontsize=12)
    axes[1].set_title('訓練與驗證Accuracy', fontsize=14, fontweight='bold')
    axes[1].legend(fontsize=11)
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 打印統計資訊
    print(f"最佳驗證Loss: {min(val_loss):.4f} (Epoch {val_loss.index(min(val_loss))+1})")
    print(f"最佳驗證Accuracy: {max(val_accuracy):.4f} (Epoch {val_accuracy.index(max(val_accuracy))+1})")
    print(f"最終訓練Accuracy: {accuracy[-1]:.4f}")
    print(f"最終驗證Accuracy: {val_accuracy[-1]:.4f}")
    print(f"訓練/驗證Accuracy差距: {(accuracy[-1] - val_accuracy[-1]):.4f}")

# 使用範例
plot_training_history(history)
```

#### 7.2.2 進階視覺化: 多指標綜合分析

```python
def plot_comprehensive_history(history):
    """
    綜合分析訓練歷史 (包含學習率)
    """
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    accuracy = history.history['accuracy']
    val_accuracy = history.history['val_accuracy']
    epochs_range = range(1, len(loss) + 1)
    
    # 1. Loss曲線
    axes[0, 0].plot(epochs_range, loss, 'b-', label='訓練Loss', linewidth=2)
    axes[0, 0].plot(epochs_range, val_loss, 'r-', label='驗證Loss', linewidth=2)
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].set_title('Loss曲線')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. Accuracy曲線
    axes[0, 1].plot(epochs_range, accuracy, 'b-', label='訓練Accuracy', linewidth=2)
    axes[0, 1].plot(epochs_range, val_accuracy, 'r-', label='驗證Accuracy', linewidth=2)
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Accuracy')
    axes[0, 1].set_title('Accuracy曲線')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. 訓練/驗證差距 (過擬合指標)
    gap = np.array(accuracy) - np.array(val_accuracy)
    axes[1, 0].plot(epochs_range, gap, 'g-', linewidth=2)
    axes[1, 0].axhline(y=0.05, color='orange', linestyle='--', label='警戒線 (5%)')
    axes[1, 0].axhline(y=0.10, color='red', linestyle='--', label='危險線 (10%)')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('Accuracy差距')
    axes[1, 0].set_title('過擬合監控 (訓練-驗證Accuracy)')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # 4. 學習率變化 (如果有)
    if 'lr' in history.history:
        lr = history.history['lr']
        axes[1, 1].plot(epochs_range, lr, 'purple', linewidth=2)
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('Learning Rate')
        axes[1, 1].set_title('學習率變化')
        axes[1, 1].set_yscale('log')
        axes[1, 1].grid(True, alpha=0.3)
    else:
        axes[1, 1].text(0.5, 0.5, '無學習率記錄', 
                       ha='center', va='center', fontsize=14)
        axes[1, 1].axis('off')
    
    plt.tight_layout()
    plt.savefig('comprehensive_history.png', dpi=300, bbox_inches='tight')
    plt.show()

# 使用範例
plot_comprehensive_history(history)
```

---

### 7.3 過擬合/欠擬合診斷

#### 7.3.1 三種典型訓練曲線

**1. 正常訓練 (Good Fit) ✅**

```
Loss曲線:
訓練Loss: ↘↘↘ (持續下降,最終穩定)
驗證Loss: ↘↘↘ (跟隨訓練loss下降)

Accuracy曲線:
訓練Acc: ↗↗↗ (持續上升,最終穩定在95-98%)
驗證Acc: ↗↗↗ (跟隨訓練acc上升,最終穩定在93-96%)

特徵:
- 訓練/驗證曲線走勢一致
- 差距小 (<5%)
- 最終都收斂到較高水平
```

**化工類比**: 反應條件適當,產率穩定提升,小試和中試結果一致

**2. 過擬合 (Overfitting) ❌**

```
Loss曲線:
訓練Loss: ↘↘↘ (持續下降,接近0)
驗證Loss: ↘↗↗ (先降後升,呈U型)

Accuracy曲線:
訓練Acc: ↗↗↗ (持續上升,達到99%+)
驗證Acc: ↗→→ (上升後停滯或下降,停在85-90%)

特徵:
- 訓練/驗證曲線分叉
- 差距大 (>10%)
- 訓練指標極好,驗證指標差
```

**化工類比**: 
- 催化劑過度活化,只對標準品有效
- 小試產率99%,中試產率只有85%
- 反應條件過於「記憶」特定原料,泛化能力差

**3. 欠擬合 (Underfitting) ❌**

```
Loss曲線:
訓練Loss: ↘→→ (下降後停滯在高位)
驗證Loss: ↘→→ (同樣停滯在高位)

Accuracy曲線:
訓練Acc: ↗→→ (上升後停滯在70-80%)
驗證Acc: ↗→→ (同樣停滯在70-80%)

特徵:
- 訓練/驗證曲線走勢一致
- 差距小 (<3%)
- 但兩者都停在較低水平
```

**化工類比**:
- 反應溫度不足,轉化率低
- 小試和中試產率都只有70%
- 反應條件需要優化

#### 7.3.2 診斷決策樹

```
開始診斷訓練曲線
    │
    ├─ 訓練Loss是否下降?
    │   ├─ 否 → 欠擬合! (模型太簡單或學習率過小)
    │   │   ├─ 增加模型複雜度 (更多層/濾波器)
    │   │   ├─ 增大學習率
    │   │   └─ 訓練更多epochs
    │   └─ 是 → 繼續
    │
    ├─ 驗證Loss是否下降?
    │   ├─ 否 → 檢查驗證Loss走勢
    │   │   ├─ 先降後升 (U型) → 過擬合!
    │   │   │   ├─ 添加Dropout
    │   │   │   ├─ 數據增強
    │   │   │   ├─ L2正則化
    │   │   │   └─ 減少模型複雜度
    │   │   └─ 一直很高 → 欠擬合!
    │   └─ 是 → 繼續
    │
    ├─ 訓練/驗證Accuracy差距是多少?
    │   ├─ >10% → 過擬合!
    │   ├─ 5-10% → 輕微過擬合,可以接受或微調
    │   └─ <5% → 繼續
    │
    └─ 驗證Accuracy是否滿足需求?
        ├─ 是 → 訓練成功! ✅
        └─ 否 → 需要改進
            ├─ 增加數據量
            ├─ 改進數據質量
            ├─ 嘗試更好的架構
            └─ 調整超參數
```

#### 7.3.3 診斷對比表

| 指標 | 欠擬合 | 正常 | 過擬合 |
|------|--------|------|--------|
| **訓練Loss** | 高 (>0.5) | 低 (0.1-0.3) | 極低 (<0.05) |
| **驗證Loss** | 高 (>0.5) | 低 (0.15-0.35) | 中高 (0.3-0.6) |
| **訓練Acc** | 低 (<85%) | 高 (93-97%) | 極高 (>99%) |
| **驗證Acc** | 低 (<85%) | 高 (91-95%) | 中 (85-92%) |
| **訓練/驗證差距** | 小 (<3%) | 小 (<5%) | 大 (>10%) |
| **驗證Loss走勢** | 平穩高位 | 持續下降 | 先降後升(U型) |
| **化工類比** | 反應不充分 | 反應適當 | 過度反應 |
| **解決方案** | 增加容量 | 保持 | 正則化 |

---

### 7.4 正則化技術

#### 7.4.1 Dropout (隨機失活)

**原理**: 訓練時隨機「關閉」一定比例的神經元,防止模型過度依賴特定神經元

**數學表示**:

$$
\mathbf{h}_{\text{dropout}} = \mathbf{h} \odot \mathbf{m}, \quad m_i \sim \text{Bernoulli}(p)
$$

其中:
- $\mathbf{h}$: 原始激活值
- $\mathbf{m}$: 隨機mask (0或1)
- $p$: 保留概率 (例如0.5表示保留50%)

**直覺理解**:

```
訓練時 (Dropout=0.5):
完整網路: [N1][N2][N3][N4][N5][N6][N7][N8]
Batch 1:  [N1][  ][N3][  ][N5][N6][  ][N8]  ← 隨機關閉N2,N4,N7
Batch 2:  [  ][N2][  ][N4][N5][  ][N7][  ]  ← 隨機關閉N1,N3,N6,N8
...
效果: 每個batch訓練不同的子網路,類似集成學習

測試時:
使用完整網路,但權重乘以保留概率 (Keras自動處理)
```

**使用方式**:

```python
from tensorflow.keras import layers

model = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    
    # 在全連接層添加Dropout
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),  # 訓練時隨機丟棄50%神經元
    
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),  # 較淺層可以用較小的dropout rate
    
    layers.Dense(10, activation='softmax')
])
```

**Dropout rate選擇建議**:

| 層類型 | 建議Dropout rate | 說明 |
|--------|-----------------|------|
| 卷積層後 | 0.2-0.3 | 卷積層已有參數共享,dropout較小 |
| 第一個全連接層 | 0.5 | 全連接層最容易過擬合 |
| 後續全連接層 | 0.3-0.4 | 逐層遞減 |
| 輸出層前 | 0.2-0.3 | 不要太大,影響輸出 |

**化工類比**:
- **Dropout** = 隨機關閉部分反應器
- 強迫系統學會在不同配置下都能工作
- 類似「冗餘設計」,提高系統魯棒性

> [!TIP]
> **Dropout使用技巧**:
> - 從0.5開始嘗試,根據效果調整
> - 如果驗證準確率提升 → dropout有效
> - 如果訓練變慢但準確率沒提升 → 減小dropout rate
> - Dropout只在訓練時啟用,預測時自動關閉

---

#### 7.4.2 L2正則化 (Weight Decay)

**原理**: 在損失函數中添加權重懲罰項,限制權重大小

**數學表示**:

$$
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{CE}} + \lambda \sum_{i} w_i^2
$$

其中:
- $\mathcal{L}_{\text{CE}}$: 交叉熵損失
- $\lambda$: 正則化強度 (通常0.0001-0.01)
- $w_i$: 模型權重

**直覺理解**:
- 大權重會被懲罰 → 模型傾向使用更多小權重
- 防止模型過度依賴少數特徵
- 類似「分散投資」,降低風險

**使用方式**:

```python
from tensorflow.keras import regularizers

model = models.Sequential([
    # 在卷積層添加L2正則化
    layers.Conv2D(64, (3, 3), activation='relu',
                  kernel_regularizer=regularizers.l2(0.001),  # L2正則化
                  input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    
    layers.Flatten(),
    
    # 在全連接層添加L2正則化
    layers.Dense(256, activation='relu',
                 kernel_regularizer=regularizers.l2(0.01)),  # 全連接層用較大值
    
    layers.Dense(10, activation='softmax')
])
```

**正則化強度選擇**:

| λ值 | 效果 | 適用場景 |
|-----|------|---------|
| 0.0001 | 輕微正則化 | 數據量大,輕微過擬合 |
| 0.001 | 標準正則化 | 大多數情況 |
| 0.01 | 強正則化 | 數據量小,嚴重過擬合 |
| 0.1 | 過強 | 可能導致欠擬合 |

**L1 vs L2正則化**:

| 特性 | L1正則化 | L2正則化 |
|------|---------|---------|
| **懲罰項** | $\lambda \sum \|w_i\|$ | $\lambda \sum w_i^2$ |
| **效果** | 產生稀疏權重 (很多權重=0) | 權重均勻縮小 |
| **特徵選擇** | 自動特徵選擇 | 保留所有特徵 |
| **適用場景** | 特徵很多,需要選擇 | 一般情況 |
| **Keras用法** | ` | ` |

**化工類比**:
- **L2正則化** = 限制反應條件的極端值
- 避免溫度、壓力過高導致副反應
- 保持系統在安全、穩定的範圍內

---

#### 7.4.3 數據增強 (Data Augmentation)

**原理**: 通過隨機變換擴充訓練集,模擬真實世界的變化

**為什麼有效?**
- 增加訓練數據的多樣性
- 模型學到更魯棒的特徵
- 相當於「免費」增加數據量

**常用變換**:

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 創建數據增強器
datagen = ImageDataGenerator(
    rotation_range=20,           # 隨機旋轉 ±20度
    width_shift_range=0.2,       # 水平平移 ±20%
    height_shift_range=0.2,      # 垂直平移 ±20%
    horizontal_flip=True,        # 水平翻轉
    vertical_flip=False,         # 垂直翻轉 (根據任務決定)
    zoom_range=0.2,              # 縮放 ±20%
    brightness_range=[0.8, 1.2], # 亮度調整 80%-120%
    shear_range=0.2,             # 剪切變換
    fill_mode='nearest'          # 填充模式
)

# 使用數據增強訓練
history = model.fit(
    datagen.flow(x_train, y_train, batch_size=32),
    steps_per_epoch=len(x_train) // 32,
    epochs=50,
    validation_data=(x_val, y_val)  # 驗證集不增強!
)
```

**化工應用場景**:

| 應用 | 適用的增強方法 | 不適用的增強 |
|------|--------------|-------------|
| **產品缺陷檢測** | 旋轉、翻轉、亮度調整 | 顏色變換 (缺陷顏色重要) |
| **顯微影像分析** | 旋轉、縮放、對比度調整 | 翻轉 (可能改變結構) |
| **光譜影像** | 亮度調整、縮放 | 旋轉、翻轉 (空間位置重要) |
| **安全監控** | 亮度調整、縮放 | 翻轉 (方向重要) |

**數據增強強度選擇**:

```python
# 輕度增強 (數據量中等,1000-5000張)
datagen_light = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    horizontal_flip=True
)

# 中度增強 (數據量較少,500-1000張)
datagen_medium = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2
)

# 強度增強 (數據量很少,<500張)
datagen_strong = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.3,
    height_shift_range=0.3,
    horizontal_flip=True,
    vertical_flip=True,
    zoom_range=0.3,
    brightness_range=[0.7, 1.3],
    shear_range=0.2
)
```

> [!WARNING]
> **數據增強注意事項**:
> - 只對訓練集增強,驗證集和測試集不增強!
> - 增強方法要符合實際應用場景
> - 過度增強可能引入不真實的變化,反而降低性能

---

#### 7.4.4 BatchNormalization (批次正規化)

**原理**: 對每個batch的數據進行正規化,加速訓練並具有正則化效果

**數學表示**:

$$
\hat{x} = \frac{x - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}
$$

$$
y = \gamma \hat{x} + \beta
$$

其中:
- $\mu_B$, $\sigma_B^2$: batch的均值和方差
- $\gamma$, $\beta$: 可學習的縮放和平移參數
- $\epsilon$: 數值穩定性常數

**使用方式**:

```python
model = models.Sequential([
    # 方法1: 在激活函數之前
    layers.Conv2D(64, (3, 3), use_bias=False, input_shape=(224, 224, 3)),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPooling2D((2, 2)),
    
    # 方法2: 在激活函數之後 (也可以)
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    
    layers.Flatten(),
    layers.Dense(256),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.Dense(10, activation='softmax')
])
```

**BatchNorm的效果**:

| 效果 | 說明 | 化工類比 |
|------|------|---------|
| **加速訓練** | 允許使用更大學習率 | 提高反應溫度而不失控 |
| **減少對初始化的敏感性** | 權重初始化不那麼重要 | 反應對初始條件不敏感 |
| **正則化效果** | 類似Dropout,防止過擬合 | 穩定反應過程 |
| **允許更深網路** | 緩解梯度消失問題 | 允許更複雜的反應路徑 |

**BatchNorm vs Dropout**:

| 特性 | BatchNorm | Dropout |
|------|-----------|---------|
| **主要目的** | 加速訓練 | 防止過擬合 |
| **副作用** | 有正則化效果 | 減慢訓練 |
| **使用位置** | 每層都可以 | 主要在全連接層 |
| **能否同時使用** | 可以,但通常選一個 | 可以,但通常選一個 |
| **化工應用建議** | 深層網路優先使用 | 小數據集優先使用 |

---

#### 7.4.5 正則化技術對比總表

| 技術 | 原理 | 優點 | 缺點 | 適用場景 | 化工類比 |
|------|------|------|------|---------|---------|
| **Dropout** | 隨機失活神經元 | 簡單有效 | 訓練變慢 | 全連接層過擬合 | 冗餘設計 |
| **L2正則化** | 懲罰大權重 | 穩定,理論清晰 | 需要調λ | 一般過擬合 | 限制極端條件 |
| **數據增強** | 擴充訓練集 | 最有效 | 需要領域知識 | 數據量小 | 增加實驗樣本 |
| **BatchNorm** | 正規化激活值 | 加速訓練 | 增加計算量 | 深層網路 | 穩定反應條件 |
| **EarlyStopping** | 提前停止訓練 | 簡單,無副作用 | 可能停太早 | 所有情況 | 安全閥 |

**組合使用建議**:

```python
# 化工影像分類標準配置 (數據量500-2000張)
model = models.Sequential([
    # 卷積塊: BatchNorm + 輕度Dropout
    layers.Conv2D(32, (3, 3), use_bias=False, input_shape=(224, 224, 3)),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),  # 輕度dropout
    
    layers.Conv2D(64, (3, 3), use_bias=False),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),
    
    # 全連接層: 強Dropout + L2正則化
    layers.Flatten(),
    layers.Dense(256, activation='relu',
                 kernel_regularizer=regularizers.l2(0.01)),  # L2正則化
    layers.Dropout(0.5),  # 強dropout
    layers.Dense(10, activation='softmax')
])

# 配合數據增強和EarlyStopping
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    horizontal_flip=True
)

callbacks = [
    EarlyStopping(patience=15, restore_best_weights=True)
]

history = model.fit(
    datagen.flow(x_train, y_train, batch_size=32),
    epochs=100,
    validation_data=(x_val, y_val),
    callbacks=callbacks
)
```

---

### 7.5 實際案例分析

#### 7.5.1 案例1: 過擬合診斷與解決

**問題描述**:
- 任務: 化工產品缺陷檢測
- 數據: 800張影像 (5類缺陷)
- 症狀: 訓練準確率99%, 驗證準確率85%

**訓練曲線分析**:

```python
# 繪製訓練曲線
plot_training_history(history)

# 輸出:
# 訓練Loss: 0.02 (極低)
# 驗證Loss: 0.65 (較高)
# 訓練Acc: 99.2%
# 驗證Acc: 84.5%
# 差距: 14.7% → 嚴重過擬合!
```

**診斷**:
1. ✅ 訓練Loss極低 → 模型有學習能力
2. ❌ 驗證Loss高 → 泛化能力差
3. ❌ 訓練/驗證差距>10% → 過擬合

**解決方案**:

```python
# 原始模型 (過擬合)
model_original = models.Sequential([
    layers.Conv2D(128, (3, 3), activation='relu', input_shape=(256, 256, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(256, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(512, activation='relu'),  # 參數太多!
    layers.Dense(5, activation='softmax')
])

# 改進模型 (添加正則化)
model_improved = models.Sequential([
    # 減少濾波器數量
    layers.Conv2D(32, (3, 3), use_bias=False, input_shape=(256, 256, 1)),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),  # 添加dropout
    
    layers.Conv2D(64, (3, 3), use_bias=False),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),
    
    # 使用GlobalAveragePooling替代Flatten+Dense
    layers.GlobalAveragePooling2D(),  # 大幅減少參數
    layers.Dense(128, activation='relu',
                 kernel_regularizer=regularizers.l2(0.01)),
    layers.Dropout(0.5),
    layers.Dense(5, activation='softmax')
])

# 配合數據增強
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2
)

# 訓練改進模型
history_improved = model_improved.fit(
    datagen.flow(x_train, y_train, batch_size=16),  # 小batch
    epochs=100,
    validation_data=(x_val, y_val),
    callbacks=[
        EarlyStopping(patience=15, restore_best_weights=True),
        ReduceLROnPlateau(patience=5, factor=0.5)
    ]
)

# 結果對比
print("原始模型: 訓練Acc=99.2%, 驗證Acc=84.5%, 差距=14.7%")
print("改進模型: 訓練Acc=96.8%, 驗證Acc=94.2%, 差距=2.6%")
```

**改進效果**:
- 驗證準確率: 84.5% → 94.2% (提升9.7%)
- 過擬合程度: 14.7% → 2.6% (大幅改善)
- 模型更穩定,泛化能力強

---

#### 7.5.2 案例2: 欠擬合診斷與解決

**問題描述**:
- 任務: 顯微影像晶體分類
- 數據: 2000張影像 (10類晶體)
- 症狀: 訓練和驗證準確率都只有75%

**診斷**:
1. ❌ 訓練Acc低 (<80%) → 模型學習能力不足
2. ❌ 驗證Acc也低 → 不是過擬合問題
3. ✅ 訓練/驗證差距小 (<3%) → 確認是欠擬合

**解決方案**:

```python
# 原始模型 (欠擬合,太簡單)
model_simple = models.Sequential([
    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(10, activation='softmax')
])

# 改進模型 (增加容量)
model_complex = models.Sequential([
    # 增加層數和濾波器
    layers.Conv2D(32, (3, 3), activation='relu', padding='same',
                  input_shape=(128, 128, 1)),
    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2)),
    
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(10, activation='softmax')
])

# 使用更大學習率
from tensorflow.keras.optimizers import Adam
optimizer = Adam(learning_rate=0.001)  # 原本可能是0.0001

model_complex.compile(
    optimizer=optimizer,
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 訓練更多epochs
history_complex = model_complex.fit(
    x_train, y_train,
    epochs=100,  # 原本可能只有20
    batch_size=32,
    validation_data=(x_val, y_val)
)

# 結果對比
print("簡單模型: 訓練Acc=75%, 驗證Acc=74%")
print("複雜模型: 訓練Acc=94%, 驗證Acc=92%")
```

---

**本章小結**

恭喜!您已經掌握了訓練歷史視覺化與診斷的核心知識:

✅ **History物件**: 理解訓練歷史記錄的結構和使用  
✅ **視覺化技術**: 學會繪製和解讀Loss/Accuracy曲線  
✅ **問題診斷**: 能夠識別過擬合、欠擬合及其他訓練問題  
✅ **正則化技術**: 掌握Dropout、L2、數據增強、BatchNorm  
✅ **實際案例**: 完成了過擬合和欠擬合的診斷與解決  

**關鍵要點回顧**:

| 概念 | 核心思想 | 化工類比 |
|------|---------|---------|
| 過擬合 | 訓練好驗證差 | 只對標準品有效 |
| 欠擬合 | 訓練驗證都差 | 反應條件不足 |
| Dropout | 隨機失活 | 冗餘設計 |
| L2正則化 | 懲罰大權重 | 限制極端條件 |
| 數據增強 | 擴充訓練集 | 增加實驗樣本 |
| BatchNorm | 正規化激活 | 穩定反應條件 |

**診斷流程圖**:

```
訓練曲線
    ↓
訓練Loss下降? → 否 → 欠擬合 → 增加容量/學習率
    ↓ 是
驗證Loss下降? → 否 → 過擬合 → 正則化
    ↓ 是
訓練/驗證差距<5%? → 否 → 輕微過擬合 → 微調
    ↓ 是
驗證Acc滿足需求? → 是 → 成功! ✅
    ↓ 否
改進數據/架構
```

> [!IMPORTANT]
> **記住三個原則**:
> 1. **先看曲線再調參**: 不要盲目調參,先診斷問題
> 2. **正則化組合使用**: Dropout + 數據增強 + EarlyStopping效果最好
> 3. **驗證集是關鍵**: 訓練準確率高不代表模型好,要看驗證集

**下一步學習**:
- Chapter 8: 模型評估 - 混淆矩陣、分類報告、評估指標詳解
- Chapter 9: 模型預測與部署 - 實際應用和工業部署

---

## 8. 模型評估

### 本章學習地圖

> [!IMPORTANT]
> **本章核心問題**: 如何全面評估CNN模型性能?如何選擇合適的評估指標?

**學習目標**:
1. 🎯 **掌握評估指標**: 理解Accuracy, Precision, Recall, F1-Score的含義和應用
2. 📊 **分析混淆矩陣**: 學會解讀混淆矩陣,發現模型的系統性錯誤
3. 💰 **成本敏感決策**: 在化工應用中考慮不同錯誤的成本
4. 📈 **綜合評估策略**: 建立完整的模型評估流程

**為什麼模型評估很重要?**

準確率不是唯一指標,需要全面評估:
- ❌ **只看準確率**: 可能忽略關鍵問題(如類別不平衡)
- ✅ **綜合評估**: 發現模型弱點,針對性改進

**化工類比**:
- **模型評估** = 產品品質檢驗
- **Accuracy** = 總合格率
- **Precision** = 判定為合格的產品中真正合格的比例
- **Recall** = 所有合格產品中被正確識別的比例
- **混淆矩陣** = 詳細的品質分析報告

**本章架構**:

```
評估基礎 (8.1)
    ↓
評估指標詳解 (8.2)
    ├─ Accuracy
    ├─ Precision
    ├─ Recall
    ├─ F1-Score
    └─ 指標選擇指南
    ↓
混淆矩陣分析 (8.3)
    ├─ 混淆矩陣解讀
    ├─ 化工類比
    └─ 視覺化技巧
    ↓
成本敏感決策 (8.4)
    └─ 化工應用案例
    ↓
綜合評估策略 (8.5)
```

> [!TIP]
> 學習建議:先理解各個指標的定義,再學習如何根據實際需求選擇指標。化工應用中,成本考量非常重要!

---

### 8.1 評估基礎

#### 8.1.1 model.evaluate() 方法

**功能**: 在測試集上評估模型性能

**基本用法**:

```python
# 在測試集上評估
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)

print(f"測試集Loss: {test_loss:.4f}")
print(f"測試集Accuracy: {test_acc:.4f}")
```

**返回值**:
- 如果只有loss: 返回單一值
- 如果有多個指標: 返回列表

**完整範例**:

```python
# 編譯時指定多個指標
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy', 'precision', 'recall']
)

# 評估返回所有指標
results = model.evaluate(x_test, y_test, verbose=1)
test_loss, test_acc, test_prec, test_rec = results

print(f"Loss: {test_loss:.4f}")
print(f"Accuracy: {test_acc:.4f}")
print(f"Precision: {test_prec:.4f}")
print(f"Recall: {test_rec:.4f}")
```

#### 8.1.2 獲取預測結果

```python
# 獲取預測機率
y_pred_proba = model.predict(x_test)  # shape: (n_samples, n_classes)

# 獲取預測類別
import numpy as np
y_pred_classes = np.argmax(y_pred_proba, axis=1)

# 如果y_test是one-hot編碼,需要轉換
if len(y_test.shape) > 1:
    y_true_classes = np.argmax(y_test, axis=1)
else:
    y_true_classes = y_test

print(f"預測形狀: {y_pred_proba.shape}")
print(f"預測類別: {y_pred_classes[:10]}")
print(f"真實類別: {y_true_classes[:10]}")
```

---

### 8.2 評估指標詳解

#### 8.2.1 Accuracy (準確率)

**定義**: 所有預測中,正確預測的比例

$$
\text{Accuracy} = \frac{\text{正確預測數}}{\text{總樣本數}} = \frac{TP + TN}{TP + TN + FP + FN}
$$

**直覺理解**: 
- 100個樣本,預測對95個 → Accuracy = 95%

**化工類比**:
- **總合格率**: 所有產品中合格的比例
- 1000個產品,950個判定正確 → 準確率95%

**優點**:
- ✅ 直觀易懂
- ✅ 適合類別平衡的問題

**缺點**:
- ❌ 類別不平衡時會誤導

**類別不平衡問題範例**:

```python
# 化工案例: 缺陷檢測
# 正常產品: 950個
# 缺陷產品: 50個

# 模型1: 全部預測為正常
# Accuracy = 950/1000 = 95% (看起來很好!)
# 但完全沒有檢測到缺陷! ❌

# 模型2: 正確識別45個缺陷,誤判10個正常為缺陷
# Accuracy = (940+45)/1000 = 98.5%
# 這才是有用的模型! ✅
```

> [!WARNING]
> **類別不平衡時不要只看Accuracy!**
> - 缺陷檢測、異常檢測等場景
> - 需要配合Precision、Recall等指標

---

#### 8.2.2 Precision (精確率)

**定義**: 預測為正類的樣本中,真正為正類的比例

$$
\text{Precision} = \frac{TP}{TP + FP}
$$

其中:
- TP (True Positive): 真正例 (預測為正,實際為正)
- FP (False Positive): 假正例 (預測為正,實際為負)

**直覺理解**:
- 模型說「這是缺陷」,有多少是真的缺陷?

**化工類比**:
- **誤報率的反面**: 判定為不合格的產品中,真正不合格的比例
- 模型報警100次,其中90次是真的缺陷 → Precision = 90%

**何時重要?**
- ❌ **誤報成本高**: 誤判正常為缺陷,導致浪費
- 例如: 產品被誤判為不合格,需要報廢或返工

**計算範例**:

```python
from sklearn.metrics import precision_score

# 二元分類
precision = precision_score(y_true, y_pred)

# 多類別分類 (計算每個類別的precision)
precision_per_class = precision_score(y_true, y_pred, average=None)

# 加權平均 (考慮類別樣本數)
precision_weighted = precision_score(y_true, y_pred, average='weighted')

print(f"Precision (加權): {precision_weighted:.4f}")
print(f"各類別Precision: {precision_per_class}")
```

---

#### 8.2.3 Recall (召回率)

**定義**: 實際為正類的樣本中,被正確預測的比例

$$
\text{Recall} = \frac{TP}{TP + FN}
$$

其中:
- FN (False Negative): 假負例 (預測為負,實際為正)

**直覺理解**:
- 所有真正的缺陷中,模型找到了多少?

**化工類比**:
- **漏檢率的反面**: 所有不合格產品中,被正確識別的比例
- 實際有100個缺陷,模型找到85個 → Recall = 85%

**何時重要?**
- ❌ **漏檢成本高**: 缺陷產品流入市場,造成嚴重後果
- 例如: 藥品缺陷、安全隱患

**計算範例**:

```python
from sklearn.metrics import recall_score

# 二元分類
recall = recall_score(y_true, y_pred)

# 多類別分類
recall_per_class = recall_score(y_true, y_pred, average=None)
recall_weighted = recall_score(y_true, y_pred, average='weighted')

print(f"Recall (加權): {recall_weighted:.4f}")
print(f"各類別Recall: {recall_per_class}")
```

---

#### 8.2.4 F1-Score (F1分數)

**定義**: Precision和Recall的調和平均

$$
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
$$

**為什麼用調和平均?**
- 算術平均: $(P + R) / 2$ → 容易被高值主導
- 調和平均: 只有P和R都高時,F1才高

**範例**:
```
模型A: Precision=90%, Recall=10%
  算術平均 = 50% (誤導!)
  F1 = 18% (真實反映性能差)

模型B: Precision=80%, Recall=85%
  算術平均 = 82.5%
  F1 = 82.4% (接近)
```

**化工類比**:
- **綜合品質指標**: 同時考慮誤報和漏檢
- 需要在兩者之間取得平衡

**計算範例**:

```python
from sklearn.metrics import f1_score

f1 = f1_score(y_true, y_pred, average='weighted')
f1_per_class = f1_score(y_true, y_pred, average=None)

print(f"F1-Score (加權): {f1:.4f}")
print(f"各類別F1: {f1_per_class}")
```

---

#### 8.2.5 指標選擇指南

**決策樹**:

```
開始選擇評估指標
    │
    ├─ 類別是否平衡?
    │   ├─ 是 → Accuracy即可
    │   └─ 否 → 繼續
    │
    ├─ 誤報成本 vs 漏檢成本?
    │   ├─ 誤報成本高 → 優先Precision
    │   │   例如: 誤判正常為缺陷,浪費成本
    │   ├─ 漏檢成本高 → 優先Recall
    │   │   例如: 缺陷流入市場,安全問題
    │   └─ 兩者都重要 → 使用F1-Score
    │
    └─ 是否需要調整決策閾值?
        ├─ 是 → 使用ROC曲線、PR曲線
        └─ 否 → 使用標準指標
```

**化工應用場景對比**:

| 應用場景 | 主要指標 | 原因 | 範例 |
|---------|---------|------|------|
| **產品缺陷檢測** | Recall | 漏檢成本高 | 缺陷產品流入市場 |
| **原料品質篩選** | Precision | 誤報成本高 | 誤判合格原料為不合格 |
| **製程異常檢測** | F1-Score | 兩者都重要 | 平衡誤報和漏檢 |
| **安全監控** | Recall | 漏檢成本極高 | 安全隱患不能漏 |
| **自動分類** | Accuracy | 類別平衡 | 一般分類任務 |

---

### 8.3 混淆矩陣分析

#### 8.3.1 混淆矩陣定義

**定義**: 對於K類分類問題,混淆矩陣是K×K方陣,元素C[i,j]表示「真實類別為i,預測為j」的樣本數

**二元分類混淆矩陣**:

```
                預測
              正類  負類
真  正類  |  TP  |  FN  |
實  負類  |  FP  |  TN  |
```

**多類別混淆矩陣** (以5類缺陷為例):

```
          預測類別
        0    1    2    3    4
真 0 | 45    2    1    0    2  |
實 1 |  1   38    3    2    1  |
類 2 |  0    2   42    1    0  |
別 3 |  1    1    0   43    0  |
   4 |  2    0    1    1   41  |
```

**解讀**:
- **對角線**: 正確預測 (越大越好)
- **非對角線**: 錯誤預測 (揭示混淆模式)

#### 8.3.2 計算和視覺化

**完整代碼**:

```python
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# 計算混淆矩陣
y_pred_classes = np.argmax(model.predict(x_test), axis=1)
y_true_classes = np.argmax(y_test, axis=1) if len(y_test.shape) > 1 else y_test

cm = confusion_matrix(y_true_classes, y_pred_classes)

# 方法1: 使用sklearn的ConfusionMatrixDisplay
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# 絕對數量
disp1 = ConfusionMatrixDisplay(confusion_matrix=cm)
disp1.plot(ax=axes[0], cmap='Blues', values_format='d')
axes[0].set_title('混淆矩陣 (絕對數量)', fontsize=14, fontweight='bold')

# 正規化 (百分比)
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
disp2 = ConfusionMatrixDisplay(confusion_matrix=cm_normalized)
disp2.plot(ax=axes[1], cmap='Blues', values_format='.2f')
axes[1].set_title('混淆矩陣 (正規化)', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.show()

# 方法2: 使用seaborn (更美觀)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', 
            cbar_kws={'label': '樣本數'},
            linewidths=0.5, linecolor='gray')
plt.xlabel('預測類別', fontsize=12)
plt.ylabel('真實類別', fontsize=12)
plt.title('混淆矩陣熱圖', fontsize=14, fontweight='bold')
plt.show()

# 分析每個類別的準確率
print("各類別準確率:")
for i in range(len(cm)):
    class_acc = cm[i, i] / cm[i, :].sum()
    print(f"類別 {i}: {class_acc:.4f} ({class_acc*100:.2f}%)")
```

#### 8.3.3 混淆模式分析

**找出最容易混淆的類別對**:

```python
def analyze_confusion_patterns(cm, class_names=None):
    """
    分析混淆矩陣,找出容易混淆的類別
    """
    n_classes = len(cm)
    if class_names is None:
        class_names = [f"類別{i}" for i in range(n_classes)]
    
    # 找出所有錯誤
    errors = []
    for i in range(n_classes):
        for j in range(n_classes):
            if i != j and cm[i, j] > 0:
                error_rate = cm[i, j] / cm[i, :].sum()
                errors.append({
                    'true_class': class_names[i],
                    'pred_class': class_names[j],
                    'count': cm[i, j],
                    'error_rate': error_rate
                })
    
    # 按錯誤數量排序
    errors_sorted = sorted(errors, key=lambda x: x['count'], reverse=True)
    
    print("最容易混淆的類別對 (Top 10):")
    print("-" * 70)
    for idx, err in enumerate(errors_sorted[:10], 1):
        print(f"{idx}. {err['true_class']} → {err['pred_class']}: "
              f"{err['count']}次 ({err['error_rate']*100:.1f}%)")
    
    return errors_sorted

# 使用範例
class_names = ['正常', '裂紋', '劃痕', '氣泡', '污點']
errors = analyze_confusion_patterns(cm, class_names)
```

**化工類比**:

```
混淆矩陣分析 = 品質問題根因分析

範例: 產品缺陷檢測
混淆矩陣顯示:
- 「裂紋」常被誤判為「劃痕」 (30次)
  → 原因: 兩者視覺特徵相似
  → 解決: 增加這兩類的訓練樣本,或改進特徵提取

- 「氣泡」很少被誤判 (僅5次)
  → 原因: 特徵明顯,容易識別
  → 結論: 這個類別的模型很可靠
```

---

### 8.4 成本敏感決策

#### 8.4.1 化工應用中的成本考量

**不同錯誤有不同成本**:

| 錯誤類型 | 化工案例 | 成本 |
|---------|---------|------|
| **假陽性 (FP)** | 合格產品被判為不合格 | 浪費成本 (報廢/返工) |
| **假陰性 (FN)** | 不合格產品被判為合格 | 嚴重後果 (安全/品質問題) |

**成本矩陣範例**:

```python
# 化工案例: 藥品品質檢測
# 成本矩陣 (單位: 元)
cost_matrix = np.array([
    #       預測: 合格  不合格
    [0,      100],    # 真實: 合格 → FP成本100元 (誤判,浪費)
    [10000,  0]       # 真實: 不合格 → FN成本10000元 (漏檢,嚴重!)
])

# 計算總成本
def calculate_cost(cm, cost_matrix):
    """
    計算基於成本矩陣的總成本
    """
    total_cost = np.sum(cm * cost_matrix)
    return total_cost

# 比較兩個模型
cm_model1 = np.array([[950, 50], [10, 90]])   # 模型1
cm_model2 = np.array([[920, 80], [2, 98]])    # 模型2

cost1 = calculate_cost(cm_model1, cost_matrix)
cost2 = calculate_cost(cm_model2, cost_matrix)

print(f"模型1總成本: {cost1:,}元")
print(f"模型2總成本: {cost2:,}元")
print(f"模型2節省: {cost1-cost2:,}元")

# 分析:
# 模型1: FP=50 (成本5000), FN=10 (成本100000) → 總成本105000
# 模型2: FP=80 (成本8000), FN=2 (成本20000) → 總成本28000
# 模型2雖然誤報更多,但漏檢少,總成本更低!
```

#### 8.4.2 調整決策閾值

**問題**: 預設閾值0.5可能不是最優的

**解決**: 根據成本調整閾值

```python
from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

# 獲取預測機率
y_pred_proba = model.predict(x_test)[:, 1]  # 正類的機率

# 計算不同閾值下的precision和recall
precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred_proba)

# 繪製PR曲線
plt.figure(figsize=(10, 6))
plt.plot(recalls, precisions, linewidth=2)
plt.xlabel('Recall', fontsize=12)
plt.ylabel('Precision', fontsize=12)
plt.title('Precision-Recall曲線', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.show()

# 根據成本選擇最優閾值
def find_optimal_threshold(y_true, y_pred_proba, cost_fp, cost_fn):
    """
    找出成本最小的決策閾值
    """
    thresholds = np.linspace(0, 1, 100)
    costs = []
    
    for threshold in thresholds:
        y_pred = (y_pred_proba >= threshold).astype(int)
        cm = confusion_matrix(y_true, y_pred)
        
        fp = cm[0, 1]
        fn = cm[1, 0]
        total_cost = fp * cost_fp + fn * cost_fn
        costs.append(total_cost)
    
    optimal_idx = np.argmin(costs)
    optimal_threshold = thresholds[optimal_idx]
    min_cost = costs[optimal_idx]
    
    return optimal_threshold, min_cost, thresholds, costs

# 使用範例
optimal_threshold, min_cost, thresholds, costs = find_optimal_threshold(
    y_true, y_pred_proba, 
    cost_fp=100,    # FP成本
    cost_fn=10000   # FN成本
)

print(f"最優閾值: {optimal_threshold:.3f}")
print(f"最小成本: {min_cost:,}元")

# 視覺化成本曲線
plt.figure(figsize=(10, 6))
plt.plot(thresholds, costs, linewidth=2)
plt.axvline(optimal_threshold, color='r', linestyle='--', 
            label=f'最優閾值={optimal_threshold:.3f}')
plt.xlabel('決策閾值', fontsize=12)
plt.ylabel('總成本 (元)', fontsize=12)
plt.title('成本 vs 決策閾值', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

---

### 8.5 綜合評估策略

#### 8.5.1 完整評估報告

```python
from sklearn.metrics import classification_report
import pandas as pd

def comprehensive_evaluation(model, x_test, y_test, class_names=None):
    """
    生成完整的模型評估報告
    """
    # 預測
    y_pred_proba = model.predict(x_test)
    y_pred_classes = np.argmax(y_pred_proba, axis=1)
    y_true_classes = np.argmax(y_test, axis=1) if len(y_test.shape) > 1 else y_test
    
    # 1. 基本指標
    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
    
    print("=" * 70)
    print("模型評估報告")
    print("=" * 70)
    print(f"\n1. 基本指標:")
    print(f"   測試集Loss: {test_loss:.4f}")
    print(f"   測試集Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)")
    
    # 2. 分類報告
    print(f"\n2. 詳細分類報告:")
    report = classification_report(y_true_classes, y_pred_classes, 
                                   target_names=class_names,
                                   digits=4)
    print(report)
    
    # 3. 混淆矩陣
    cm = confusion_matrix(y_true_classes, y_pred_classes)
    print(f"\n3. 混淆矩陣:")
    print(cm)
    
    # 4. 各類別準確率
    print(f"\n4. 各類別準確率:")
    for i in range(len(cm)):
        class_acc = cm[i, i] / cm[i, :].sum()
        class_name = class_names[i] if class_names else f"類別{i}"
        print(f"   {class_name}: {class_acc:.4f} ({class_acc*100:.2f}%)")
    
    # 5. 混淆分析
    print(f"\n5. 最容易混淆的類別對:")
    errors = []
    for i in range(len(cm)):
        for j in range(len(cm)):
            if i != j and cm[i, j] > 0:
                errors.append((i, j, cm[i, j]))
    
    errors_sorted = sorted(errors, key=lambda x: x[2], reverse=True)
    for idx, (i, j, count) in enumerate(errors_sorted[:5], 1):
        true_name = class_names[i] if class_names else f"類別{i}"
        pred_name = class_names[j] if class_names else f"類別{j}"
        print(f"   {idx}. {true_name} → {pred_name}: {count}次")
    
    print("=" * 70)
    
    return {
        'loss': test_loss,
        'accuracy': test_acc,
        'confusion_matrix': cm,
        'predictions': y_pred_classes,
        'probabilities': y_pred_proba
    }

# 使用範例
class_names = ['正常', '裂紋', '劃痕', '氣泡', '污點']
results = comprehensive_evaluation(model, x_test, y_test, class_names)
```

#### 8.5.2 化工評估檢查清單

**模型上線前必檢項目**:

- [ ] **基本性能**
  - [ ] 測試集Accuracy > 目標值 (如95%)
  - [ ] 各類別Recall都達標 (特別是關鍵類別)
  - [ ] 訓練/測試性能差距 < 5% (無過擬合)

- [ ] **混淆矩陣分析**
  - [ ] 檢查是否有嚴重的混淆模式
  - [ ] 確認關鍵類別(如危險缺陷)的Recall足夠高
  - [ ] 分析混淆原因,是否需要改進

- [ ] **成本分析**
  - [ ] 計算實際應用中的預期成本
  - [ ] 對比人工檢測的成本
  - [ ] 確認ROI (投資回報率)

- [ ] **魯棒性測試**
  - [ ] 測試不同光照條件下的性能
  - [ ] 測試不同角度、位置的影像
  - [ ] 測試邊界案例

- [ ] **可解釋性**
  - [ ] 能否解釋模型的決策?
  - [ ] 是否符合領域知識?
  - [ ] 失敗案例是否可以理解?

---

**本章小結**

恭喜!您已經掌握了CNN模型評估的核心知識:

✅ **評估指標**: 理解Accuracy, Precision, Recall, F1-Score的含義和應用  
✅ **混淆矩陣**: 學會分析混淆矩陣,發現模型弱點  
✅ **成本敏感**: 在化工應用中考慮不同錯誤的成本  
✅ **綜合評估**: 建立完整的評估流程和檢查清單  

**關鍵要點回顧**:

| 指標 | 定義 | 何時重要 | 化工類比 |
|------|------|---------|---------|
| Accuracy | 總體正確率 | 類別平衡時 | 總合格率 |
| Precision | 預測為正中真正為正的比例 | 誤報成本高 | 避免浪費 |
| Recall | 真正為正中被預測為正的比例 | 漏檢成本高 | 避免漏檢 |
| F1-Score | P和R的調和平均 | 兩者都重要 | 綜合指標 |

**評估決策樹**:

```
開始評估模型
    ↓
基本指標達標? → 否 → 返回訓練/改進模型
    ↓ 是
類別平衡? → 是 → 主要看Accuracy
    ↓ 否
分析混淆矩陣
    ↓
識別關鍵錯誤類型
    ↓
計算成本影響
    ↓
調整決策閾值 (如需要)
    ↓
通過檢查清單? → 是 → 可以部署! ✅
    ↓ 否
針對性改進
```

> [!IMPORTANT]
> **記住三個原則**:
> 1. **不要只看Accuracy**: 特別是類別不平衡時
> 2. **考慮實際成本**: 不同錯誤的成本不同
> 3. **全面評估**: 使用混淆矩陣、分類報告等多種工具

**下一步學習**:
- Chapter 9: 模型預測與部署 - 實際應用和工業部署策略
- Chapter 10: 進階主題 - 模型可解釋性、優化技術

---

## 9. 模型預測與部署

### 本章學習地圖

> [!IMPORTANT]
> **本章核心問題**: 如何將訓練好的CNN模型應用於實際化工場景?需要考慮哪些部署細節?

**學習目標**:
1. 🎯 **掌握預測方法**: 了解單張和批次預測的不同使用場景
2. 💾 **學會模型持久化**: 掌握模型保存、載入和版本管理
3. 🚀 **理解部署策略**: 認識不同的部署架構及其適用場景
4. 🏭 **掌握工業考量**: 了解化工產線部署的特殊需求

**為什麼部署很重要?**

訓練好的模型只是「半成品」,真正的價值在於將其部署到生產環境:
- 實時品質檢測: 生產線上的即時缺陷檢測
- 批次分析: 定期分析大量產品影像
- 邊緣部署: 在設備端直接執行(如智能攝影機)
- 雲端服務: 透過API提供影像分析服務

**本章架構**:

```
預測基礎 (9.1)
    ├─ 單張預測
    └─ 批次預測
    ↓
模型持久化 (9.2)
    ├─ SavedModel格式
    ├─ H5格式
    └─ 權重保存
    ↓
部署策略 (9.3)
    ├─ 本地部署
    ├─ 雲端部署
    ├─ 邊緣部署
    └─ 混合部署
    ↓
工業實踐 (9.4)
    ├─ 性能優化
    ├─ 可靠性保證
    └─ 監控與維護
```

> [!TIP]
> 部署不是「一次性」的工作,而是一個持續的過程:訓練 → 部署 → 監控 → 改進 → 重新部署

---

### 9.1 模型預測方法

#### 9.1.1 單張影像預測

**使用場景**: 即時檢測、互動式應用

**基本流程**:

```python
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt

# 1. 載入訓練好的模型
model = load_model('defect_detection_model.h5')

# 2. 載入並預處理單張影像
def load_and_preprocess_image(img_path, target_size=(224, 224)):
    """載入並預處理單張影像"""
    # 載入影像
    img = image.load_img(img_path, target_size=target_size)
    
    # 轉換為numpy陣列
    img_array = image.img_to_array(img)
    
    # 正規化 (與訓練時保持一致!)
    img_array = img_array / 255.0
    
    # 增加批次維度: (224, 224, 3) → (1, 224, 224, 3)
    img_array = np.expand_dims(img_array, axis=0)
    
    return img_array

# 3. 執行預測
img_path = 'test_images/product_001.jpg'
processed_img = load_and_preprocess_image(img_path)

# 使用 model.predict()
predictions = model.predict(processed_img)
# predictions shape: (1, num_classes)

# 4. 解讀預測結果
predicted_class = np.argmax(predictions[0])
confidence = predictions[0][predicted_class]

class_names = ['正常', '裂紋', '凹陷', '刮痕', '污漬']
print(f"預測類別: {class_names[predicted_class]}")
print(f"信心分數: {confidence:.2%}")

# 5. 視覺化結果
plt.figure(figsize=(10, 4))

# 顯示原始影像
plt.subplot(1, 2, 1)
original_img = image.load_img(img_path)
plt.imshow(original_img)
plt.title(f'預測: {class_names[predicted_class]}\n信心: {confidence:.2%}')
plt.axis('off')

# 顯示機率分布
plt.subplot(1, 2, 2)
plt.bar(class_names, predictions[0])
plt.ylabel('機率')
plt.title('各類別機率分布')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```

**關鍵注意事項**:

> [!WARNING]
> **預處理必須與訓練時完全一致!**
> - 影像尺寸
> - 正規化方法 (除以255, 或標準化)
> - 顏色模式 (RGB vs BGR)
> - 數據範圍 ([0,1] vs [-1,1])

**化工應用範例**:

```python
def predict_product_quality(img_path, model, threshold=0.95):
    """
    化工產品品質檢測
    
    Args:
        img_path: 產品影像路徑
        model: 訓練好的CNN模型
        threshold: 合格品信心閾值
        
    Returns:
        dict: 包含預測結果和建議動作
    """
    # 預處理影像
    img_array = load_and_preprocess_image(img_path)
    
    # 預測
    predictions = model.predict(img_array, verbose=0)
    
    # 解讀結果
    is_defect = predictions[0][0] < 0.5  # 假設index 0為正常品
    confidence = predictions[0][0] if not is_defect else (1 - predictions[0][0])
    
    # 決策邏輯
    if not is_defect and confidence >= threshold:
        decision = "合格 - 放行"
        action = "PASS"
    elif not is_defect and confidence < threshold:
        decision = "疑似合格 - 人工複檢"
        action = "MANUAL_CHECK"
    else:
        decision = "不合格 - 剔除"
        action = "REJECT"
    
    return {
        'is_defect': is_defect,
        'confidence': confidence,
        'decision': decision,
        'action': action,
        'raw_predictions': predictions[0].tolist()
    }

# 使用範例
result = predict_product_quality('production/batch_001/item_042.jpg', model)
print(f"檢測結果: {result['decision']}")
print(f"信心分數: {result['confidence']:.2%}")
```

---

#### 9.1.2 批次預測

**使用場景**: 離線分析、大量影像處理

**為什麼需要批次預測?**

| 特性 | 單張預測 | 批次預測 |
|------|---------|---------|
| **速度** | 慢 (每張單獨推論) | 快 (GPU並行處理) |
| **GPU利用率** | 低 (~10-20%) | 高 (~80-95%) |
| **適用場景** | 即時檢測 | 離線分析、歷史數據處理 |
| **記憶體** | 需求低 | 需求較高 |

**批次預測實作**:

```python
import os
import numpy as np
from tensorflow.keras.preprocessing import image
from tqdm import tqdm  # 進度條

def batch_predict(model, img_folder, batch_size=32, target_size=(224, 224)):
    """
    批次預測多張影像
    
    Args:
        model: 訓練好的模型
        img_folder: 影像資料夾路徑
        batch_size: 批次大小 (根據GPU記憶體調整)
        target_size: 目標影像尺寸
        
    Returns:
        list: 包含每張影像的預測結果
    """
    # 1. 獲取所有影像路徑
    img_paths = []
    for filename in os.listdir(img_folder):
        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            img_paths.append(os.path.join(img_folder, filename))
    
    print(f"找到 {len(img_paths)} 張影像")
    
    # 2. 批次處理
    results = []
    
    for i in tqdm(range(0, len(img_paths), batch_size), desc="預測進度"):
        # 取得當前批次的影像路徑
        batch_paths = img_paths[i:i+batch_size]
        
        # 載入並預處理批次影像
        batch_images = []
        for img_path in batch_paths:
            img = image.load_img(img_path, target_size=target_size)
            img_array = image.img_to_array(img) / 255.0
            batch_images.append(img_array)
        
        # 轉換為numpy陣列: (batch_size, height, width, channels)
        batch_images = np.array(batch_images)
        
        # 批次預測 (一次處理多張影像, GPU並行)
        batch_predictions = model.predict(batch_images, verbose=0)
        
        # 儲存結果
        for img_path, predictions in zip(batch_paths, batch_predictions):
            results.append({
                'path': img_path,
                'filename': os.path.basename(img_path),
                'predictions': predictions,
                'predicted_class': np.argmax(predictions),
                'confidence': np.max(predictions)
            })
    
    return results

# 使用範例
results = batch_predict(model, 'test_images/', batch_size=32)

# 3. 分析結果
class_names = ['正常', '裂紋', '凹陷', '刮痕', '污漬']

# 統計各類別數量
from collections import Counter
predicted_classes = [r['predicted_class'] for r in results]
class_counts = Counter(predicted_classes)

print("\n=== 批次預測統計 ===")
for class_idx, count in class_counts.items():
    print(f"{class_names[class_idx]}: {count} 張 ({count/len(results)*100:.1f}%)")

# 找出低信心預測 (需要人工複檢)
low_confidence = [r for r in results if r['confidence'] < 0.9]
print(f"\n低信心預測 (<90%): {len(low_confidence)} 張")

# 4. 輸出CSV報告
import pandas as pd

df = pd.DataFrame([
    {
        'filename': r['filename'],
        'predicted_class': class_names[r['predicted_class']],
        'confidence': r['confidence'],
        'needs_review': r['confidence'] < 0.9
    }
    for r in results
])

df.to_csv('batch_prediction_report.csv', index=False, encoding='utf-8-sig')
print("\n報告已儲存至: batch_prediction_report.csv")
```

**性能優化技巧**:

> [!TIP]
> **批次大小選擇指南**:
> - **GPU記憶體 4GB**: batch_size = 16-32
> - **GPU記憶體 8GB**: batch_size = 32-64
> - **GPU記憶體 16GB+**: batch_size = 64-128
> - 如果出現OOM錯誤,降低batch_size

**化工應用: 生產批次分析**

```python
def analyze_production_batch(batch_folder, model, quality_threshold=0.95):
    """
    分析整個生產批次的品質
    
    Args:
        batch_folder: 批次影像資料夾
        model: 品質檢測模型
        quality_threshold: 合格品信心閾值
        
    Returns:
        dict: 批次品質報告
    """
    # 批次預測
    results = batch_predict(model, batch_folder, batch_size=32)
    
    # 品質分析
    total = len(results)
    passed = sum(1 for r in results 
                 if r['predicted_class'] == 0 and r['confidence'] >= quality_threshold)
    rejected = sum(1 for r in results 
                   if r['predicted_class'] != 0)
    manual_check = total - passed - rejected
    
    # 缺陷類型統計
    defect_types = {}
    for r in results:
        if r['predicted_class'] != 0:
            defect_type = class_names[r['predicted_class']]
            defect_types[defect_type] = defect_types.get(defect_type, 0) + 1
    
    # 生成報告
    report = {
        'batch_id': os.path.basename(batch_folder),
        'total_products': total,
        'passed': passed,
        'rejected': rejected,
        'manual_check': manual_check,
        'pass_rate': passed / total * 100,
        'reject_rate': rejected / total * 100,
        'defect_breakdown': defect_types,
        'timestamp': pd.Timestamp.now()
    }
    
    # 列印報告
    print(f"\n{'='*50}")
    print(f"生產批次品質報告: {report['batch_id']}")
    print(f"{'='*50}")
    print(f"總產品數: {total}")
    print(f"合格品: {passed} ({report['pass_rate']:.1f}%)")
    print(f"不合格品: {rejected} ({report['reject_rate']:.1f}%)")
    print(f"待複檢: {manual_check}")
    
    if defect_types:
        print(f"\n缺陷類型分布:")
        for defect, count in defect_types.items():
            print(f"  {defect}: {count} ({count/total*100:.1f}%)")
    
    return report

# 使用範例
report = analyze_production_batch('production/batch_20231201/', model)
```

**進階: 生成器批次預測 (記憶體高效)**

```python
def image_generator(img_folder, batch_size=32, target_size=(224, 224)):
    """影像生成器 - 逐批載入影像,節省記憶體"""
    img_paths = [os.path.join(img_folder, f) 
                 for f in os.listdir(img_folder) 
                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    
    for i in range(0, len(img_paths), batch_size):
        batch_paths = img_paths[i:i+batch_size]
        batch_images = []
        
        for img_path in batch_paths:
            img = image.load_img(img_path, target_size=target_size)
            img_array = image.img_to_array(img) / 255.0
            batch_images.append(img_array)
        
        yield np.array(batch_images), batch_paths

# 使用生成器預測
results = []
for batch_images, batch_paths in image_generator('large_dataset/', batch_size=32):
    predictions = model.predict(batch_images, verbose=0)
    for img_path, pred in zip(batch_paths, predictions):
        results.append({'path': img_path, 'predictions': pred})
```

---

### 9.2 模型保存與載入

**為什麼需要保存模型?**

- ✅ 訓練一次,多次使用
- ✅ 版本控制與回滾
- ✅ 部署到生產環境
- ✅ 分享與協作

#### 9.2.1 SavedModel 格式 (推薦)

**TensorFlow 2.x 的標準格式**,包含完整的計算圖和權重

**優點**:
- 包含完整模型架構和權重
- 支援 TensorFlow Serving 部署
- 跨平台相容性好
- 可以在不同語言中使用 (Python, C++, Java)

```python
# 1. 保存完整模型
model.save('saved_models/defect_detector_v1')

# 保存後的目錄結構:
# saved_models/defect_detector_v1/
# ├── assets/
# ├── variables/
# │   ├── variables.data-00000-of-00001
# │   └── variables.index
# └── saved_model.pb  ← 模型架構(計算圖)

# 2. 載入模型
from tensorflow.keras.models import load_model

loaded_model = load_model('saved_models/defect_detector_v1')

# 3. 驗證模型
# 檢查架構
loaded_model.summary()

# 檢查預測結果是否一致
test_image = load_and_preprocess_image('test.jpg')
original_pred = model.predict(test_image)
loaded_pred = loaded_model.predict(test_image)

print(f"預測結果一致: {np.allclose(original_pred, loaded_pred)}")
```

---

#### 9.2.2 H5 格式 (傳統格式)

**HDF5 格式**,將整個模型保存在單一檔案中

```python
# 1. 保存為 H5 格式
model.save('models/defect_detector_v1.h5')

# 2. 載入 H5 模型
loaded_model = load_model('models/defect_detector_v1.h5')
```

**SavedModel vs H5 對比**:

| 特性 | SavedModel | H5 |
|------|-----------|-----|
| **格式** | 目錄結構 | 單一檔案 |
| **TF Serving** | ✅ 原生支持 | ❌ 需要轉換 |
| **自定義層** | ✅ 完整支持 | ⚠️ 需要額外處理 |
| **檔案大小** | 較大 | 較小 |
| **推薦度** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ |

> [!TIP]
> **推薦**: 使用 SavedModel 格式進行生產部署,H5 格式用於實驗和快速分享

---

#### 9.2.3 僅保存權重

**使用場景**: 模型架構已知,只需保存訓練的權重

```python
# 1. 僅保存權重
model.save_weights('weights/defect_detector_weights.h5')

# 2. 載入權重
# 必須先建立相同架構的模型
model_new = create_model()  # 與原模型相同架構
model_new.load_weights('weights/defect_detector_weights.h5')

# 3. 注意: 需要重新編譯
model_new.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

**優缺點**:

| 優點 | 缺點 |
|------|------|
| 檔案最小 | 需要重建架構 |
| 載入速度快 | 需要重新編譯 |
| 適合實驗對比 | 容易出錯 (架構不匹配) |

---

#### 9.2.4 模型版本管理

**化工生產環境的最佳實踐**:

```python
import os
from datetime import datetime

class ModelVersionManager:
    """CNN模型版本管理器"""
    
    def __init__(self, base_dir='models'):
        self.base_dir = base_dir
        os.makedirs(base_dir, exist_ok=True)
    
    def save_model(self, model, model_name, version=None, metadata=None):
        """
        保存模型並記錄版本資訊
        
        Args:
            model: Keras模型
            model_name: 模型名稱 (如 'defect_detector')
            version: 版本號 (如 'v1.0', 若為None則自動生成)
            metadata: 額外資訊 (如訓練參數、準確率等)
        """
        if version is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            version = f'v_{timestamp}'
        
        # 建立版本目錄
        version_dir = os.path.join(self.base_dir, model_name, version)
        os.makedirs(version_dir, exist_ok=True)
        
        # 保存模型
        model_path = os.path.join(version_dir, 'model')
        model.save(model_path)
        print(f"✅ 模型已保存至: {model_path}")
        
        # 保存元數據
        if metadata is None:
            metadata = {}
        
        metadata.update({
            'model_name': model_name,
            'version': version,
            'save_time': datetime.now().isoformat(),
            'tensorflow_version': tf.__version__
        })
        
        import json
        metadata_path = os.path.join(version_dir, 'metadata.json')
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        print(f"✅ 元數據已保存至: {metadata_path}")
        
        return version_dir
    
    def load_model(self, model_name, version='latest'):
        """載入指定版本的模型"""
        model_dir = os.path.join(self.base_dir, model_name)
        
        if version == 'latest':
            # 找到最新版本
            versions = sorted(os.listdir(model_dir))
            if not versions:
                raise ValueError(f"找不到模型: {model_name}")
            version = versions[-1]
        
        model_path = os.path.join(model_dir, version, 'model')
        model = load_model(model_path)
        
        # 載入元數據
        metadata_path = os.path.join(model_dir, version, 'metadata.json')
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        print(f"✅ 已載入模型: {model_name} {version}")
        print(f"   訓練時間: {metadata.get('save_time', 'unknown')}")
        print(f"   準確率: {metadata.get('accuracy', 'unknown')}")
        
        return model, metadata
    
    def list_versions(self, model_name):
        """列出所有版本"""
        model_dir = os.path.join(self.base_dir, model_name)
        if not os.path.exists(model_dir):
            return []
        
        versions = []
        for version in os.listdir(model_dir):
            metadata_path = os.path.join(model_dir, version, 'metadata.json')
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                    versions.append({
                        'version': version,
                        'save_time': metadata.get('save_time'),
                        'accuracy': metadata.get('accuracy'),
                        'val_accuracy': metadata.get('val_accuracy')
                    })
        
        return sorted(versions, key=lambda x: x['save_time'], reverse=True)

# 使用範例
manager = ModelVersionManager(base_dir='production_models')

# 保存模型
metadata = {
    'accuracy': 0.9856,
    'val_accuracy': 0.9723,
    'epochs': 50,
    'batch_size': 32,
    'dataset_size': 10000,
    'notes': '使用數據增強, Dropout=0.5'
}

version_dir = manager.save_model(
    model, 
    model_name='defect_detector',
    version='v1.0',
    metadata=metadata
)

# 載入最新模型
model, metadata = manager.load_model('defect_detector', version='latest')

# 查看所有版本
versions = manager.list_versions('defect_detector')
for v in versions:
    print(f"{v['version']}: 準確率={v['accuracy']:.2%}, "
          f"時間={v['save_time']}")
```

---

### 9.3 部署策略

**選擇合適的部署方式取決於**:
- 推論頻率 (即時 vs 批次)
- 延遲要求 (毫秒 vs 秒)
- 資源限制 (邊緣設備 vs 雲端)
- 成本考量

#### 9.3.1 本地部署 (Local Deployment)

**適用場景**: 小規模應用、原型驗證、離線分析

**優點**: ✅ 簡單快速 ✅ 無需網路 ✅ 數據隱私

**缺點**: ❌ 難以擴展 ❌ 維護困難 ❌ 需要本地GPU

```python
# 簡單的本地推論腳本
import tensorflow as tf

# 載入模型
model = tf.keras.models.load_model('defect_detector.h5')

# 推論函數
def predict_image(img_path):
    img = load_and_preprocess_image(img_path)
    pred = model.predict(img)
    return pred

# 直接在本地運行
result = predict_image('test.jpg')
```

---

#### 9.3.2 雲端部署 (Cloud Deployment)

**適用場景**: 大規模應用、需要彈性擴展

**主流平台**:

| 平台 | 優勢 | 適用場景 |
|------|------|---------|
| **TensorFlow Serving** | 高性能、原生支持 | 生產級部署 |
| **AWS SageMaker** | 完整MLOps | 企業級應用 |
| **Google Cloud AI** | 與TF整合好 | 大規模推論 |
| **Azure ML** | 混合雲支持 | 企業內部+雲端 |

**Flask API 部署範例**:

```python
from flask import Flask, request, jsonify
import tensorflow as tf
import numpy as np
from PIL import Image
import io

app = Flask(__name__)

# 啟動時載入模型 (只載入一次)
model = tf.keras.models.load_model('defect_detector.h5')
class_names = ['正常', '裂紋', '凹陷', '刮痕', '污漬']

@app.route('/predict', methods=['POST'])
def predict():
    """
    API端點: 接收影像並返回預測結果
    
    Request:
        POST /predict
        Body: image file (multipart/form-data)
        
    Response:
        JSON: {
            "predicted_class": "裂紋",
            "confidence": 0.95,
            "all_probabilities": {...}
        }
    """
    try:
        # 1. 接收上傳的影像
        if 'image' not in request.files:
            return jsonify({'error': '未上傳影像'}), 400
        
        file = request.files['image']
        img_bytes = file.read()
        
        # 2. 預處理影像
        img = Image.open(io.BytesIO(img_bytes))
        img = img.resize((224, 224))
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # 3. 推論
        predictions = model.predict(img_array)[0]
        
        # 4. 整理結果
        predicted_idx = int(np.argmax(predictions))
        confidence = float(predictions[predicted_idx])
        
        result = {
            'predicted_class': class_names[predicted_idx],
            'confidence': confidence,
            'all_probabilities': {
                name: float(prob) 
                for name, prob in zip(class_names, predictions)
            },
            'is_defect': predicted_idx != 0,
            'timestamp': datetime.now().isoformat()
        }
        
        return jsonify(result), 200
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/health', methods=['GET'])
def health():
    """健康檢查端點"""
    return jsonify({'status': 'healthy', 'model_loaded': model is not None})

if __name__ == '__main__':
    # 生產環境使用 gunicorn 或 uwsgi
    app.run(host='0.0.0.0', port=5000, debug=False)
```

**使用API的客戶端範例**:

```python
import requests

# 上傳影像進行預測
url = 'http://your-server:5000/predict'
files = {'image': open('test.jpg', 'rb')}

response = requests.post(url, files=files)
result = response.json()

print(f"預測類別: {result['predicted_class']}")
print(f"信心分數: {result['confidence']:.2%}")
```

---

#### 9.3.3 邊緣部署 (Edge Deployment)

**適用場景**: 
- 需要極低延遲 (<100ms)
- 網路不穩定或無網路環境
- 數據隱私要求高
- 智能攝影機、工業設備端

**挑戰**:
- 計算資源受限 (CPU、記憶體)
- 需要模型優化 (量化、剪枝)
- 功耗限制

**TensorFlow Lite 轉換**:

```python
import tensorflow as tf

# 1. 載入原始模型
model = tf.keras.models.load_model('defect_detector.h5')

# 2. 轉換為 TensorFlow Lite 格式
converter = tf.lite.TFLiteConverter.from_keras_model(model)

# 3. 啟用優化 (減小模型大小、提升速度)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# 4. 量化 (將 float32 轉為 int8, 模型縮小4倍)
# 提供代表性數據集用於量化校準
def representative_dataset():
    for _ in range(100):
        # 載入代表性影像
        img = load_and_preprocess_image('calibration_image.jpg')
        yield [img.astype(np.float32)]

converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

# 5. 轉換
tflite_model = converter.convert()

# 6. 保存
with open('defect_detector.tflite', 'wb') as f:
    f.write(tflite_model)

print(f"原始模型大小: {os.path.getsize('defect_detector.h5') / 1024 / 1024:.2f} MB")
print(f"TFLite模型大小: {os.path.getsize('defect_detector.tflite') / 1024 / 1024:.2f} MB")
```

**在邊緣設備上使用 TFLite 模型**:

```python
import tensorflow as tf
import numpy as np

# 1. 載入 TFLite 模型
interpreter = tf.lite.Interpreter(model_path='defect_detector.tflite')
interpreter.allocate_tensors()

# 2. 獲取輸入輸出詳情
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

print(f"輸入shape: {input_details[0]['shape']}")
print(f"輸入dtype: {input_details[0]['dtype']}")

# 3. 推論函數
def predict_tflite(img_path):
    # 載入並預處理影像
    img = load_and_preprocess_image(img_path)
    
    # 如果模型被量化為 uint8, 需要轉換輸入
    if input_details[0]['dtype'] == np.uint8:
        img = (img * 255).astype(np.uint8)
    
    # 設置輸入
    interpreter.set_tensor(input_details[0]['index'], img)
    
    # 執行推論
    interpreter.invoke()
    
    # 獲取輸出
    output = interpreter.get_tensor(output_details[0]['index'])
    
    # 如果輸出是 uint8, 需要反量化
    if output_details[0]['dtype'] == np.uint8:
        scale, zero_point = output_details[0]['quantization']
        output = (output.astype(np.float32) - zero_point) * scale
    
    return output

# 4. 性能測試
import time

times = []
for _ in range(100):
    start = time.time()
    pred = predict_tflite('test.jpg')
    times.append(time.time() - start)

print(f"平均推論時間: {np.mean(times)*1000:.2f} ms")
print(f"FPS: {1/np.mean(times):.1f}")
```

**模型優化對比**:

| 優化技術 | 模型大小 | 速度提升 | 準確率影響 | 適用場景 |
|---------|---------|---------|-----------|---------|
| **無優化** | 100% | 1x | 0% | GPU服務器 |
| **Dynamic Range量化** | 25% | 2-3x | <1% | 移動設備 |
| **INT8量化** | 25% | 3-4x | 1-2% | 邊緣設備 |
| **剪枝** | 10-30% | 1.5-2x | 1-3% | 極端資源受限 |
| **知識蒸餾** | 自定義 | 2-5x | 2-5% | 移動/嵌入式 |

---

#### 9.3.4 混合部署 (Hybrid Deployment)

**化工產線的實際方案**: 結合邊緣和雲端的優勢

```
生產線攝影機 (邊緣)
    ↓
快速初篩 (TFLite, <50ms)
    ├─ 明確合格 → 直接放行
    ├─ 明確不合格 → 直接剔除
    └─ 不確定 (60-80%信心) → 送雲端
                ↓
            雲端精確模型
                ↓
            最終決策
```

**實作範例**:

```python
class HybridDefectDetector:
    """混合部署缺陷檢測器"""
    
    def __init__(self, edge_model_path, cloud_api_url):
        # 邊緣模型 (TFLite, 快速)
        self.edge_interpreter = tf.lite.Interpreter(model_path=edge_model_path)
        self.edge_interpreter.allocate_tensors()
        
        # 雲端API
        self.cloud_api_url = cloud_api_url
        
        # 統計數據
        self.stats = {
            'total': 0,
            'edge_decided': 0,
            'cloud_decided': 0,
            'edge_confidence_threshold': 0.85
        }
    
    def predict(self, img_path):
        """混合預測策略"""
        self.stats['total'] += 1
        
        # 1. 邊緣快速推論
        edge_pred, edge_confidence = self._predict_edge(img_path)
        
        # 2. 決策邏輯
        if edge_confidence >= self.stats['edge_confidence_threshold']:
            # 高信心 → 邊緣直接決策
            self.stats['edge_decided'] += 1
            return {
                'predicted_class': edge_pred,
                'confidence': edge_confidence,
                'decided_by': 'edge',
                'latency_ms': 50  # 邊緣推論很快
            }
        else:
            # 低信心 → 送雲端精確模型
            self.stats['cloud_decided'] += 1
            cloud_result = self._predict_cloud(img_path)
            cloud_result['decided_by'] = 'cloud'
            return cloud_result
    
    def _predict_edge(self, img_path):
        """邊緣推論 (TFLite)"""
        img = load_and_preprocess_image(img_path)
        # ... TFLite 推論邏輯 ...
        return predicted_class, confidence
    
    def _predict_cloud(self, img_path):
        """雲端推論 (完整模型)"""
        files = {'image': open(img_path, 'rb')}
        response = requests.post(self.cloud_api_url, files=files, timeout=2.0)
        return response.json()
    
    def get_stats(self):
        """獲取統計數據"""
        edge_ratio = self.stats['edge_decided'] / max(self.stats['total'], 1)
        return {
            'total_predictions': self.stats['total'],
            'edge_decided': self.stats['edge_decided'],
            'cloud_decided': self.stats['cloud_decided'],
            'edge_ratio': edge_ratio,
            'cost_saving': edge_ratio  # 邊緣處理節省雲端成本
        }

# 使用範例
detector = HybridDefectDetector(
    edge_model_path='defect_detector_edge.tflite',
    cloud_api_url='https://api.example.com/predict'
)

result = detector.predict('production_line_image.jpg')
print(f"決策來源: {result['decided_by']}")
print(f"預測類別: {result['predicted_class']}")

# 定期檢查統計
stats = detector.get_stats()
print(f"邊緣處理比例: {stats['edge_ratio']:.1%}")
```

---

### 9.4 工業部署考量

**化工產線部署的特殊需求**:

#### 9.4.1 可靠性與容錯

**挑戰**: 生產線不能因為AI系統故障而停擺

**解決方案**:

```python
class RobustPredictor:
    """具備容錯機制的預測器"""
    
    def __init__(self, model_path, fallback_model_path=None):
        self.primary_model = load_model(model_path)
        self.fallback_model = load_model(fallback_model_path) if fallback_model_path else None
        self.error_count = 0
        self.max_errors = 3
    
    def predict_with_fallback(self, img_path, timeout=1.0):
        """帶容錯的預測"""
        try:
            # 嘗試主模型
            result = self._predict_with_timeout(self.primary_model, img_path, timeout)
            self.error_count = 0  # 重置錯誤計數
            return result
            
        except Exception as e:
            self.error_count += 1
            logging.error(f"主模型預測失敗 ({self.error_count}/{self.max_errors}): {e}")
            
            if self.fallback_model:
                # 使用備用模型
                try:
                    result = self._predict_with_timeout(self.fallback_model, img_path, timeout)
                    result['used_fallback'] = True
                    return result
                except Exception as e2:
                    logging.error(f"備用模型也失敗: {e2}")
            
            # 所有模型都失敗 → 返回安全決策
            return self._safe_fallback_decision()
    
    def _safe_fallback_decision(self):
        """當AI失敗時的安全決策"""
        return {
            'predicted_class': 'MANUAL_CHECK',
            'confidence': 0.0,
            'error': True,
            'action': '請人工檢查'
        }
```

---

#### 9.4.2 性能監控

**化工產線需要監控**:
- 推論延遲 (是否滿足產線節拍)
- 模型準確率 (是否有數據漂移)
- 系統資源使用

```python
import time
from collections import deque
import numpy as np

class PerformanceMonitor:
    """性能監控器"""
    
    def __init__(self, window_size=100):
        self.latencies = deque(maxlen=window_size)
        self.predictions = deque(maxlen=window_size)
        self.errors = 0
        self.total = 0
    
    def record_prediction(self, latency_ms, predicted_class, confidence):
        """記錄每次預測"""
        self.latencies.append(latency_ms)
        self.predictions.append({
            'class': predicted_class,
            'confidence': confidence,
            'timestamp': time.time()
        })
        self.total += 1
    
    def record_error(self):
        """記錄錯誤"""
        self.errors += 1
    
    def get_metrics(self):
        """獲取性能指標"""
        if not self.latencies:
            return None
        
        return {
            'avg_latency_ms': np.mean(self.latencies),
            'p50_latency_ms': np.percentile(self.latencies, 50),
            'p95_latency_ms': np.percentile(self.latencies, 95),
            'p99_latency_ms': np.percentile(self.latencies, 99),
            'avg_confidence': np.mean([p['confidence'] for p in self.predictions]),
            'error_rate': self.errors / max(self.total, 1),
            'throughput_fps': len(self.latencies) / (time.time() - self.predictions[0]['timestamp'])
        }
    
    def print_report(self):
        """列印監控報告"""
        metrics = self.get_metrics()
        if metrics:
            print("\n=== 性能監控報告 ===")
            print(f"平均延遲: {metrics['avg_latency_ms']:.1f} ms")
            print(f"P95 延遲: {metrics['p95_latency_ms']:.1f} ms")
            print(f"平均信心: {metrics['avg_confidence']:.2%}")
            print(f"錯誤率: {metrics['error_rate']:.2%}")
            print(f"吞吐量: {metrics['throughput_fps']:.1f} FPS")
```

---

#### 9.4.3 數據漂移檢測

**問題**: 生產環境的數據分布可能隨時間改變,導致模型性能下降

```python
class DriftDetector:
    """數據漂移檢測器"""
    
    def __init__(self, reference_predictions):
        """
        Args:
            reference_predictions: 驗證集上的預測分布 (基準)
        """
        self.reference_dist = self._compute_distribution(reference_predictions)
        self.current_window = deque(maxlen=1000)
    
    def add_prediction(self, predictions):
        """添加新的預測"""
        self.current_window.append(predictions)
    
    def detect_drift(self, threshold=0.1):
        """檢測是否發生漂移"""
        if len(self.current_window) < 100:
            return False, 0.0
        
        current_dist = self._compute_distribution(list(self.current_window))
        
        # 使用 KL散度 衡量分布差異
        kl_div = self._kl_divergence(self.reference_dist, current_dist)
        
        is_drift = kl_div > threshold
        
        if is_drift:
            logging.warning(f"⚠️ 檢測到數據漂移! KL散度={kl_div:.4f}")
        
        return is_drift, kl_div
    
    def _compute_distribution(self, predictions):
        """計算預測分布"""
        predictions = np.array(predictions)
        return np.mean(predictions, axis=0)
    
    def _kl_divergence(self, p, q):
        """計算KL散度"""
        p = np.asarray(p) + 1e-10  # 避免log(0)
        q = np.asarray(q) + 1e-10
        return np.sum(p * np.log(p / q))
```

---

### 9.5 完整部署範例

**化工產品缺陷檢測系統 - 生產級部署**

```python
import logging
import tensorflow as tf
from flask import Flask, request, jsonify
from datetime import datetime
import os

# 配置logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('defect_detector.log'),
        logging.StreamHandler()
    ]
)

app = Flask(__name__)

# 全局變量
model = None
monitor = None
drift_detector = None

def initialize_system():
    """系統初始化"""
    global model, monitor, drift_detector
    
    try:
        # 載入模型
        model_path = os.getenv('MODEL_PATH', 'models/defect_detector_v1')
        model = tf.keras.models.load_model(model_path)
        logging.info(f"✅ 模型已載入: {model_path}")
        
        # 初始化監控
        monitor = PerformanceMonitor(window_size=1000)
        logging.info("✅ 性能監控器已啟動")
        
        # 初始化漂移檢測
        # reference_predictions = np.load('reference_predictions.npy')
        # drift_detector = DriftDetector(reference_predictions)
        # logging.info("✅ 漂移檢測器已啟動")
        
        return True
        
    except Exception as e:
        logging.error(f"❌ 系統初始化失敗: {e}")
        return False

@app.route('/health', methods=['GET'])
def health_check():
    """健康檢查"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': model is not None,
        'timestamp': datetime.now().isoformat()
    })

@app.route('/predict', methods=['POST'])
def predict_endpoint():
    """預測端點"""
    start_time = time.time()
    
    try:
        # 1. 接收影像
        if 'image' not in request.files:
            return jsonify({'error': '未上傳影像'}), 400
        
        file = request.files['image']
        
        # 2. 預處理
        img = Image.open(io.BytesIO(file.read()))
        img_array = preprocess_image(img)
        
        # 3. 推論
        predictions = model.predict(img_array, verbose=0)[0]
        predicted_class = int(np.argmax(predictions))
        confidence = float(predictions[predicted_class])
        
        # 4. 記錄性能
        latency_ms = (time.time() - start_time) * 1000
        monitor.record_prediction(latency_ms, predicted_class, confidence)
        
        # 5. 漂移檢測
        if drift_detector:
            drift_detector.add_prediction(predictions)
            is_drift, kl_div = drift_detector.detect_drift()
            if is_drift:
                logging.warning(f"⚠️ 數據漂移: KL={kl_div:.4f}")
        
        # 6. 返回結果
        result = {
            'predicted_class': class_names[predicted_class],
            'confidence': confidence,
            'is_defect': predicted_class != 0,
            'latency_ms': latency_ms,
            'timestamp': datetime.now().isoformat()
        }
        
        logging.info(f"預測完成: {result['predicted_class']} ({confidence:.2%}) in {latency_ms:.1f}ms")
        
        return jsonify(result), 200
        
    except Exception as e:
        logging.error(f"預測失敗: {e}", exc_info=True)
        monitor.record_error()
        return jsonify({'error': str(e)}), 500

@app.route('/metrics', methods=['GET'])
def get_metrics():
    """獲取性能指標"""
    metrics = monitor.get_metrics()
    return jsonify(metrics)

if __name__ == '__main__':
    # 初始化系統
    if not initialize_system():
        logging.error("系統初始化失敗,退出")
        exit(1)
    
    # 啟動服務
    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False, threaded=True)
```

---

### 9.6 章節小結

恭喜!您已經掌握了CNN模型的預測與部署:

✅ **預測方法**: 單張預測vs批次預測,選擇合適的方式  
✅ **模型持久化**: SavedModel vs H5 vs 權重,版本管理  
✅ **部署策略**: 本地、雲端、邊緣、混合部署的選擇  
✅ **工業考量**: 可靠性、性能監控、數據漂移檢測  

**關鍵要點回顧**:

| 主題 | 核心要點 | 化工應用 |
|------|---------|---------|
| **預測** | 批次預測效率更高 | 定期產品批次分析 |
| **保存** | 推薦SavedModel格式 | 生產環境標準格式 |
| **部署** | 根據需求選擇架構 | 邊緣快篩+雲端精確 |
| **監控** | 持續監控性能和漂移 | 確保產線穩定運行 |

**部署決策樹**:

```
需要即時預測 (<100ms)? 
    ↓ 是
邊緣部署 (TFLite) + 混合策略
    ↓ 否
預測頻率高 (>1000次/天)?
    ↓ 是
雲端部署 (TF Serving / API)
    ↓ 否
本地部署 (簡單腳本)
```

> [!IMPORTANT]
> **記住**: 部署不是終點,而是起點!
> - 持續監控模型性能
> - 收集新數據進行再訓練
> - 根據反饋優化模型
> - 建立完整的MLOps流程

**實際部署檢查清單**:

- [ ] 模型已保存並版本化
- [ ] 預處理邏輯與訓練時一致
- [ ] 推論延遲滿足需求
- [ ] 容錯機制已建立
- [ ] 性能監控已部署
- [ ] 數據漂移檢測已啟用
- [ ] 日誌記錄完整
- [ ] 安全措施已實施 (API認證、加密)
- [ ] 備份與回滾策略已規劃
- [ ] 文檔已完成 (API文檔、運維手冊)

**下一步學習**:
- Chapter 10: 進階主題 - 模型可解釋性、優化技術、實際應用gap分析

---

## 10. 進階主題

### 本章學習地圖

> [!IMPORTANT]
> **本章核心問題**: CNN的「黑盒子」內部發生了什麼?如何從MNIST實驗走向化工產線應用?

**學習目標**:
1. 🔍 **理解模型決策**: 學會可視化和解釋CNN的內部運作
2. 🚀 **加速模型開發**: 掌握遷移學習,站在巨人肩膀上
3. 🏭 **跨越應用鴻溝**: 認識實驗室到工業應用的關鍵差異
4. ⚡ **優化模型性能**: 學會模型壓縮和加速技術

**為什麼需要進階技巧?**

在化工產線實際應用CNN時,我們會遇到:
- ❓ **信任問題**: 工程師不敢相信「黑盒子」的決策
- ⏰ **時間壓力**: 從零訓練模型太慢,數據量可能不足
- 💰 **成本限制**: 需要在邊緣設備上運行
- 🎯 **品質要求**: MNIST 99%準確率 ≠ 工業級可靠性

**本章架構**:

```
模型可解釋性 (10.1)
    ├─ 卷積核可視化
    ├─ 特徵圖分析
    ├─ 類別激活圖(CAM)
    └─ 化工應用案例
    ↓
遷移學習 (10.2)
    ├─ 預訓練模型
    ├─ 微調策略
    └─ 化工領域適配
    ↓
MNIST → 工業 (10.3)
    ├─ 數據差異
    ├─ 環境挑戰
    └─ 可靠性要求
    ↓
模型優化 (10.4)
    ├─ 量化
    ├─ 剪枝
    └─ 知識蒸餾
```

> [!TIP]
> 本章內容偏向實踐,建議邊學邊做,將技術應用到自己的化工問題上。

---

### 10.1 模型可解釋性

**為什麼可解釋性重要?**

在化工產線部署AI系統時,工程師經常問:
- 🤔 「模型為什麼說這個產品有缺陷?」
- 🎯 「它是看到了什麼特徵才做出判斷?」
- ⚠️ 「如果誤判,我怎麼知道哪裡出錯?」

**可解釋性的三個層次**:

| 層次 | 目標 | 方法 | 化工應用 |
|------|------|------|---------|
| **Layer 1: 濾波器** | 看每個濾波器學到什麼 | 卷積核可視化 | 了解模型提取了哪些基礎特徵 |
| **Layer 2: 特徵圖** | 看模型如何「看」影像 | 特徵圖分析 | 理解模型關注影像的哪些區域 |
| **Layer 3: 決策依據** | 看哪些區域影響決策 | CAM/Grad-CAM | 定位缺陷位置,驗證決策合理性 |

---

#### 10.1.1 卷積核可視化

**問題**: 第一層的卷積核學到了什麼樣的特徵檢測器?

**方法**: 直接可視化卷積核的權重

```python
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.models import load_model

# 載入訓練好的模型
model = load_model('defect_detector.h5')

def visualize_conv_filters(model, layer_name, num_filters=32):
    """
    可視化指定卷積層的濾波器
    
    Args:
        model: Keras模型
        layer_name: 層名稱 (如 'conv2d_1')
        num_filters: 顯示多少個濾波器
    """
    # 獲取指定層
    layer = model.get_layer(name=layer_name)
    
    # 獲取權重: shape = (height, width, in_channels, num_filters)
    weights = layer.get_weights()[0]
    
    # 正規化到 [0, 1]
    weights = (weights - weights.min()) / (weights.max() - weights.min())
    
    # 可視化
    n_cols = 8
    n_rows = min(num_filters, 32) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 2*n_rows))
    fig.suptitle(f'卷積層 "{layer_name}" 的濾波器', fontsize=16)
    
    for i in range(n_rows * n_cols):
        row = i // n_cols
        col = i % n_cols
        
        # 取第 i 個濾波器
        # 如果是彩色輸入 (3通道), 取平均或選一個通道
        if weights.shape[2] == 3:
            filter_img = weights[:, :, :, i].mean(axis=2)  # RGB平均
        else:
            filter_img = weights[:, :, 0, i]  # 灰階
        
        axes[row, col].imshow(filter_img, cmap='viridis')
        axes[row, col].set_title(f'Filter {i}', fontsize=8)
        axes[row, col].axis('off')
    
    plt.tight_layout()
    plt.show()

# 使用範例
visualize_conv_filters(model, layer_name='conv2d', num_filters=32)
```

**典型第一層濾波器模式**:

```
觀察到的模式:
┌─────────────┬─────────────┬─────────────┐
│ 邊緣檢測器   │ 顏色檢測器   │ 紋理檢測器   │
├─────────────┼─────────────┼─────────────┤
│ ╱╱╱╱╱      │ ████ (紅)   │ ▓▓▓▓▓▓     │
│ ╱╱╱╱╱      │ ████ (綠)   │ ▓░▓░▓░     │
│ ╱╱╱╱╱      │ ████ (藍)   │ ▓▓▓▓▓▓     │
└─────────────┴─────────────┴─────────────┘
```

**化工類比**:

| 濾波器類型 | 檢測特徵 | 化工應用場景 |
|-----------|---------|-------------|
| **水平/垂直邊緣** | 裂紋、分界線 | 產品表面裂痕檢測 |
| **斜向邊緣** | 角度、方向 | 晶體生長方向分析 |
| **顏色斑塊** | 色差、污漬 | 產品顏色均勻性檢查 |
| **高頻紋理** | 粗糙度、顆粒感 | 表面光滑度評估 |

> [!NOTE]
> 第一層濾波器通常學到類似Gabor濾波器的模式(邊緣檢測器),這與人類視覺皮層V1區的神經元功能相似!

---

#### 10.1.2 特徵圖可視化

**問題**: 模型在處理具體影像時,每一層「看到」了什麼?

**方法**: 將測試影像通過網路,可視化中間層的輸出(特徵圖)

```python
from tensorflow.keras import models

def visualize_feature_maps(model, img_path, layer_names=None):
    """
    可視化模型中間層的特徵圖
    
    Args:
        model: Keras模型
        img_path: 測試影像路徑
        layer_names: 要可視化的層名稱列表 (None則可視化所有卷積層)
    """
    # 1. 載入並預處理影像
    img = load_and_preprocess_image(img_path)
    
    # 2. 獲取所有卷積層
    if layer_names is None:
        layer_names = [layer.name for layer in model.layers 
                      if 'conv' in layer.name]
    
    # 3. 創建特徵提取模型
    layer_outputs = [model.get_layer(name).output for name in layer_names]
    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)
    
    # 4. 獲取特徵圖
    activations = activation_model.predict(img)
    
    # 5. 可視化每一層
    for layer_name, activation in zip(layer_names, activations):
        visualize_single_layer(layer_name, activation)

def visualize_single_layer(layer_name, activation):
    """可視化單層的特徵圖"""
    # activation shape: (1, height, width, channels)
    n_features = activation.shape[-1]  # 特徵圖數量
    size = activation.shape[1]  # 特徵圖尺寸
    
    # 計算網格大小
    n_cols = 8
    n_rows = (n_features // n_cols) + (1 if n_features % n_cols else 0)
    
    # 限制顯示數量
    n_rows = min(n_rows, 4)
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 2*n_rows))
    fig.suptitle(f'特徵圖: {layer_name} (尺寸: {size}×{size})', fontsize=14)
    
    for i in range(n_rows * n_cols):
        row = i // n_cols
        col = i % n_cols
        
        if i < n_features:
            # 顯示第 i 個特徵圖
            feature_map = activation[0, :, :, i]
            axes[row, col].imshow(feature_map, cmap='viridis')
            axes[row, col].set_title(f'Ch {i}', fontsize=8)
        else:
            axes[row, col].axis('off')
        
        axes[row, col].set_xticks([])
        axes[row, col].set_yticks([])
    
    plt.tight_layout()
    plt.show()

# 使用範例
visualize_feature_maps(model, 'test_images/crack_sample.jpg')
```

**觀察到的特徵演進**:

```
原始影像 (224×224×3)
    ↓
第1層卷積 (112×112×32): 邊緣、顏色、紋理
    特徵圖顯示: 各種方向的邊緣被激活
    ↓
第2層卷積 (56×56×64): 簡單形狀組合
    特徵圖顯示: 角點、小區域模式
    ↓
第3層卷積 (28×28×128): 複雜紋理、局部結構
    特徵圖顯示: 特定紋理類型被激活
    ↓
第4層卷積 (14×14×256): 物體部件
    特徵圖顯示: 越來越抽象,難以直接解讀
```

**化工應用案例**: 表面缺陷檢測

```python
def analyze_defect_detection(model, defect_image_path, normal_image_path):
    """
    對比缺陷品和正常品的特徵圖,找出關鍵差異
    """
    # 獲取兩張影像的特徵圖
    defect_activations = get_activations(model, defect_image_path)
    normal_activations = get_activations(model, normal_image_path)
    
    # 對比分析
    layer_name = 'conv2d_3'  # 選擇一個中間層
    defect_feat = defect_activations[layer_name]
    normal_feat = normal_activations[layer_name]
    
    # 計算差異
    diff = np.abs(defect_feat - normal_feat)
    
    # 找出差異最大的特徵圖
    mean_diff = diff.mean(axis=(1, 2))  # 對每個特徵圖計算平均差異
    top_channels = np.argsort(mean_diff[0])[-8:]  # 差異最大的8個
    
    # 可視化
    fig, axes = plt.subplots(3, 8, figsize=(16, 6))
    
    for i, ch in enumerate(top_channels):
        # 正常品特徵圖
        axes[0, i].imshow(normal_feat[0, :, :, ch], cmap='viridis')
        axes[0, i].set_title(f'正常-Ch{ch}', fontsize=8)
        axes[0, i].axis('off')
        
        # 缺陷品特徵圖
        axes[1, i].imshow(defect_feat[0, :, :, ch], cmap='viridis')
        axes[1, i].set_title(f'缺陷-Ch{ch}', fontsize=8)
        axes[1, i].axis('off')
        
        # 差異圖
        axes[2, i].imshow(diff[0, :, :, ch], cmap='hot')
        axes[2, i].set_title(f'差異-Ch{ch}', fontsize=8)
        axes[2, i].axis('off')
    
    plt.suptitle('正常品 vs 缺陷品 特徵圖對比', fontsize=14)
    plt.tight_layout()
    plt.show()
    
    print(f"\n差異最大的特徵通道: {top_channels}")
    print("這些通道可能對缺陷檢測最重要!")

# 使用範例
analyze_defect_detection(
    model,
    defect_image_path='defects/crack_001.jpg',
    normal_image_path='normal/good_001.jpg'
)
```

**關鍵洞察**:

> [!IMPORTANT]
> **特徵圖可視化的價值**:
> 1. **驗證模型學習**: 檢查模型是否學到了正確的特徵
> 2. **診斷問題**: 如果某層特徵圖全為零,可能有梯度消失問題
> 3. **特徵選擇**: 找出對分類最重要的特徵通道
> 4. **建立信任**: 向工程師展示模型「看到」了缺陷

---

#### 10.1.3 類別激活圖 (Class Activation Mapping, CAM)

**核心問題**: 模型在影像的「哪個位置」看到了缺陷?

**CAM的作用**: 生成熱力圖,顯示影響分類決策的影像區域

**Grad-CAM 原理** (梯度加權類別激活圖):

$$
L_{Grad-CAM}^c = ReLU\left(\sum_k w_k^c A^k\right)
$$

其中:
- $L_{Grad-CAM}^c$ : 類別 $c$ 的激活圖
- $A^k$ : 第 $k$ 個特徵圖
- $w_k^c$ : 特徵圖 $k$ 對類別 $c$ 的重要性權重(透過梯度計算)
- $ReLU$ : 只保留正向貢獻(增加該類別預測的區域)

**實作 Grad-CAM**:

```python
import tensorflow as tf
import cv2

def make_gradcam_heatmap(model, img_array, last_conv_layer_name, pred_index=None):
    """
    生成 Grad-CAM 熱力圖
    
    Args:
        model: Keras模型
        img_array: 預處理後的影像 (1, H, W, C)
        last_conv_layer_name: 最後一個卷積層的名稱
        pred_index: 目標類別索引 (None則使用預測類別)
        
    Returns:
        heatmap: 熱力圖 (H, W)
    """
    # 1. 創建模型: 輸入 → [最後卷積層輸出, 模型預測]
    grad_model = tf.keras.models.Model(
        inputs=[model.inputs],
        outputs=[model.get_layer(last_conv_layer_name).output, model.output]
    )
    
    # 2. 計算梯度
    with tf.GradientTape() as tape:
        # 前向傳播
        conv_outputs, predictions = grad_model(img_array)
        
        # 如果沒指定類別,使用預測類別
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        
        # 取該類別的預測分數
        class_channel = predictions[:, pred_index]
    
    # 3. 計算梯度: 預測分數對最後卷積層輸出的梯度
    grads = tape.gradient(class_channel, conv_outputs)
    
    # 4. 全局平均池化梯度 → 每個特徵圖的重要性權重
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    
    # 5. 加權求和特徵圖
    conv_outputs = conv_outputs[0]  # (H, W, C)
    pooled_grads = pooled_grads.numpy()
    
    heatmap = np.zeros(conv_outputs.shape[:2])  # (H, W)
    for i in range(len(pooled_grads)):
        heatmap += pooled_grads[i] * conv_outputs[:, :, i]
    
    # 6. ReLU + 正規化
    heatmap = np.maximum(heatmap, 0)  # ReLU
    heatmap = heatmap / (heatmap.max() + 1e-10)  # 正規化到 [0, 1]
    
    return heatmap

def overlay_heatmap_on_image(img_path, heatmap, alpha=0.4, colormap=cv2.COLORMAP_JET):
    """
    將熱力圖疊加到原始影像上
    
    Args:
        img_path: 原始影像路徑
        heatmap: Grad-CAM熱力圖 (H, W), 值在 [0, 1]
        alpha: 熱力圖透明度
        colormap: OpenCV顏色映射
        
    Returns:
        superimposed_img: 疊加後的影像
    """
    # 1. 載入原始影像
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # 2. 調整熱力圖尺寸到原始影像大小
    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
    
    # 3. 轉換為彩色熱力圖
    heatmap_colored = cv2.applyColorMap(
        np.uint8(255 * heatmap_resized), 
        colormap
    )
    heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)
    
    # 4. 疊加
    superimposed_img = heatmap_colored * alpha + img * (1 - alpha)
    superimposed_img = np.uint8(superimposed_img)
    
    return superimposed_img, heatmap_resized

def visualize_gradcam(model, img_path, last_conv_layer_name='conv2d_4'):
    """
    完整的 Grad-CAM 可視化流程
    """
    # 1. 載入並預處理影像
    img_array = load_and_preprocess_image(img_path)
    
    # 2. 預測
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions[0])
    confidence = predictions[0][predicted_class]
    
    # 3. 生成熱力圖
    heatmap = make_gradcam_heatmap(model, img_array, last_conv_layer_name)
    
    # 4. 疊加到原始影像
    superimposed_img, heatmap_resized = overlay_heatmap_on_image(img_path, heatmap)
    
    # 5. 可視化
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # 原始影像
    original_img = cv2.imread(img_path)
    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
    axes[0].imshow(original_img)
    axes[0].set_title('原始影像')
    axes[0].axis('off')
    
    # 熱力圖
    axes[1].imshow(heatmap_resized, cmap='jet')
    axes[1].set_title('Grad-CAM 熱力圖')
    axes[1].axis('off')
    
    # 疊加
    axes[2].imshow(superimposed_img)
    axes[2].set_title(f'預測: {class_names[predicted_class]} ({confidence:.2%})')
    axes[2].axis('off')
    
    plt.suptitle('Grad-CAM 可視化: 模型關注的區域', fontsize=14)
    plt.tight_layout()
    plt.show()
    
    return heatmap, superimposed_img

# 使用範例
class_names = ['正常', '裂紋', '凹陷', '刮痕', '污漬']

heatmap, overlay = visualize_gradcam(
    model, 
    'test_images/crack_sample.jpg',
    last_conv_layer_name='conv2d_4'  # 最後一個卷積層
)
```

**化工應用: 缺陷定位**

```python
def batch_gradcam_analysis(model, img_folder, output_folder, threshold=0.8):
    """
    批次生成 Grad-CAM,用於缺陷定位和驗證
    
    用途:
    1. 驗證模型是否關注正確區域
    2. 自動標註缺陷位置
    3. 生成檢測報告
    """
    os.makedirs(output_folder, exist_ok=True)
    
    img_paths = [os.path.join(img_folder, f) for f in os.listdir(img_folder)
                 if f.endswith(('.jpg', '.png'))]
    
    results = []
    
    for img_path in tqdm(img_paths):
        # 預測
        img_array = load_and_preprocess_image(img_path)
        predictions = model.predict(img_array, verbose=0)
        pred_class = np.argmax(predictions[0])
        confidence = predictions[0][pred_class]
        
        # 只對高信心的預測生成 Grad-CAM
        if confidence >= threshold:
            # 生成熱力圖
            heatmap = make_gradcam_heatmap(model, img_array, 'conv2d_4', pred_class)
            superimposed, _ = overlay_heatmap_on_image(img_path, heatmap)
            
            # 保存結果
            output_path = os.path.join(
                output_folder, 
                f"{os.path.basename(img_path)[:-4]}_gradcam.jpg"
            )
            cv2.imwrite(output_path, cv2.cvtColor(superimposed, cv2.COLOR_RGB2BGR))
            
            results.append({
                'image': os.path.basename(img_path),
                'predicted_class': class_names[pred_class],
                'confidence': confidence,
                'gradcam_saved': output_path
            })
    
    # 生成報告
    df = pd.DataFrame(results)
    df.to_csv(os.path.join(output_folder, 'gradcam_report.csv'), 
              index=False, encoding='utf-8-sig')
    
    print(f"✅ 已處理 {len(results)} 張影像,結果保存至: {output_folder}")
    
    return df

# 使用範例
report = batch_gradcam_analysis(
    model,
    img_folder='production_batch_001/',
    output_folder='gradcam_results/',
    threshold=0.8
)
```

**Grad-CAM 應用價值**:

| 應用場景 | 具體用途 | 化工實例 |
|---------|---------|---------|
| **模型驗證** | 確認模型關注正確區域 | 檢查是否真的看到裂紋,而非背景 |
| **缺陷定位** | 自動標註缺陷位置 | 生成缺陷位置熱力圖供人工複檢 |
| **誤判診斷** | 找出誤判原因 | 分析為何把正常品判為缺陷品 |
| **建立信任** | 向操作員解釋AI決策 | 「看,模型就是在這個位置發現問題」 |

> [!CAUTION]
> **Grad-CAM 的限制**:
> - 只能顯示「促進該類別預測」的區域
> - 解析度受限於最後卷積層的特徵圖尺寸
> - 無法解釋為什麼模型「沒有」選擇某個類別

---

### 10.1.4 可解釋性總結與化工應用

**可解釋性技術對比**:

| 技術 | 優點 | 缺點 | 化工應用場景 |
|------|------|------|-------------|
| **卷積核可視化** | 直觀,易理解 | 只能看第一層 | 了解基礎特徵提取器 |
| **特徵圖分析** | 看到完整處理流程 | 深層難解讀 | 診斷模型問題,特徵工程 |
| **Grad-CAM** | 直接定位關鍵區域 | 解析度有限 | 缺陷定位,建立信任 |

**化工產線部署建議**:

```python
# 生產環境: 結合預測和可解釋性
def production_predict_with_explanation(model, img_path, 
                                       confidence_threshold=0.85,
                                       generate_gradcam=True):
    """
    生產級預測 + 可解釋性
    
    低信心預測自動生成 Grad-CAM 供人工複檢
    """
    # 1. 預測
    img_array = load_and_preprocess_image(img_path)
    predictions = model.predict(img_array, verbose=0)
    pred_class = np.argmax(predictions[0])
    confidence = predictions[0][pred_class]
    
    result = {
        'predicted_class': class_names[pred_class],
        'confidence': confidence,
        'action': 'AUTO_PASS' if confidence >= confidence_threshold else 'MANUAL_CHECK'
    }
    
    # 2. 低信心 → 生成 Grad-CAM
    if confidence < confidence_threshold and generate_gradcam:
        heatmap = make_gradcam_heatmap(model, img_array, 'conv2d_4', pred_class)
        overlay, _ = overlay_heatmap_on_image(img_path, heatmap)
        
        # 保存可視化結果供人工查看
        gradcam_path = f"manual_review/{os.path.basename(img_path)[:-4]}_gradcam.jpg"
        cv2.imwrite(gradcam_path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))
        
        result['gradcam_path'] = gradcam_path
        result['note'] = '信心不足,已生成熱力圖供人工複檢'
    
    return result

# 使用
result = production_predict_with_explanation(model, 'test.jpg')
if result['action'] == 'MANUAL_CHECK':
    print(f"⚠️ 需要人工複檢: {result['note']}")
    print(f"   查看熱力圖: {result['gradcam_path']}")
```

**本節小結**:

✅ **卷積核可視化**: 理解模型學到的基礎特徵檢測器  
✅ **特徵圖分析**: 追蹤模型的「視覺」處理流程  
✅ **Grad-CAM**: 定位影響決策的關鍵影像區域  
✅ **化工應用**: 建立信任、缺陷定位、誤判診斷  

> [!IMPORTANT]
> 可解釋性不僅是研究工具,更是工業部署的**必需品**。沒有人敢在化工產線上使用完全的「黑盒子」!

---

### 10.2 遷移學習與預訓練模型

**問題場景**: 化工公司想做產品缺陷檢測,但只有500張標註影像。從零訓練CNN需要數萬張影像,怎麼辦?

**解決方案**: 遷移學習 (Transfer Learning) - 站在巨人的肩膀上!

#### 10.2.1 遷移學習的核心概念

**核心思想**: 在大規模數據集(ImageNet)上訓練的模型,已經學會了通用的視覺特徵(邊緣、紋理、形狀等)。我們可以「遷移」這些知識到化工任務。

**化工類比**:

想像培訓一位品質檢測員:
- **從零訓練** = 招聘完全沒經驗的新人,從「什麼是影像」開始教 → 需要數年時間
- **遷移學習** = 招聘有豐富視覺經驗的人(看過上百萬張照片),只需教他「化工產品的特殊缺陷」→ 只需數週

**ImageNet 預訓練的價值**:

| 學習層次 | 學到的特徵 | 是否需要重新學習? |
|---------|-----------|------------------|
| **淺層** | 邊緣、顏色、紋理 | ❌ 通用特徵,可直接複用 |
| **中層** | 形狀、角點、小區域模式 | ⚠️ 部分可用,可能需微調 |
| **深層** | 物體部件、語義特徵 | ✅ 任務特定,需要重新訓練 |

**遷移學習的兩種策略**:

```
策略1: 特徵提取 (Feature Extraction)
┌─────────────────────────────────────────┐
│ 預訓練模型                               │
│ ┌──────────┐  ┌──────────┐  ┌─────────┐│
│ │ 卷積層   │→ │ 卷積層   │→ │ 卷積層  ││
│ │ (凍結)  │  │ (凍結)  │  │ (凍結) ││ ← 固定權重,不訓練
│ └──────────┘  └──────────┘  └─────────┘│
└─────────────────────────────────────────┘
                    ↓
         ┌─────────────────────┐
         │ 新的全連接層         │
         │ (隨機初始化,訓練)   │ ← 只訓練這部分
         └─────────────────────┘
                    ↓
              化工任務輸出

策略2: 微調 (Fine-Tuning)
┌─────────────────────────────────────────┐
│ 預訓練模型                               │
│ ┌──────────┐  ┌──────────┐  ┌─────────┐│
│ │ 卷積層   │→ │ 卷積層   │→ │ 卷積層  ││
│ │ (凍結)  │  │ (微調)  │  │ (微調) ││ ← 以極小學習率微調
│ └──────────┘  └──────────┘  └─────────┘│
└─────────────────────────────────────────┘
                    ↓
         ┌─────────────────────┐
         │ 新的全連接層         │
         │ (訓練)             │
         └─────────────────────┘
```

---

#### 10.2.2 使用預訓練模型

**Keras 提供的預訓練模型**:

| 模型 | 參數量 | ImageNet Top-1 | 推薦用途 |
|------|-------|----------------|---------|
| **VGG16** | 138M | 71.3% | 特徵提取基準 |
| **ResNet50** | 25.6M | 76.1% | 平衡準確率和速度 |
| **InceptionV3** | 23.9M | 77.9% | 多尺度特徵提取 |
| **MobileNetV2** | 3.5M | 71.8% | 邊緣設備、移動端 |
| **EfficientNetB0** | 5.3M | 77.1% | 最佳準確率/效率比 |

**載入預訓練模型 (特徵提取)**:

```python
from tensorflow.keras.applications import ResNet50
from tensorflow.keras import layers, models

# 1. 載入預訓練模型 (不包含頂部分類層)
base_model = ResNet50(
    weights='imagenet',     # 使用 ImageNet 預訓練權重
    include_top=False,      # 不包含最後的全連接層
    input_shape=(224, 224, 3)  # 輸入影像尺寸
)

# 2. 凍結預訓練層 (不訓練)
base_model.trainable = False

print(f"基礎模型層數: {len(base_model.layers)}")
print(f"可訓練參數: {base_model.count_params()}")

# 3. 添加自定義分類頭
model = models.Sequential([
    base_model,  # 預訓練的特徵提取器
    
    # 全局平均池化 (替代 Flatten, 更少參數)
    layers.GlobalAveragePooling2D(),
    
    # 自定義分類層
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(5, activation='softmax')  # 5類別化工缺陷分類
])

# 4. 編譯模型
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()
```

**輸出分析**:

```
Total params: 25,636,712
Trainable params: 328,453    ← 只訓練新添加的層
Non-trainable params: 25,308,259  ← 預訓練權重被凍結
```

**訓練特徵提取模型**:

```python
# 準備數據 (假設已有 ImageDataGenerator)
history = model.fit(
    train_generator,
    epochs=10,  # 特徵提取階段,通常10-20 epochs足夠
    validation_data=val_generator,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),
        tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)
    ]
)

# 評估
test_loss, test_acc = model.evaluate(test_generator)
print(f"測試準確率: {test_acc:.2%}")
```

---

#### 10.2.3 微調 (Fine-Tuning)

**何時需要微調?**

- ✅ 特徵提取性能已不錯,想進一步提升
- ✅ 化工影像與 ImageNet 差異較大
- ✅ 有足夠的訓練數據 (>1000張)

**微調策略**:

```python
# 第一階段: 特徵提取 (已完成,假設達到 85% 準確率)

# 第二階段: 微調
print("開始微調...")

# 1. 解凍基礎模型的後半部分
base_model.trainable = True

# 查看所有層
print(f"總層數: {len(base_model.layers)}")

# 凍結前100層,微調後面的層
fine_tune_at = 100

for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False

for layer in base_model.layers[fine_tune_at:]:
    layer.trainable = True

print(f"凍結層: 0-{fine_tune_at}")
print(f"微調層: {fine_tune_at}-{len(base_model.layers)}")

# 2. 重新編譯 (使用更小的學習率!)
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),  # 比初始訓練小100倍
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# 3. 微調訓練
history_fine = model.fit(
    train_generator,
    epochs=10,  # 再訓練10個epochs
    initial_epoch=history.epoch[-1],  # 從上次結束繼續
    validation_data=val_generator,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)
    ]
)

# 評估微調效果
test_loss, test_acc = model.evaluate(test_generator)
print(f"微調後測試準確率: {test_acc:.2%}")  # 預期提升到 88-90%
```

**微調的關鍵要點**:

> [!IMPORTANT]
> **微調三原則**:
> 1. **小學習率**: 避免破壞預訓練權重 (通常是初始訓練的 1/10 ~ 1/100)
> 2. **逐步解凍**: 先凍結全部,再逐步解凍後面的層
> 3. **早停機制**: 防止過擬合,保留最佳權重

**可視化訓練過程**:

```python
def plot_transfer_learning_history(history1, history2):
    """
    可視化遷移學習的兩階段訓練
    
    Args:
        history1: 特徵提取階段的訓練歷史
        history2: 微調階段的訓練歷史
    """
    # 合併兩階段歷史
    acc = history1.history['accuracy'] + history2.history['accuracy']
    val_acc = history1.history['val_accuracy'] + history2.history['val_accuracy']
    loss = history1.history['loss'] + history2.history['loss']
    val_loss = history1.history['val_loss'] + history2.history['val_loss']
    
    plt.figure(figsize=(14, 5))
    
    # 準確率
    plt.subplot(1, 2, 1)
    plt.plot(acc, label='訓練準確率')
    plt.plot(val_acc, label='驗證準確率')
    plt.axvline(x=len(history1.history['accuracy']), 
                color='r', linestyle='--', label='開始微調')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title('遷移學習: 準確率變化')
    plt.grid(True, alpha=0.3)
    
    # 損失
    plt.subplot(1, 2, 2)
    plt.plot(loss, label='訓練損失')
    plt.plot(val_loss, label='驗證損失')
    plt.axvline(x=len(history1.history['loss']), 
                color='r', linestyle='--', label='開始微調')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('遷移學習: 損失變化')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

plot_transfer_learning_history(history, history_fine)
```

---

#### 10.2.4 選擇合適的預訓練模型

**決策樹**:

```
數據量多少?
    ├─ <500張 → 特徵提取 + 簡單分類頭
    ├─ 500-2000張 → 特徵提取 + 輕度微調 (後20%層)
    └─ >2000張 → 特徵提取 + 深度微調 (後50%層)
    
計算資源?
    ├─ GPU充足 → ResNet50 / EfficientNetB0
    ├─ 邊緣設備 → MobileNetV2
    └─ 極端受限 → 從零訓練小模型 (可能比大模型更好)

影像特性?
    ├─ 高解析度細節 → VGG16 (保留更多空間資訊)
    ├─ 多尺度特徵 → InceptionV3
    └─ 一般場景 → ResNet50 (通用選擇)
```

**化工應用對比**:

| 應用場景 | 推薦模型 | 理由 | 預期性能 |
|---------|---------|------|---------|
| **產品表面缺陷** | ResNet50 | 需要深層特徵,殘差連接穩定 | 95%+ |
| **顯微影像分析** | VGG16 | 需要細節,大卷積核保留更多資訊 | 90%+ |
| **即時品質檢測** | MobileNetV2 | 速度快,適合邊緣部署 | 90%+ |
| **多尺度缺陷** | InceptionV3 | 不同大小的缺陷都能檢測 | 93%+ |
| **小數據集 (<500)** | EfficientNetB0 | 參數效率高,過擬合風險小 | 85%+ |

---

#### 10.2.5 完整化工應用範例

**案例: 化工產品表面缺陷檢測 (5類別, 1000張影像)**

```python
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ========== 第一階段: 數據準備 ==========
# 數據增強 (關鍵!)
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    'data/train',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    'data/validation',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# ========== 第二階段: 建立模型 (特徵提取) ==========
base_model = ResNet50(
    weights='imagenet',
    include_top=False,
    input_shape=(224, 224, 3)
)

base_model.trainable = False  # 凍結所有層

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.BatchNormalization(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(5, activation='softmax')  # 5類別
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# ========== 第三階段: 特徵提取訓練 ==========
print("第一階段: 特徵提取訓練...")
history1 = model.fit(
    train_generator,
    epochs=15,
    validation_data=val_generator,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),
        tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3),
        tf.keras.callbacks.ModelCheckpoint('best_model_stage1.h5', save_best_only=True)
    ]
)

# ========== 第四階段: 微調 ==========
print("\n第二階段: 微調訓練...")
base_model.trainable = True

# 凍結前100層
for layer in base_model.layers[:100]:
    layer.trainable = False

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),  # 小學習率!
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history2 = model.fit(
    train_generator,
    epochs=10,
    initial_epoch=len(history1.history['loss']),
    validation_data=val_generator,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),
        tf.keras.callbacks.ModelCheckpoint('best_model_final.h5', save_best_only=True)
    ]
)

# ========== 第五階段: 評估 ==========
test_generator = val_datagen.flow_from_directory(
    'data/test',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

test_loss, test_acc = model.evaluate(test_generator)
print(f"\n最終測試準確率: {test_acc:.2%}")

# 保存最終模型
model.save('defect_detector_transfer_learning.h5')
print("模型已保存!")

# ========== 第六階段: 可視化 ==========
plot_transfer_learning_history(history1, history2)
```

**預期結果**:

```
階段1 (特徵提取): 
  - Epochs: ~10
  - 驗證準確率: 87-92%
  - 訓練時間: 10-20分鐘 (GPU)

階段2 (微調):
  - Epochs: ~5-8
  - 驗證準確率: 92-96%
  - 訓練時間: 15-30分鐘

總結:
  - 從零訓練可能需要: 10,000張影像, 數天訓練
  - 遷移學習僅需: 1,000張影像, <1小時訓練
  - 性能提升: 從 70% → 95%
```

---

#### 10.2.6 遷移學習的限制與建議

**何時遷移學習效果不佳?**

| 情況 | 原因 | 解決方案 |
|------|------|---------|
| **影像差異極大** | 化工顯微影像 vs ImageNet自然影像 | 考慮領域特定預訓練模型 |
| **極小數據 (<100)** | 即使遷移學習也容易過擬合 | 數據增強 + 極簡分類頭 |
| **極端邊緣部署** | 預訓練模型太大 | 從零訓練小模型 |
| **實時性要求高** | 大模型推論慢 | 使用 MobileNet 或模型蒸餾 |

**化工領域的特殊考量**:

> [!TIP]
> **化工影像的特殊處理**:
> 1. **灰階影像**: 如果只有單通道,複製成3通道或使用灰階預訓練模型
> 2. **非標準尺寸**: 統一 resize 到 224×224, 或使用 GlobalAveragePooling 支持任意尺寸
> 3. **極端光照**: 訓練時增加亮度/對比度增強
> 4. **微小缺陷**: 使用高解析度輸入 (如 384×384) 或裁剪感興趣區域

**從零訓練 vs 遷移學習 決策表**:

| 考量因素 | 從零訓練 | 遷移學習 |
|---------|---------|---------|
| **數據量需求** | >10,000張 | 500-2,000張 |
| **訓練時間** | 數天 | 數小時 |
| **GPU需求** | 高 | 中等 |
| **最終性能** | 可能更優 (如果數據充足) | 通常足夠好 |
| **推薦場景** | 領域特定、數據豐富 | 大多數化工應用 |

---

### 10.2.7 本節小結

✅ **遷移學習核心**: 複用 ImageNet 學到的通用視覺特徵  
✅ **兩階段策略**: 先特徵提取,再微調  
✅ **模型選擇**: 根據數據量、計算資源、影像特性選擇  
✅ **化工應用**: 小數據集 (500-2000張) 就能達到 90%+ 準確率  

**關鍵要點**:

```
遷移學習 = 預訓練模型 + 領域適配

成功要素:
1. 選擇合適的預訓練模型
2. 足夠的數據增強
3. 合理的凍結/解凍策略
4. 微調時使用極小學習率
5. 早停機制防止過擬合
```

> [!IMPORTANT]
> 在化工領域,**95%的應用場景都應該優先考慮遷移學習**,而非從零訓練!

---

### 10.3 從MNIST到工業應用的鴻溝

**現實困境**: 在MNIST上達到 99% 準確率很容易,但在化工產線上...

```
實驗室環境:
✅ MNIST: 99.2% 準確率
✅ 訓練時間: 10分鐘
✅ 數據完美: 乾淨、均勻、標準化

化工產線現實:
❌ 實際準確率: 70-80% (初次部署)
❌ 誤報頻繁: 正常品被判為缺陷
❌ 數據混亂: 光照不均、角度各異、部分遮擋
```

**核心問題**: 為什麼 MNIST 的成功經驗無法直接遷移到工業應用?

---

#### 10.3.1 數據品質鴻溝

**MNIST vs 化工影像對比**:

| 特性 | MNIST | 化工產線影像 | 影響 |
|------|-------|-------------|------|
| **影像品質** | 完美清晰 | 光照不均、模糊、雜訊 | 特徵提取困難 |
| **拍攝角度** | 正面、居中 | 任意角度、偏移、傾斜 | 需要旋轉不變性 |
| **背景** | 純黑背景 | 複雜背景、反光、陰影 | 容易誤判 |
| **尺寸** | 統一 28×28 | 不同產品尺寸各異 | 需要尺度不變性 |
| **類內變異** | 極小 | 巨大 (同類缺陷千變萬化) | 泛化困難 |
| **類間差異** | 明顯 | 模糊 (輕微劃痕 vs 嚴重劃痕) | 決策邊界難定 |

**具體案例: 產品表面劃痕檢測**

```python
# MNIST 風格的「完美」數據
perfect_data = {
    'lighting': '均勻光照',
    'angle': '正面 0°',
    'background': '純色背景',
    'position': '居中',
    'quality': '高清無雜訊',
    'label_quality': '100%正確'
}

# 化工產線的「現實」數據
real_data = {
    'lighting': '左邊亮、右邊暗,還有反光',
    'angle': '5-30° 傾斜,隨機旋轉',
    'background': '傳送帶、其他產品、操作員手',
    'position': '偏移、部分遮擋',
    'quality': '運動模糊、壓縮失真、灰塵',
    'label_quality': '70-80%正確 (標註人員也會犯錯)'
}
```

**解決策略**:

| 問題 | 解決方案 | 實作技巧 |
|------|---------|---------|
| **光照不均** | 預處理正規化 | 直方圖均衡化、自適應閾值 |
| **角度變化** | 數據增強 | 旋轉 ±30°、翻轉 |
| **複雜背景** | 目標檢測 + 分類 | 先用 YOLO 定位產品,再分類 |
| **尺寸不一** | Multi-scale training | 訓練時使用多種解析度 |
| **類內變異大** | 更多數據 + 遷移學習 | 至少每類 500+ 張 |
| **標註錯誤** | 半監督學習 | 用高信心樣本重新訓練 |

**數據清洗範例**:

```python
def preprocess_industrial_image(img_path):
    """
    化工影像預處理 - 處理現實世界的問題
    """
    # 載入影像
    img = cv2.imread(img_path)
    
    # 1. 光照正規化
    # 轉換到 LAB 色彩空間, 對 L 通道進行直方圖均衡化
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    l = clahe.apply(l)
    img = cv2.merge([l, a, b])
    img = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)
    
    # 2. 降噪
    img = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)
    
    # 3. 銳化 (如果影像模糊)
    kernel = np.array([[-1,-1,-1],
                       [-1, 9,-1],
                       [-1,-1,-1]])
    img = cv2.filter2D(img, -1, kernel)
    
    # 4. Resize到標準尺寸
    img = cv2.resize(img, (224, 224))
    
    # 5. 正規化
    img = img.astype(np.float32) / 255.0
    
    return img
```

---

#### 10.3.2 環境穩健性鴻溝

**MNIST**: 永遠不變的環境  
**化工產線**: 時刻變化的環境

**常見環境變化**:

| 變化類型 | 具體表現 | 對模型影響 | 檢測方法 |
|---------|---------|-----------|---------|
| **光照漂移** | 早上明亮、傍晚昏暗 | 同樣產品預測不一致 | 監控平均亮度 |
| **設備老化** | 鏡頭髒污、焦距偏移 | 影像模糊,準確率下降 | 監控影像清晰度 |
| **產品變更** | 新批次材料、顏色略異 | 正常品被誤判 | 監控預測分布 |
| **季節變化** | 溫濕度影響產品外觀 | 夏天和冬天表現不同 | 季節性重訓練 |

**數據漂移檢測器** (前面9.4.3已實作,這裡應用):

```python
class IndustrialDriftMonitor:
    """
    工業環境漂移監控
    """
    def __init__(self, model, reference_data):
        self.model = model
        self.reference_dist = self._compute_prediction_dist(reference_data)
        self.drift_history = []
    
    def check_daily_drift(self, daily_images):
        """
        每日檢查數據漂移
        
        Args:
            daily_images: 當天拍攝的影像列表
            
        Returns:
            report: 漂移檢測報告
        """
        # 1. 批次預測
        predictions = []
        for img_path in daily_images:
            img = load_and_preprocess_image(img_path)
            pred = self.model.predict(img, verbose=0)
            predictions.append(pred[0])
        
        # 2. 計算分布差異
        current_dist = np.mean(predictions, axis=0)
        kl_div = self._kl_divergence(self.reference_dist, current_dist)
        
        # 3. 計算影像品質指標
        brightness_avg = np.mean([cv2.imread(img).mean() for img in daily_images[:10]])
        sharpness_avg = np.mean([self._calculate_sharpness(cv2.imread(img)) 
                                 for img in daily_images[:10]])
        
        # 4. 生成報告
        report = {
            'date': datetime.now().date(),
            'num_images': len(daily_images),
            'kl_divergence': kl_div,
            'drift_detected': kl_div > 0.1,
            'avg_brightness': brightness_avg,
            'avg_sharpness': sharpness_avg,
            'recommendation': self._generate_recommendation(kl_div, brightness_avg, sharpness_avg)
        }
        
        self.drift_history.append(report)
        
        if report['drift_detected']:
            print(f"⚠️ 檢測到數據漂移! KL散度={kl_div:.4f}")
            print(f"   建議: {report['recommendation']}")
        
        return report
    
    def _calculate_sharpness(self, img):
        """計算影像清晰度 (Laplacian方差)"""
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        return cv2.Laplacian(gray, cv2.CV_64F).var()
    
    def _generate_recommendation(self, kl_div, brightness, sharpness):
        """根據指標生成建議"""
        recommendations = []
        
        if brightness < 50:
            recommendations.append("增加照明亮度")
        elif brightness > 200:
            recommendations.append("降低照明或調整曝光")
        
        if sharpness < 100:
            recommendations.append("檢查鏡頭清潔度和對焦")
        
        if kl_div > 0.15:
            recommendations.append("考慮重新訓練模型或微調")
        
        return '; '.join(recommendations) if recommendations else "系統運行正常"

# 使用範例
monitor = IndustrialDriftMonitor(model, validation_images)

# 每日監控
daily_report = monitor.check_daily_drift(get_today_images())

# 每週生成趨勢報告
if len(monitor.drift_history) >= 7:
    plot_drift_trend(monitor.drift_history)
```

---

#### 10.3.3 部署可靠性鴻溝

**MNIST**: 離線測試,錯了也沒關係  
**化工產線**: 24/7 運行,錯誤有實際成本

**可靠性要求對比**:

| 層面 | MNIST實驗 | 化工產線 | 差距 |
|------|----------|---------|------|
| **可用性** | 隨時可停 | 99.9% 正常運行時間 | 需要容錯機制 |
| **延遲** | 無要求 | <100ms (產線節拍) | 需要優化 |
| **錯誤成本** | 0 | 誤判成本、漏檢成本 | 需要成本感知決策 |
| **可維護性** | 無 | 需要監控、日誌、告警 | 需要 MLOps |
| **可解釋性** | 無 | 工程師需要理解決策 | 需要 Grad-CAM |

**工業級可靠性架構**:

```python
class IndustrialCNNSystem:
    """
    工業級CNN部署系統
    """
    def __init__(self, primary_model_path, fallback_model_path=None):
        self.primary_model = self._load_model_safe(primary_model_path)
        self.fallback_model = self._load_model_safe(fallback_model_path) if fallback_model_path else None
        
        # 監控
        self.performance_monitor = PerformanceMonitor()
        self.drift_monitor = IndustrialDriftMonitor(self.primary_model, reference_data)
        
        # 容錯
        self.consecutive_errors = 0
        self.max_errors = 5
        
        # 日誌
        self.logger = self._setup_logger()
    
    def predict_with_reliability(self, img_path, timeout=1.0):
        """
        可靠性優先的預測
        
        容錯策略:
        1. 主模型超時 → 備用模型
        2. 連續錯誤 → 告警並切換到手動模式
        3. 低信心 → 人工複檢
        """
        start_time = time.time()
        
        try:
            # 1. 影像品質檢查
            quality_check = self._check_image_quality(img_path)
            if not quality_check['passed']:
                self.logger.warning(f"影像品質不佳: {quality_check['reason']}")
                return self._safe_fallback(img_path, reason='poor_quality')
            
            # 2. 主模型預測
            result = self._predict_with_timeout(
                self.primary_model, 
                img_path, 
                timeout
            )
            
            # 3. 信心度檢查
            if result['confidence'] < 0.75:
                # 低信心 → 嘗試備用模型
                if self.fallback_model:
                    fallback_result = self._predict_with_timeout(
                        self.fallback_model,
                        img_path,
                        timeout
                    )
                    # 如果兩個模型預測一致且信心提升,使用備用模型結果
                    if (fallback_result['predicted_class'] == result['predicted_class'] and
                        fallback_result['confidence'] > result['confidence']):
                        result = fallback_result
                        result['model_used'] = 'fallback'
                
                # 仍然低信心 → 人工複檢
                if result['confidence'] < 0.75:
                    result['action'] = 'MANUAL_CHECK'
                    result['reason'] = 'low_confidence'
            
            # 4. 記錄性能
            latency = (time.time() - start_time) * 1000
            self.performance_monitor.record_prediction(
                latency,
                result['predicted_class'],
                result['confidence']
            )
            
            # 5. 重置錯誤計數
            self.consecutive_errors = 0
            
            return result
            
        except Exception as e:
            self.consecutive_errors += 1
            self.logger.error(f"預測錯誤 ({self.consecutive_errors}/{self.max_errors}): {e}")
            
            # 連續錯誤過多 → 系統告警
            if self.consecutive_errors >= self.max_errors:
                self._trigger_alert("CNN系統連續錯誤,需要維護!")
                return self._safe_fallback(img_path, reason='system_error')
            
            # 嘗試備用模型
            if self.fallback_model:
                try:
                    result = self._predict_with_timeout(self.fallback_model, img_path, timeout)
                    result['model_used'] = 'fallback'
                    return result
                except:
                    pass
            
            # 所有嘗試都失敗 → 安全回退
            return self._safe_fallback(img_path, reason='prediction_failed')
    
    def _check_image_quality(self, img_path):
        """檢查影像品質"""
        img = cv2.imread(img_path)
        
        if img is None:
            return {'passed': False, 'reason': '影像載入失敗'}
        
        # 檢查亮度
        brightness = img.mean()
        if brightness < 30 or brightness > 225:
            return {'passed': False, 'reason': f'亮度異常: {brightness:.1f}'}
        
        # 檢查清晰度
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
        if sharpness < 100:
            return {'passed': False, 'reason': f'影像模糊: {sharpness:.1f}'}
        
        return {'passed': True}
    
    def _safe_fallback(self, img_path, reason):
        """安全回退決策"""
        self.logger.warning(f"進入安全回退模式: {reason}")
        return {
            'predicted_class': 'UNKNOWN',
            'confidence': 0.0,
            'action': 'MANUAL_CHECK',
            'reason': reason,
            'model_used': 'none',
            'timestamp': datetime.now().isoformat()
        }
    
    def _trigger_alert(self, message):
        """觸發系統告警 (可接入郵件、簡訊等)"""
        self.logger.critical(f"🚨 系統告警: {message}")
        # TODO: 發送郵件/簡訊通知維護人員
        
    def _load_model_safe(self, model_path):
        """安全載入模型"""
        try:
            model = tf.keras.models.load_model(model_path)
            self.logger.info(f"✅ 模型已載入: {model_path}")
            return model
        except Exception as e:
            self.logger.error(f"❌ 模型載入失敗: {e}")
            return None
    
    def _setup_logger(self):
        """設置日誌系統"""
        logger = logging.getLogger('IndustrialCNN')
        logger.setLevel(logging.INFO)
        
        # 檔案處理器
        fh = logging.FileHandler('industrial_cnn.log')
        fh.setLevel(logging.INFO)
        
        # 格式
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        fh.setFormatter(formatter)
        
        logger.addHandler(fh)
        return logger
    
    def daily_health_check(self):
        """每日健康檢查"""
        metrics = self.performance_monitor.get_metrics()
        drift_report = self.drift_monitor.check_daily_drift(get_today_images())
        
        health_report = {
            'date': datetime.now().date(),
            'predictions_count': metrics['throughput_fps'] * 3600 * 8,  # 假設8小時運行
            'avg_latency': metrics['avg_latency_ms'],
            'error_rate': metrics['error_rate'],
            'drift_detected': drift_report['drift_detected'],
            'status': 'HEALTHY' if metrics['error_rate'] < 0.01 and not drift_report['drift_detected'] else 'ATTENTION_NEEDED'
        }
        
        self.logger.info(f"每日健康檢查: {health_report}")
        return health_report

# 部署範例
system = IndustrialCNNSystem(
    primary_model_path='models/defect_detector_v2.h5',
    fallback_model_path='models/defect_detector_v1.h5'  # 舊版本作為備份
)

# 產線使用
result = system.predict_with_reliability('production_line/item_001.jpg')

if result['action'] == 'MANUAL_CHECK':
    print(f"⚠️ 需要人工複檢: {result['reason']}")
else:
    print(f"✅ 自動檢測: {result['predicted_class']} ({result['confidence']:.2%})")

# 每日健康檢查
daily_report = system.daily_health_check()
```

---

#### 10.3.4 實際案例: MNIST到化工的完整遷移

**案例背景**: 從手寫數字識別遷移到化學品包裝批號識別

**挑戰對比**:

| 挑戰 | MNIST | 化學品批號 | 解決方案 |
|------|-------|-----------|---------|
| **字體** | 統一手寫 | 噴印、標籤、手寫混合 | 多字體訓練數據 |
| **清晰度** | 高清 | 磨損、污漬、反光 | 強化預處理 |
| **背景** | 純色 | 包裝材質、顏色各異 | 背景分割 |
| **完整性** | 完整數字 | 部分遮擋、殘缺 | 序列模型(LSTM) |
| **實時性** | 無要求 | 產線速度 1件/秒 | 模型優化(TFLite) |

**解決方案架構**:

```python
class ChemicalBatchNumberRecognizer:
    """
    化學品批號識別系統 (從MNIST演進而來)
    """
    def __init__(self):
        # 第一步: 目標檢測 (定位批號區域)
        self.detector = self._load_detector()
        
        # 第二步: 字符分割
        self.segmenter = CharacterSegmenter()
        
        # 第三步: 字符識別 (基於MNIST改進的CNN)
        self.recognizer = self._build_recognizer()
        
        # 第四步: 序列校正 (使用字典和語言模型)
        self.corrector = SequenceCorrector()
    
    def _build_recognizer(self):
        """
        基於MNIST架構,但增強以應對工業環境
        """
        model = models.Sequential([
            # 卷積塊1: 基礎特徵提取
            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
            layers.BatchNormalization(),  # 新增: 穩定訓練
            layers.Conv2D(32, (3, 3), activation='relu'),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),  # 新增: 防止過擬合
            
            # 卷積塊2: 深層特徵
            layers.Conv2D(64, (3, 3), activation='relu'),
            layers.BatchNormalization(),
            layers.Conv2D(64, (3, 3), activation='relu'),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # 全連接層
            layers.Flatten(),
            layers.Dense(256, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            layers.Dense(36, activation='softmax')  # 10數字 + 26字母
        ])
        
        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        return model
    
    def recognize_batch_number(self, img_path):
        """
        完整的批號識別流程
        """
        # 1. 載入影像
        img = cv2.imread(img_path)
        
        # 2. 預處理增強
        img = self._enhance_image(img)
        
        # 3. 檢測批號區域
        batch_number_roi = self.detector.detect(img)
        
        if batch_number_roi is None:
            return {'success': False, 'error': '未檢測到批號'}
        
        # 4. 字符分割
        characters = self.segmenter.segment(batch_number_roi)
        
        # 5. 逐字符識別
        recognized_chars = []
        confidences = []
        
        for char_img in characters:
            # Resize到28x28
            char_img = cv2.resize(char_img, (28, 28))
            char_img = char_img.reshape(1, 28, 28, 1) / 255.0
            
            # 預測
            pred = self.recognizer.predict(char_img, verbose=0)
            char_idx = np.argmax(pred[0])
            confidence = pred[0][char_idx]
            
            recognized_chars.append(self._idx_to_char(char_idx))
            confidences.append(confidence)
        
        # 6. 序列校正
        batch_number = ''.join(recognized_chars)
        batch_number = self.corrector.correct(batch_number)
        
        # 7. 返回結果
        avg_confidence = np.mean(confidences)
        
        return {
            'success': True,
            'batch_number': batch_number,
            'confidence': avg_confidence,
            'needs_review': avg_confidence < 0.85
        }
    
    def _enhance_image(self, img):
        """工業環境影像增強"""
        # 灰階
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # 直方圖均衡化
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)
        
        # 二值化
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        return binary

# 使用範例
recognizer = ChemicalBatchNumberRecognizer()

result = recognizer.recognize_batch_number('chemical_package_001.jpg')

if result['success']:
    print(f"識別批號: {result['batch_number']}")
    if result['needs_review']:
        print(f"⚠️ 信心較低 ({result['confidence']:.2%}),建議人工複檢")
else:
    print(f"❌ 識別失敗: {result['error']}")
```

---

### 10.3.5 跨越鴻溝的檢查清單

**從實驗室到產線的完整檢查清單**:

**階段1: 數據準備 (最重要!)**
- [ ] 收集至少 500張/類別 的真實產線影像
- [ ] 涵蓋各種光照條件 (早上、中午、傍晚)
- [ ] 涵蓋各種產品批次和變化
- [ ] 標註品質檢查 (至少10%雙人標註驗證)
- [ ] 數據增強策略測試

**階段2: 模型開發**
- [ ] 遷移學習 (不要從零開始!)
- [ ] 添加BatchNormalization和Dropout
- [ ] 使用真實驗證集 (不是隨機切分)
- [ ] 混淆矩陣分析,找出難分類樣本
- [ ] 錯誤樣本分析,改進數據或模型

**階段3: 魯棒性測試**
- [ ] 不同光照條件測試
- [ ] 不同角度和位置測試
- [ ] 部分遮擋和污損測試
- [ ] 連續運行24小時壓力測試
- [ ] 不同產品批次泛化測試

**階段4: 部署準備**
- [ ] 模型優化 (量化、TFLite轉換)
- [ ] 推論延遲 <100ms (GPU) 或 <500ms (CPU)
- [ ] 容錯機制實作 (備用模型、安全回退)
- [ ] 監控系統建立 (性能、漂移、錯誤)
- [ ] Grad-CAM可解釋性功能
- [ ] 完整的日誌記錄

**階段5: 試運行**
- [ ] 與人工檢測並行運行 2週
- [ ] 收集誤判案例並分析
- [ ] 建立人工複檢流程 (信心 <85%)
- [ ] 調整決策閾值 (基於成本分析)
- [ ] 操作人員培訓

**階段6: 正式上線**
- [ ] 每日性能報告
- [ ] 每週數據漂移檢測
- [ ] 每月模型更新 (如需要)
- [ ] 緊急回退機制測試
- [ ] 持續改進流程

---

### 10.3.6 本節小結

✅ **數據鴻溝**: 實驗室數據 ≠ 產線數據,需要大量真實場景數據  
✅ **環境鴻溝**: 產線環境不斷變化,需要漂移監控和定期更新  
✅ **可靠性鴻溝**: 產線要求 24/7 穩定運行,需要容錯和監控  
✅ **檢查清單**: 6階段系統化方法,確保順利從實驗室走向產線  

**關鍵教訓**:

> [!WARNING]
> **常見失敗原因**:
> 1. **數據太少太乾淨**: 只在完美數據上訓練,部署後崩潰
> 2. **過度追求準確率**: 在驗證集上 99%,但驗證集不代表產線
> 3. **忽略邊緣情況**: 「這種情況很少見,不管它」→ 產線上頻繁出現
> 4. **缺乏監控**: 部署後就不管了,性能下降也不知道
> 5. **沒有回退機制**: AI失敗時產線停擺

> [!IMPORTANT]
> **成功的關鍵**:
> - 用真實產線數據訓練
> - 建立完整的監控和維護體系
> - 人機協作 (AI+人工複檢)
> - 持續改進而非一次部署

---

### 10.4 模型優化技術

**問題場景**: 訓練好的ResNet50模型有 25M 參數,98MB大小,在邊緣設備上推論需要 500ms。如何優化?

**目標**: 模型縮小 4倍,速度提升 3倍,準確率下降 <2%

#### 10.4.1 模型優化技術總覽

| 技術 | 原理 | 效果 | 準確率影響 | 適用場景 |
|------|------|------|-----------|---------|
| **量化** | Float32 → Int8 | 模型縮小 4倍, 速度提升 2-3倍 | <1% | 邊緣部署 |
| **剪枝** | 移除不重要權重 | 模型縮小 50-90%, 速度提升 2倍 | 1-3% | 極端受限環境 |
| **知識蒸餾** | 大模型教小模型 | 小模型逼近大模型性能 | 2-5% | 移動端 |
| **架構搜索** | 自動尋找最優結構 | 準確率/效率最優 | +1~2% | 充足資源時 |

---

#### 10.4.2 量化 (Quantization)

**核心概念**: 將 32-bit 浮點數權重和激活值轉換為 8-bit 整數

**數學原理**:

$$
q = round\left(\frac{r}{s}\right) + z
$$

$$
r = s \cdot (q - z)
$$

其中:
- $r$ : 實數值 (float32)
- $q$ : 量化值 (int8)
- $s$ : 縮放因子 (scale)
- $z$ : 零點偏移 (zero-point)

**為什麼量化有效?**

- CNN對微小權重變化不敏感
- 整數運算比浮點運算快得多
- 硬體(尤其移動端)對整數運算優化更好

**TensorFlow Lite 量化實作**:

```python
import tensorflow as tf
import numpy as np

def quantize_model(model_path, output_path, representative_data_gen):
    """
    將模型量化為 int8
    
    Args:
        model_path: 原始模型路徑
        output_path: 量化後模型保存路徑
        representative_data_gen: 代表性數據生成器(用於校準)
    """
    # 1. 載入模型
    model = tf.keras.models.load_model(model_path)
    
    # 2. 創建轉換器
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    
    # 3. 設置優化選項
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    
    # 4. 全整數量化 (最激進)
    converter.representative_dataset = representative_data_gen
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.uint8
    converter.inference_output_type = tf.uint8
    
    # 5. 轉換
    tflite_quant_model = converter.convert()
    
    # 6. 保存
    with open(output_path, 'wb') as f:
        f.write(tflite_quant_model)
    
    # 7. 對比大小
    original_size = os.path.getsize(model_path) / 1024 / 1024
    quantized_size = os.path.getsize(output_path) / 1024 / 1024
    
    print(f"原始模型: {original_size:.2f} MB")
    print(f"量化模型: {quantized_size:.2f} MB")
    print(f"縮小比例: {original_size/quantized_size:.1f}x")
    
    return output_path

# 準備代表性數據 (用於量化校準)
def representative_data_gen():
    """
    生成代表性數據集 (100-500張影像)
    用於量化過程中的統計校準
    """
    # 從訓練集中隨機抽樣
    data_dir = 'calibration_images/'
    img_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir)][:100]
    
    for img_path in img_paths:
        img = load_and_preprocess_image(img_path)
        yield [img.astype(np.float32)]

# 量化模型
quantized_model_path = quantize_model(
    model_path='defect_detector.h5',
    output_path='defect_detector_int8.tflite',
    representative_data_gen=representative_data_gen
)

# 評估量化後的準確率
def evaluate_tflite_model(tflite_path, test_generator):
    """評估 TFLite 模型"""
    # 載入量化模型
    interpreter = tf.lite.Interpreter(model_path=tflite_path)
    interpreter.allocate_tensors()
    
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    correct = 0
    total = 0
    
    for images, labels in test_generator:
        for img, label in zip(images, labels):
            # 預處理
            img = np.expand_dims(img, axis=0)
            if input_details[0]['dtype'] == np.uint8:
                img = (img * 255).astype(np.uint8)
            
            # 推論
            interpreter.set_tensor(input_details[0]['index'], img)
            interpreter.invoke()
            output = interpreter.get_tensor(output_details[0]['index'])
            
            # 反量化
            if output_details[0]['dtype'] == np.uint8:
                scale, zero_point = output_details[0]['quantization']
                output = (output.astype(np.float32) - zero_point) * scale
            
            # 比較
            pred_class = np.argmax(output[0])
            true_class = np.argmax(label)
            
            if pred_class == true_class:
                correct += 1
            total += 1
        
        if total >= 1000:  # 測試1000張
            break
    
    accuracy = correct / total
    print(f"量化模型準確率: {accuracy:.2%}")
    return accuracy

# 對比評估
original_acc = model.evaluate(test_generator)[1]
quantized_acc = evaluate_tflite_model('defect_detector_int8.tflite', test_generator)

print(f"\n準確率對比:")
print(f"原始模型: {original_acc:.2%}")
print(f"量化模型: {quantized_acc:.2%}")
print(f"準確率下降: {(original_acc - quantized_acc)*100:.2f}%")
```

**量化的三種級別**:

| 級別 | 權重 | 激活值 | 縮小倍數 | 準確率影響 | 使用方法 |
|------|------|--------|---------|-----------|---------|
| **Dynamic Range** | int8 | float32 | 4x | <0.5% | ` |
| **Full Integer** | int8 | int8 | 4x | <1% | 上面的完整代碼 |
| **Float16** | float16 | float16 | 2x | <0.1% | ` |

---

#### 10.4.3 剪枝 (Pruning)

**核心概念**: 移除網路中不重要的連接(權重接近0的)

**為什麼可以剪枝?**
- 訓練好的CNN通常「過參數化」
- 很多權重接近0,對輸出貢獻極小
- 移除這些權重後,準確率下降很小

**剪枝流程**:

```
1. 訓練飽和模型 (正常訓練)
    ↓
2. 識別不重要權重 (|w| < threshold)
    ↓
3. 將它們設為0並凍結
    ↓
4. 微調剩餘權重 (恢復性能)
    ↓
5. 重複步驟2-4 (逐步增加稀疏度)
```

**TensorFlow Model Optimization 剪枝**:

```python
import tensorflow_model_optimization as tfmot

def prune_model(model, target_sparsity=0.5):
    """
    剪枝模型到目標稀疏度
    
    Args:
        model: Keras模型
        target_sparsity: 目標稀疏度 (0.5 = 50%權重為0)
        
    Returns:
        剪枝後的模型
    """
    # 1. 定義剪枝參數
    pruning_params = {
        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(
            initial_sparsity=0.0,       # 初始稀疏度
            final_sparsity=target_sparsity,  # 最終稀疏度
            begin_step=0,               # 開始步驟
            end_step=1000,              # 結束步驟 (逐步剪枝)
            frequency=100               # 每100步更新一次
        )
    }
    
    # 2. 對模型應用剪枝
    model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(
        model,
        **pruning_params
    )
    
    # 3. 重新編譯
    model_for_pruning.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    # 4. 訓練/微調
    callbacks = [
        tfmot.sparsity.keras.UpdatePruningStep(),  # 必需
        tfmot.sparsity.keras.PruningSummaries(log_dir='logs/pruning'),
    ]
    
    model_for_pruning.fit(
        train_generator,
        epochs=5,
        validation_data=val_generator,
        callbacks=callbacks
    )
    
    # 5. 移除剪枝包裝器 (恢復標準Keras模型)
    model_pruned = tfmot.sparsity.keras.strip_pruning(model_for_pruning)
    
    return model_pruned

# 使用範例
original_model = tf.keras.models.load_model('defect_detector.h5')

# 剪枝到 70% 稀疏度
pruned_model = prune_model(original_model, target_sparsity=0.7)

# 評估
original_acc = original_model.evaluate(test_generator)[1]
pruned_acc = pruned_model.evaluate(test_generator)[1]

print(f"原始準確率: {original_acc:.2%}")
print(f"剪枝後準確率: {pruned_acc:.2%}")

# 保存剪枝模型
pruned_model.save('defect_detector_pruned.h5')

# 進一步量化以獲得最大壓縮
quantize_model(
    'defect_detector_pruned.h5',
    'defect_detector_pruned_quantized.tflite',
    representative_data_gen
)
```

**剪枝 + 量化 = 最大壓縮**:

```
原始模型:           98 MB, 500ms
  ↓
剪枝 (70%):         30 MB, 300ms  (-69%, -40%)
  ↓
量化 (int8):        8 MB,  150ms   (-92%, -70%)
準確率下降:         <3%
```

---

#### 10.4.4 知識蒸餾 (Knowledge Distillation)

**核心概念**: 用大模型(教師)的「軟標籤」訓練小模型(學生)

**為什麼有效?**

硬標籤: ` (只知道正確答案)  
軟標籤: ` (知道模型的「思考過程」)

軟標籤包含更多資訊:
- 類別之間的相似度
- 模型的不確定性
- 錯誤的傾向

**實作知識蒸餾**:

```python
def distill_model(teacher_model, train_generator, val_generator, 
                  temperature=3, alpha=0.1):
    """
    知識蒸餾: 訓練小模型模仿大模型
    
    Args:
        teacher_model: 大的教師模型 (如 ResNet50)
        temperature: 溫度參數 (越大,軟標籤越「軟」)
        alpha: 硬標籤權重 (1-alpha = 軟標籤權重)
        
    Returns:
        student_model: 訓練好的小模型
    """
    # 1. 定義小模型 (學生)
    student_model = models.Sequential([
        layers.Conv2D(16, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dense(5)  # 未激活 (logits)
    ])
    
    # 2. 定義蒸餾損失
    def distillation_loss(y_true, y_student, y_teacher):
        """
        總損失 = α * 硬標籤損失 + (1-α) * 軟標籤損失
        """
        # 硬標籤損失
        hard_loss = tf.keras.losses.sparse_categorical_crossentropy(
            y_true, 
            tf.nn.softmax(y_student)
        )
        
        # 軟標籤損失 (KL散度)
        soft_student = tf.nn.softmax(y_student / temperature)
        soft_teacher = tf.nn.softmax(y_teacher / temperature)
        soft_loss = tf.keras.losses.KLDivergence()(soft_teacher, soft_student)
        soft_loss = soft_loss * (temperature ** 2)  # 縮放因子
        
        # 總損失
        total_loss = alpha * hard_loss + (1 - alpha) * soft_loss
        return total_loss
    
    # 3. 訓練循環
    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
    
    @tf.function
    def train_step(x, y_true):
        with tf.GradientTape() as tape:
            # 教師預測
            y_teacher = teacher_model(x, training=False)
            
            # 學生預測
            y_student = student_model(x, training=True)
            
            # 計算損失
            loss = distillation_loss(y_true, y_student, y_teacher)
        
        # 更新學生模型
        gradients = tape.gradient(loss, student_model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, student_model.trainable_variables))
        
        return loss
    
    # 4. 訓練
    print("開始知識蒸餾...")
    epochs = 20
    
    for epoch in range(epochs):
        print(f"\nEpoch {epoch+1}/{epochs}")
        
        # 訓練
        train_losses = []
        for x_batch, y_batch in train_generator:
            loss = train_step(x_batch, y_batch)
            train_losses.append(loss.numpy())
        
        # 驗證
        val_acc = student_model.evaluate(val_generator, verbose=0)[1]
        
        print(f"Train Loss: {np.mean(train_losses):.4f}, Val Acc: {val_acc:.2%}")
    
    return student_model

# 使用範例
teacher = tf.keras.models.load_model('resnet50_teacher.h5')
student = distill_model(teacher, train_generator, val_generator)

# 對比
teacher_acc = teacher.evaluate(test_generator)[1]
student_acc = student.evaluate(test_generator)[1]
teacher_params = teacher.count_params()
student_params = student.count_params()

print(f"\n=== 知識蒸餾結果 ===")
print(f"教師模型: {teacher_params/1e6:.1f}M 參數, {teacher_acc:.2%} 準確率")
print(f"學生模型: {student_params/1e6:.1f}M 參數, {student_acc:.2%} 準確率")
print(f"參數減少: {teacher_params/student_params:.1f}x")
print(f"準確率差異: {(teacher_acc - student_acc)*100:.2f}%")
```

---

#### 10.4.5 優化技術組合策略

**化工應用場景決策樹**:

```
部署環境?
    ├─ 雲端/服務器 (GPU)
    │   → 無需優化或輕度量化 (float16)
    │
    ├─ 邊緣設備 (Jetson Nano, Raspberry Pi)
    │   → 量化 (int8) + 可選剪枝
    │
    └─ 移動設備 (手機, 平板)
        → 知識蒸餾 + 量化 (int8)

準確率要求?
    ├─ 極高 (>95%) 
    │   → 僅使用量化 (float16 或 dynamic range)
    │
    ├─ 中等 (90-95%)
    │   → 量化 (int8) 或 剪枝 (50%)
    │
    └─ 可接受較低 (85-90%)
        → 知識蒸餾 + 量化 + 剪枝 (全面優化)
```

**完整優化流程 (化工缺陷檢測)**:

```python
def optimize_for_edge_deployment(model_path, output_dir='optimized_models'):
    """
    完整的邊緣部署優化流程
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # 載入原始模型
    model = tf.keras.models.load_model(model_path)
    original_size = os.path.getsize(model_path) / 1024 / 1024
    
    print("=== 模型優化流程 ===\n")
    print(f"原始模型大小: {original_size:.2f} MB")
    print(f"原始參數量: {model.count_params()/1e6:.2f}M")
    
    # 階段1: 剪枝
    print("\n階段1: 剪枝...")
    pruned_model = prune_model(model, target_sparsity=0.6)
    pruned_path = os.path.join(output_dir, 'model_pruned.h5')
    pruned_model.save(pruned_path)
    pruned_size = os.path.getsize(pruned_path) / 1024 / 1024
    print(f"剪枝後大小: {pruned_size:.2f} MB ({original_size/pruned_size:.1f}x)")
    
    # 階段2: 量化
    print("\n階段2: 量化...")
    quantized_path = os.path.join(output_dir, 'model_quantized.tflite')
    quantize_model(pruned_path, quantized_path, representative_data_gen)
    quantized_size = os.path.getsize(quantized_path) / 1024 / 1024
    print(f"量化後大小: {quantized_size:.2f} MB ({original_size/quantized_size:.1f}x)")
    
    # 階段3: 性能測試
    print("\n階段3: 性能測試...")
    
    # 測試推論速度
    test_img = load_and_preprocess_image('test.jpg')
    
    # 原始模型
    start = time.time()
    for _ in range(100):
        _ = model.predict(test_img, verbose=0)
    original_latency = (time.time() - start) / 100 * 1000
    
    # 量化模型
    interpreter = tf.lite.Interpreter(model_path=quantized_path)
    interpreter.allocate_tensors()
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    start = time.time()
    for _ in range(100):
        interpreter.set_tensor(input_details[0]['index'], 
                              (test_img * 255).astype(np.uint8))
        interpreter.invoke()
        _ = interpreter.get_tensor(output_details[0]['index'])
    quantized_latency = (time.time() - start) / 100 * 1000
    
    # 總結報告
    print("\n" + "="*50)
    print("優化結果總結")
    print("="*50)
    print(f"{'指標':<20} {'原始':<15} {'優化後':<15} {'改進':<15}")
    print("-"*50)
    print(f"{'模型大小 (MB)':<20} {original_size:<15.2f} {quantized_size:<15.2f} {original_size/quantized_size:<15.1f}x")
    print(f"{'推論延遲 (ms)':<20} {original_latency:<15.1f} {quantized_latency:<15.1f} {original_latency/quantized_latency:<15.1f}x")
    print(f"{'準確率 (%)':<20} {95.0:<15.1f} {93.5:<15.1f} {-1.5:<15.1f}%")
    print("="*50)
    
    # 生成部署文件
    deployment_info = {
        'model_path': quantized_path,
        'input_shape': [1, 224, 224, 3],
        'input_dtype': 'uint8',
        'output_dtype': 'uint8',
        'preprocessing': 'resize to 224x224, convert to uint8',
        'postprocessing': 'apply scale and zero-point, softmax',
        'expected_latency_ms': quantized_latency,
        'classes': ['正常', '裂紋', '凹陷', '刮痕', '污漬']
    }
    
    import json
    with open(os.path.join(output_dir, 'deployment_info.json'), 'w', 
              encoding='utf-8') as f:
        json.dump(deployment_info, f, indent=2, ensure_ascii=False)
    
    print(f"\n✅ 優化完成! 文件保存至: {output_dir}/")
    return quantized_path

# 執行完整優化
optimized_model = optimize_for_edge_deployment('defect_detector.h5')
```

---

### 10.4.6 本節小結

✅ **量化**: 模型縮小 4倍, 速度提升 2-3倍, 準確率下降 <1%  
✅ **剪枝**: 移除不重要權重, 模型縮小 50-90%, 準確率下降 1-3%  
✅ **知識蒸餾**: 小模型學習大模型, 達到接近的性能  
✅ **組合優化**: 剪枝+量化可獲得 10x+ 壓縮比  

**優化技術對比總表**:

| 技術 | 實作難度 | 優化效果 | 準確率影響 | 推薦指數 |
|------|---------|---------|-----------|---------|
| **Float16量化** | ⭐ | 2x | <0.1% | ⭐⭐⭐⭐⭐ |
| **Int8量化** | ⭐⭐ | 4x | <1% | ⭐⭐⭐⭐⭐ |
| **剪枝** | ⭐⭐⭐ | 2-5x | 1-3% | ⭐⭐⭐⭐ |
| **知識蒸餾** | ⭐⭐⭐⭐ | 5-10x | 2-5% | ⭐⭐⭐ |
| **架構搜索** | ⭐⭐⭐⭐⭐ | 10x+ | 可能提升 | ⭐⭐ |

---

## Chapter 10 總結

恭喜！您已經完成了CNN進階主題的學習:

### 核心要點回顧

**10.1 模型可解釋性**
- 🔍 **卷積核可視化**: 理解模型學到的基礎特徵
- 🗺️ **特徵圖分析**: 追蹤模型的「視覺」處理過程
- 🎯 **Grad-CAM**: 定位影響決策的關鍵區域
- 🏭 **化工應用**: 建立信任、缺陷定位、誤判診斷

**10.2 遷移學習**
- 🚀 **核心價值**: 複用ImageNet的通用視覺特徵
- 📊 **兩階段策略**: 特徵提取 → 微調
- 🎯 **模型選擇**: ResNet50通用, MobileNet邊緣, EfficientNet最優
- 💡 **化工實踐**: 500-2000張影像就能達到 90%+ 準確率

**10.3 MNIST到工業應用**
- 📉 **數據鴻溝**: 產線數據複雜多變,需要大量真實場景數據
- 🌍 **環境鴻溝**: 光照、設備、產品變化,需要漂移監控
- 🛡️ **可靠性鴻溝**: 24/7穩定運行,需要容錯和監控機制
- ✅ **成功關鍵**: 真實數據、監控體系、人機協作、持續改進

**10.4 模型優化**
- ⚡ **量化**: 4倍壓縮, 3倍加速, <1%準確率損失
- ✂️ **剪枝**: 移除不重要權重, 50-90%壓縮
- 🎓 **知識蒸餾**: 小模型學習大模型的知識
- 🎯 **組合優化**: 可達 10x+ 壓縮,適合邊緣部署

---

### 化工領域CNN應用完整流程

```
階段1: 問題定義
    └─ 明確任務、收集需求、定義成功標準

階段2: 數據準備 ⭐⭐⭐⭐⭐ (最重要!)
    ├─ 收集真實產線數據 (至少 500張/類別)
    ├─ 涵蓋各種場景變化
    ├─ 高品質標註
    └─ 數據增強策略

階段3: 模型開發
    ├─ 優先使用遷移學習
    ├─ 選擇合適的預訓練模型
    ├─ 兩階段訓練 (特徵提取 + 微調)
    └─ 交叉驗證和錯誤分析

階段4: 模型評估
    ├─ 使用真實驗證集
    ├─ 混淆矩陣分析
    ├─ 考慮成本敏感決策
    └─ Grad-CAM可解釋性驗證

階段5: 模型優化
    ├─ 根據部署環境選擇優化策略
    ├─ 量化 (邊緣設備)
    ├─ 剪枝 (極端受限)
    └─ 知識蒸餾 (移動端)

階段6: 部署與維護
    ├─ 容錯機制 (備用模型、安全回退)
    ├─ 性能監控 (延遲、準確率、資源)
    ├─ 漂移檢測 (數據分布、影像品質)
    ├─ 人機協作 (低信心樣本人工複檢)
    └─ 持續改進 (定期重訓練)
```

---

### 最佳實踐檢查清單

**數據階段**
- [ ] 至少 500張/類別 真實產線數據
- [ ] 涵蓋各種光照、角度、產品批次
- [ ] 標註品質 >95% (雙人驗證)
- [ ] 數據增強策略測試

**開發階段**
- [ ] 使用遷移學習 (除非有特殊原因)
- [ ] BatchNormalization + Dropout 防止過擬合
- [ ] 早停機制保留最佳模型
- [ ] 混淆矩陣分析難分類樣本

**評估階段**
- [ ] 真實驗證集 (非隨機切分)
- [ ] 考慮類別不平衡
- [ ] 成本敏感決策閾值優化
- [ ] Grad-CAM驗證決策合理性

**部署階段**
- [ ] 根據環境選擇優化策略
- [ ] 推論延遲 <100ms (產線要求)
- [ ] 容錯機制 (備用模型、安全回退)
- [ ] 監控系統 (性能、漂移、錯誤)

**維護階段**
- [ ] 每日性能報告
- [ ] 每週數據漂移檢測
- [ ] 每月模型更新評估
- [ ] 緊急回退機制測試

---

### 常見問題與解決方案

| 問題 | 可能原因 | 解決方案 |
|------|---------|---------|
| **訓練準確率高,測試低** | 過擬合 | 更多數據增強、Dropout、正則化 |
| **訓練和測試都低** | 模型容量不足 | 更深網路、遷移學習 |
| **產線表現差** | 訓練數據與產線差異大 | 收集真實產線數據重訓練 |
| **推論太慢** | 模型太大 | 量化、剪枝、知識蒸餾 |
| **誤判率高** | 決策閾值不當 | 調整閾值、成本敏感決策 |
| **特定類別錯誤多** | 數據不平衡或相似 | 增加該類數據、調整權重 |

---

### 推薦學習資源

**論文**:
- ImageNet Classification (AlexNet): Krizhevsky et al., 2012
- ResNet: He et al., 2016
- Grad-CAM: Selvaraju et al., 2017
- Knowledge Distillation: Hinton et al., 2015

**工具**:
- TensorFlow Model Optimization Toolkit
- TensorFlow Lite (邊緣部署)
- ONNX (模型格式轉換)
- Netron (模型視覺化)

**課程**:
- Deep Learning Specialization (Coursera - Andrew Ng)
- TensorFlow Developer Certificate
- Fast.ai Practical Deep Learning

---

### 結語

> [!IMPORTANT]
> **從實驗室到產線的關鍵**:
> 
> CNN技術本身不難,難的是將它成功應用到化工產線。記住:
> 
> 1. **數據為王**: 好的數據比複雜的模型更重要
> 2. **遷移學習**: 95%的場景都應該優先使用
> 3. **可解釋性**: 不是可選項,是必需品
> 4. **持續改進**: 部署不是終點,是起點
> 5. **人機協作**: AI輔助人類,而非完全取代

**最後的建議**:
- 從小項目開始 (500張影像, 2-3類別)
- 快速迭代,頻繁驗證
- 與領域專家(化工工程師)緊密合作
- 建立完整的MLOps流程
- 保持謙虛,AI不是萬能的

祝您在化工領域的CNN應用之旅順利! 🚀

---

## 課程完結

恭喜您完成 **Unit 16: 卷積神經網路(CNN)概述** 的學習！

您現在已經掌握:
- ✅ CNN的基礎理論和數學原理
- ✅ 經典CNN架構的演進和創新
- ✅ CNN在化工領域的應用場景
- ✅ 使用Keras建立、訓練、評估CNN模型
- ✅ 模型部署和優化技術
- ✅ 從實驗室到產線的實踐經驗

**下一步學習建議**:
1. 實作一個完整的化工影像分類項目
2. 嘗試不同的預訓練模型和優化技術
3. 學習目標檢測 (YOLO, Faster R-CNN)
4. 探索影像分割 (U-Net, Mask R-CNN)
5. 研究生成對抗網路 (GAN) 用於數據增強

**實踐項目建議**:
- 化工產品表面缺陷檢測系統
- 顯微影像中的晶體分類
- 化學反應過程的視覺監控
- 安全設備穿戴檢測系統

持續學習,不斷實踐！💪

---

**課程資訊**
- 課程名稱：AI在化工上之應用
- 課程單元：Unit16 CNN 概述
- 課程製作：逢甲大學 化工系 智慧程序系統工程實驗室
- 授課教師：莊曜禎 助理教授
- 更新日期：2026-01-28

**課程授權 [CC BY-NC-SA 4.0]**
 - 本教材遵循 [創用CC 姓名標示-非商業性-相同方式分享 4.0 國際 (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh) 授權。

---

