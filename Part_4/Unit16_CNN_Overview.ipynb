{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unit 16: CNN 卷積神經網路實作演練\n",
                "## 使用 MNIST 手寫數字辨識資料集\n",
                "\n",
                "---\n",
                "\n",
                "## 學習目標\n",
                "- 學習如何載入和預處理 MNIST 資料集\n",
                "- 學習如何使用 Keras 建立 CNN 模型\n",
                "- 學習如何訓練、評估和使用 CNN 模型進行預測\n",
                "- 學習如何視覺化訓練過程和預測結果\n",
                "- 學習如何保存和載入訓練好的模型\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 導入必要的套件"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 基本套件\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# TensorFlow 和 Keras\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers, models\n",
                "from tensorflow.keras.datasets import mnist\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "\n",
                "# Callbacks\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
                "\n",
                "# 評估指標\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "\n",
                "# 其他工具\n",
                "import datetime\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# 設定隨機種子以確保結果可重現\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "# 顯示 TensorFlow 版本\n",
                "print(f'TensorFlow 版本: {tf.__version__}')\n",
                "print(f'Keras 版本: {keras.__version__}')\n",
                "\n",
                "# 檢查 GPU 是否可用\n",
                "print(f'\\nGPU 是否可用: {tf.config.list_physical_devices(\"GPU\")}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 載入 MNIST 資料集\n",
                "\n",
                "MNIST 資料集包含 70,000 張手寫數字影像 (0-9):\n",
                "- 訓練集: 60,000 張\n",
                "- 測試集: 10,000 張\n",
                "- 影像尺寸: 28×28 像素\n",
                "- 灰階影像: 像素值範圍 0-255"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 載入 MNIST 資料集\n",
                "print(\"正在載入 MNIST 資料集...\")\n",
                "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
                "\n",
                "print(\"\\n資料集載入完成!\")\n",
                "print(f\"訓練集影像形狀: {x_train.shape}\")\n",
                "print(f\"訓練集Label形狀: {y_train.shape}\")\n",
                "print(f\"測試集影像形狀: {x_test.shape}\")\n",
                "print(f\"測試集Label形狀: {y_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 資料探索與視覺化"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 查看資料基本統計資訊\n",
                "print(\"訓練集影像統計資訊:\")\n",
                "print(f\"最小值: {x_train.min()}\")\n",
                "print(f\"最大值: {x_train.max()}\")\n",
                "print(f\"平均值: {x_train.mean():.2f}\")\n",
                "print(f\"標準差: {x_train.std():.2f}\")\n",
                "\n",
                "# 查看Label分布\n",
                "print(\"\\nTraining Set Label Distribution:\")\n",
                "unique, counts = np.unique(y_train, return_counts=True)\n",
                "for digit, count in zip(unique, counts):\n",
                "    print(f\"Digit {digit}: {count} 張 ({count/len(y_train)*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 視覺化Label分布\n",
                "plt.figure(figsize=(10, 5))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.bar(unique, counts, color='steelblue', alpha=0.7)\n",
                "plt.xlabel('Digit', fontsize=12)\n",
                "plt.ylabel('Count', fontsize=12)\n",
                "plt.title('Training Set Label Distribution', fontsize=14, fontweight='bold')\n",
                "plt.xticks(unique)\n",
                "plt.grid(axis='y', alpha=0.3)\n",
                "\n",
                "# Test Set Label Distribution\n",
                "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.bar(unique_test, counts_test, color='coral', alpha=0.7)\n",
                "plt.xlabel('Digit', fontsize=12)\n",
                "plt.ylabel('Count', fontsize=12)\n",
                "plt.title('Test Set Label Distribution', fontsize=14, fontweight='bold')\n",
                "plt.xticks(unique_test)\n",
                "plt.grid(axis='y', alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 視覺化部分訓練樣本\n",
                "plt.figure(figsize=(12, 8))\n",
                "for i in range(25):\n",
                "    plt.subplot(5, 5, i + 1)\n",
                "    plt.imshow(x_train[i], cmap='gray')\n",
                "    plt.title(f'Label: {y_train[i]}', fontsize=10)\n",
                "    plt.axis('off')\n",
                "\n",
                "plt.suptitle('MNIST Training Samples (First 25)', fontsize=16, fontweight='bold', y=1.00)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 視覺化單一影像的Pixel Value分布\n",
                "sample_idx = 0\n",
                "sample_image = x_train[sample_idx]\n",
                "sample_label = y_train[sample_idx]\n",
                "\n",
                "plt.figure(figsize=(14, 4))\n",
                "\n",
                "# 顯示影像\n",
                "plt.subplot(1, 3, 1)\n",
                "plt.imshow(sample_image, cmap='gray')\n",
                "plt.title(f'影像 (Label: {sample_label})', fontsize=12, fontweight='bold')\n",
                "plt.axis('off')\n",
                "\n",
                "# 顯示Pixel Value Heatmap\n",
                "plt.subplot(1, 3, 2)\n",
                "sns.heatmap(sample_image, cmap='gray', cbar=True, square=True)\n",
                "plt.title('Pixel Value Heatmap', fontsize=12, fontweight='bold')\n",
                "\n",
                "# 顯示Pixel Value分布直方圖\n",
                "plt.subplot(1, 3, 3)\n",
                "plt.hist(sample_image.flatten(), bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
                "plt.xlabel('Pixel Value', fontsize=11)\n",
                "plt.ylabel('Frequency', fontsize=11)\n",
                "plt.title('Pixel Value分布', fontsize=12, fontweight='bold')\n",
                "plt.grid(axis='y', alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 資料預處理\n",
                "\n",
                "### 4.1 正規化 (Normalization)\n",
                "將像素值從 [0, 255] 縮放到 [0, 1],有助於模型訓練。\n",
                "\n",
                "### 4.2 重塑 (Reshape)\n",
                "CNN 需要 4D 輸入: (樣本數, 高度, 寬度, 通道數)\n",
                "- MNIST 是灰階影像,通道數為 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 正規化: 將Pixel Value縮放到 [0, 1]\n",
                "x_train_normalized = x_train.astype('float32') / 255.0\n",
                "x_test_normalized = x_test.astype('float32') / 255.0\n",
                "\n",
                "print(\"正規化後的統計資訊:\")\n",
                "print(f\"訓練集 - 最小值: {x_train_normalized.min()}, 最大值: {x_train_normalized.max()}\")\n",
                "print(f\"測試集 - 最小值: {x_test_normalized.min()}, 最大值: {x_test_normalized.max()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 重塑: 添加通道維度\n",
                "x_train_reshaped = x_train_normalized.reshape(-1, 28, 28, 1)\n",
                "x_test_reshaped = x_test_normalized.reshape(-1, 28, 28, 1)\n",
                "\n",
                "print(\"重塑後的形狀:\")\n",
                "print(f\"訓練集: {x_train_reshaped.shape}\")\n",
                "print(f\"測試集: {x_test_reshaped.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 查看Label的唯一值\n",
                "print(f\"\\nLabel的唯一值: {np.unique(y_train)}\")\n",
                "print(f\"類別Count: {len(np.unique(y_train))}\")\n",
                "\n",
                "# 注意: 我們使用 sparse_categorical_crossentropy,所以不需要 one-hot 編碼\n",
                "# 如果使用 categorical_crossentropy,則需要進行 one-hot 編碼:\n",
                "# y_train_onehot = to_categorical(y_train, num_classes=10)\n",
                "# y_test_onehot = to_categorical(y_test, num_classes=10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 建立 CNN 模型\n",
                "\n",
                "### 模型架構:\n",
                "1. **卷積塊 1**: Conv2D(32) → MaxPooling2D\n",
                "2. **卷積塊 2**: Conv2D(64) → MaxPooling2D\n",
                "3. **卷積塊 3**: Conv2D(64)\n",
                "4. **全連接層**: Flatten → Dense(64) → Dropout(0.5) → Dense(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 使用 Sequential API 建立模型\n",
                "def create_cnn_model():\n",
                "    \"\"\"\n",
                "    建立 CNN 模型\n",
                "    \"\"\"\n",
                "    model = models.Sequential([\n",
                "        # 第一個卷積塊\n",
                "        layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', \n",
                "                      input_shape=(28, 28, 1), padding='same', name='conv1'),\n",
                "        layers.MaxPooling2D(pool_size=(2, 2), name='pool1'),\n",
                "        \n",
                "        # 第二個卷積塊\n",
                "        layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', \n",
                "                      padding='same', name='conv2'),\n",
                "        layers.MaxPooling2D(pool_size=(2, 2), name='pool2'),\n",
                "        \n",
                "        # 第三個卷積塊\n",
                "        layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', \n",
                "                      padding='same', name='conv3'),\n",
                "        \n",
                "        # 展平層\n",
                "        layers.Flatten(name='flatten'),\n",
                "        \n",
                "        # 全連接層\n",
                "        layers.Dense(units=64, activation='relu', name='dense1'),\n",
                "        layers.Dropout(rate=0.5, name='dropout'),\n",
                "        \n",
                "        # 輸出層 (10 個類別)\n",
                "        layers.Dense(units=10, activation='softmax', name='output')\n",
                "    ], name='MNIST_CNN')\n",
                "    \n",
                "    return model\n",
                "\n",
                "# 建立模型\n",
                "model = create_cnn_model()\n",
                "print(\"CNN 模型建立完成!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 查看模型結構\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 模型參數計算說明:\n",
                "\n",
                "**Conv2D 層的參數數量計算:**\n",
                "- 公式: `參數數量 = (kernel_height × kernel_width × input_channels + 1) × filters`\n",
                "- `+1` 是偏差項 (bias)\n",
                "\n",
                "**範例 - conv1 層:**\n",
                "- kernel_size = (3, 3)\n",
                "- input_channels = 1 (灰階影像)\n",
                "- filters = 32\n",
                "- 參數數量 = (3 × 3 × 1 + 1) × 32 = 10 × 32 = 320\n",
                "\n",
                "**Dense 層的參數數量計算:**\n",
                "- 公式: `參數數量 = (input_units + 1) × output_units`\n",
                "\n",
                "**範例 - dense1 層:**\n",
                "- input_units = 3136 (來自 Flatten 層)\n",
                "- output_units = 64\n",
                "- 參數數量 = (3136 + 1) × 64 = 200,768"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. 編譯模型\n",
                "\n",
                "### 編譯參數說明:\n",
                "- **optimizer**: Adam (自適應學習率優化器)\n",
                "- **loss**: sparse_categorical_crossentropy (多類別分類,標籤為整數)\n",
                "- **metrics**: accuracy (準確率)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 編譯模型\n",
                "model.compile(\n",
                "    optimizer='adam',\n",
                "    loss='sparse_categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "print(\"模型編譯完成!\")\n",
                "print(f\"優化器: Adam\")\n",
                "print(f\"損失函數: Sparse Categorical Crossentropy\")\n",
                "print(f\"評估指標: Accuracy\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. 設定 Callbacks\n",
                "\n",
                "### Callbacks 說明:\n",
                "1. **EarlyStopping**: 當驗證損失不再改善時,提前停止訓練\n",
                "2. **ModelCheckpoint**: 保存訓練過程中的最佳模型\n",
                "3. **ReduceLROnPlateau**: 當驗證損失停止改善時,降低學習率"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 設定 Callbacks\n",
                "callbacks_list = [\n",
                "    # Early Stopping: 當Validation Loss連續 5 個 epochs 沒有改善時停止訓練\n",
                "    EarlyStopping(\n",
                "        monitor='val_loss',\n",
                "        patience=5,\n",
                "        restore_best_weights=True,\n",
                "        verbose=1\n",
                "    ),\n",
                "    \n",
                "    # Model Checkpoint: 保存最佳模型\n",
                "    ModelCheckpoint(\n",
                "        filepath='best_mnist_cnn_model.h5',\n",
                "        monitor='val_accuracy',\n",
                "        save_best_only=True,\n",
                "        verbose=1\n",
                "    ),\n",
                "    \n",
                "    # Reduce Learning Rate: 當Validation Loss連續 3 個 epochs 沒有改善時,將學習率降低為原來的 0.5 倍\n",
                "    ReduceLROnPlateau(\n",
                "        monitor='val_loss',\n",
                "        factor=0.5,\n",
                "        patience=3,\n",
                "        min_lr=1e-7,\n",
                "        verbose=1\n",
                "    )\n",
                "]\n",
                "\n",
                "print(\"Callbacks 設定完成!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. 訓練模型\n",
                "\n",
                "### 訓練參數:\n",
                "- **epochs**: 20 (最大訓練輪數)\n",
                "- **batch_size**: 128\n",
                "- **validation_split**: 0.2 (從訓練集中分出 20% 作為驗證集)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 訓練模型\n",
                "print(\"開始訓練模型...\\n\")\n",
                "\n",
                "history = model.fit(\n",
                "    x_train_reshaped, y_train,\n",
                "    epochs=20,\n",
                "    batch_size=128,\n",
                "    validation_split=0.2,\n",
                "    callbacks=callbacks_list,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\n模型訓練完成!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. 視覺化訓練歷史\n",
                "\n",
                "### 訓練曲線分析:\n",
                "- **損失曲線**: 觀察訓練損失和驗證損失的變化\n",
                "- **準確率曲線**: 觀察訓練準確率和驗證準確率的變化\n",
                "- **過擬合診斷**: 如果訓練損失持續下降但驗證損失上升,表示過擬合"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 提取訓練歷史\n",
                "history_dict = history.history\n",
                "\n",
                "# 查看可用的指標\n",
                "print(\"可用的訓練指標:\")\n",
                "for key in history_dict.keys():\n",
                "    print(f\"  - {key}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 繪製訓練歷史\n",
                "def plot_training_history(history):\n",
                "    \"\"\"\n",
                "    繪製訓練歷史曲線\n",
                "    \"\"\"\n",
                "    history_dict = history.history\n",
                "    loss = history_dict['loss']\n",
                "    val_loss = history_dict['val_loss']\n",
                "    accuracy = history_dict['accuracy']\n",
                "    val_accuracy = history_dict['val_accuracy']\n",
                "    epochs_range = range(1, len(loss) + 1)\n",
                "    \n",
                "    plt.figure(figsize=(14, 5))\n",
                "    \n",
                "    # 損失曲線\n",
                "    plt.subplot(1, 2, 1)\n",
                "    plt.plot(epochs_range, loss, 'bo-', label='Training Loss', linewidth=2, markersize=6)\n",
                "    plt.plot(epochs_range, val_loss, 'ro-', label='Validation Loss', linewidth=2, markersize=6)\n",
                "    plt.xlabel('Epochs', fontsize=12)\n",
                "    plt.ylabel('Loss', fontsize=12)\n",
                "    plt.title('訓練與Validation Loss', fontsize=14, fontweight='bold')\n",
                "    plt.legend(fontsize=11)\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    \n",
                "    # 準確率曲線\n",
                "    plt.subplot(1, 2, 2)\n",
                "    plt.plot(epochs_range, accuracy, 'bo-', label='Training Accuracy', linewidth=2, markersize=6)\n",
                "    plt.plot(epochs_range, val_accuracy, 'ro-', label='Validation Accuracy', linewidth=2, markersize=6)\n",
                "    plt.xlabel('Epochs', fontsize=12)\n",
                "    plt.ylabel('Accuracy', fontsize=12)\n",
                "    plt.title('訓練與Validation Accuracy', fontsize=14, fontweight='bold')\n",
                "    plt.legend(fontsize=11)\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    # 顯示最終結果\n",
                "    print(\"\\n訓練結果摘要:\")\n",
                "    print(f\"最終Training Loss: {loss[-1]:.4f}\")\n",
                "    print(f\"最終Validation Loss: {val_loss[-1]:.4f}\")\n",
                "    print(f\"最終Training Accuracy: {accuracy[-1]:.4f}\")\n",
                "    print(f\"最終Validation Accuracy: {val_accuracy[-1]:.4f}\")\n",
                "    print(f\"\\n最佳Validation Accuracy: {max(val_accuracy):.4f} (Epoch {val_accuracy.index(max(val_accuracy)) + 1})\")\n",
                "\n",
                "# 繪製訓練歷史\n",
                "plot_training_history(history)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. 模型評估\n",
                "\n",
                "### 在測試集上評估模型性能"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 在測試集上評估模型\n",
                "print(\"在測試集上評估模型...\\n\")\n",
                "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=1)\n",
                "\n",
                "print(f\"\\n測試集損失: {test_loss:.4f}\")\n",
                "print(f\"測試集準確率: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. 模型預測\n",
                "\n",
                "### 使用訓練好的模型對測試集進行預測"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 對測試集進行預測\n",
                "print(\"對測試集進行預測...\")\n",
                "y_pred_proba = model.predict(x_test_reshaped, verbose=0)\n",
                "y_pred_classes = np.argmax(y_pred_proba, axis=1)\n",
                "\n",
                "print(f\"預測完成! 預測結果形狀: {y_pred_proba.shape}\")\n",
                "print(f\"Predicted Class形狀: {y_pred_classes.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 查看單一樣本的預測結果\n",
                "sample_idx = 0\n",
                "sample_pred_proba = y_pred_proba[sample_idx]\n",
                "sample_pred_class = y_pred_classes[sample_idx]\n",
                "sample_true_class = y_test[sample_idx]\n",
                "\n",
                "print(f\"樣本 {sample_idx} 的預測結果:\")\n",
                "print(f\"真實Label: {sample_true_class}\")\n",
                "print(f\"預測Label: {sample_pred_class}\")\n",
                "print(f\"預測Conf: {sample_pred_proba[sample_pred_class]:.4f}\")\n",
                "print(f\"\\n各類別的Prediction Probability:\")\n",
                "for i, prob in enumerate(sample_pred_proba):\n",
                "    print(f\"  Digit {i}: {prob:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. 詳細評估 - 混淆矩陣與分類報告"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 計算Confusion Matrix\n",
                "cm = confusion_matrix(y_test, y_pred_classes)\n",
                "\n",
                "# 視覺化Confusion Matrix\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, \n",
                "            xticklabels=range(10), yticklabels=range(10))\n",
                "plt.xlabel('預測Label', fontsize=12)\n",
                "plt.ylabel('真實Label', fontsize=12)\n",
                "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# 計算每個類別的準確率\n",
                "print(\"\\n每個Digit的分類準確率:\")\n",
                "for i in range(10):\n",
                "    class_accuracy = cm[i, i] / cm[i, :].sum()\n",
                "    print(f\"Digit {i}: {class_accuracy:.4f} ({class_accuracy*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 顯示分類報告\n",
                "print(\"分類報告:\\n\")\n",
                "report = classification_report(y_test, y_pred_classes, \n",
                "                               target_names=[f'Digit {i}' for i in range(10)])\n",
                "print(report)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. 視覺化預測結果"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 視覺化Correctly Predicted Samples\n",
                "correct_indices = np.where(y_pred_classes == y_test)[0]\n",
                "print(f\"Correctly Predicted SamplesCount: {len(correct_indices)} / {len(y_test)} ({len(correct_indices)/len(y_test)*100:.2f}%)\")\n",
                "\n",
                "# 隨機選擇 25 個Correctly Predicted Samples\n",
                "np.random.seed(42)\n",
                "correct_samples = np.random.choice(correct_indices, size=25, replace=False)\n",
                "\n",
                "plt.figure(figsize=(12, 10))\n",
                "for i, idx in enumerate(correct_samples):\n",
                "    plt.subplot(5, 5, i + 1)\n",
                "    plt.imshow(x_test[idx], cmap='gray')\n",
                "    pred_class = y_pred_classes[idx]\n",
                "    true_class = y_test[idx]\n",
                "    confidence = y_pred_proba[idx][pred_class]\n",
                "    plt.title(f'Pred: {pred_class}\\nConf: {confidence:.2f}', \n",
                "              fontsize=9, color='green')\n",
                "    plt.axis('off')\n",
                "\n",
                "plt.suptitle('Correctly Predicted Samples', fontsize=16, fontweight='bold', y=0.995)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 視覺化Incorrectly Predicted Samples\n",
                "incorrect_indices = np.where(y_pred_classes != y_test)[0]\n",
                "print(f\"Incorrectly Predicted SamplesCount: {len(incorrect_indices)} / {len(y_test)} ({len(incorrect_indices)/len(y_test)*100:.2f}%)\")\n",
                "\n",
                "if len(incorrect_indices) > 0:\n",
                "    # 選擇前 25 個Incorrectly Predicted Samples\n",
                "    num_samples = min(25, len(incorrect_indices))\n",
                "    incorrect_samples = incorrect_indices[:num_samples]\n",
                "    \n",
                "    plt.figure(figsize=(12, 10))\n",
                "    for i, idx in enumerate(incorrect_samples):\n",
                "        plt.subplot(5, 5, i + 1)\n",
                "        plt.imshow(x_test[idx], cmap='gray')\n",
                "        pred_class = y_pred_classes[idx]\n",
                "        true_class = y_test[idx]\n",
                "        confidence = y_pred_proba[idx][pred_class]\n",
                "        plt.title(f'Pred: {pred_class} (True: {true_class})\\nConf: {confidence:.2f}', \n",
                "                  fontsize=8, color='red')\n",
                "        plt.axis('off')\n",
                "    \n",
                "    plt.suptitle('Incorrectly Predicted Samples', fontsize=16, fontweight='bold', y=0.995)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"沒有Incorrectly Predicted Samples!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 視覺化單一樣本的Prediction Probability分布\n",
                "def plot_prediction_distribution(idx):\n",
                "    \"\"\"\n",
                "    視覺化單一樣本的Prediction Probability分布\n",
                "    \"\"\"\n",
                "    plt.figure(figsize=(12, 4))\n",
                "    \n",
                "    # 顯示影像\n",
                "    plt.subplot(1, 2, 1)\n",
                "    plt.imshow(x_test[idx], cmap='gray')\n",
                "    plt.title(f'Test Sample {idx}', fontsize=12, fontweight='bold')\n",
                "    plt.axis('off')\n",
                "    \n",
                "    # 顯示Prediction Probability分布\n",
                "    plt.subplot(1, 2, 2)\n",
                "    pred_proba = y_pred_proba[idx]\n",
                "    pred_class = y_pred_classes[idx]\n",
                "    true_class = y_test[idx]\n",
                "    \n",
                "    colors = ['green' if i == pred_class else 'steelblue' for i in range(10)]\n",
                "    if pred_class != true_class:\n",
                "        colors[true_class] = 'red'\n",
                "    \n",
                "    bars = plt.bar(range(10), pred_proba, color=colors, alpha=0.7, edgecolor='black')\n",
                "    plt.xlabel('Digit類別', fontsize=11)\n",
                "    plt.ylabel('Prediction Probability', fontsize=11)\n",
                "    plt.title(f'Pred: {pred_class} | True: {true_class} | Conf: {pred_proba[pred_class]:.4f}', \n",
                "              fontsize=11, fontweight='bold')\n",
                "    plt.xticks(range(10))\n",
                "    plt.ylim([0, 1])\n",
                "    plt.grid(axis='y', alpha=0.3)\n",
                "    \n",
                "    # 添加圖例\n",
                "    from matplotlib.patches import Patch\n",
                "    legend_elements = [\n",
                "        Patch(facecolor='green', alpha=0.7, label='Predicted Class'),\n",
                "        Patch(facecolor='red', alpha=0.7, label='True Class (Incorrect)'),\n",
                "        Patch(facecolor='steelblue', alpha=0.7, label='Other Classes')\n",
                "    ]\n",
                "    plt.legend(handles=legend_elements, fontsize=9, loc='upper right')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# 視覺化幾個樣本的Prediction Probability分布\n",
                "print(\"Correctly Predicted Samples:\")\n",
                "plot_prediction_distribution(correct_indices[0])\n",
                "\n",
                "if len(incorrect_indices) > 0:\n",
                "    print(\"\\nIncorrectly Predicted Samples:\")\n",
                "    plot_prediction_distribution(incorrect_indices[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 14. 模型保存與載入\n",
                "\n",
                "### 保存模型的三種方式:\n",
                "1. **保存整個模型** (架構 + 權重 + 訓練配置)\n",
                "2. **只保存權重**\n",
                "3. **保存架構** (JSON 格式)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 方式 1: 保存整個模型 (推薦)\n",
                "model.save('mnist_cnn_complete_model.h5')\n",
                "print(\"完整模型已保存為: mnist_cnn_complete_model.h5\")\n",
                "\n",
                "# 方式 2: 只保存權重\n",
                "model.save_weights('mnist_cnn_weights.h5')\n",
                "print(\"模型權重已保存為: mnist_cnn_weights.h5\")\n",
                "\n",
                "# 方式 3: 保存模型架構為 JSON\n",
                "model_json = model.to_json()\n",
                "with open('mnist_cnn_architecture.json', 'w') as json_file:\n",
                "    json_file.write(model_json)\n",
                "print(\"模型架構已保存為: mnist_cnn_architecture.json\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 載入完整模型\n",
                "from tensorflow.keras.models import load_model\n",
                "\n",
                "loaded_model = load_model('mnist_cnn_complete_model.h5')\n",
                "print(\"模型載入完成!\")\n",
                "\n",
                "# 驗證載入的模型\n",
                "loaded_test_loss, loaded_test_accuracy = loaded_model.evaluate(x_test_reshaped, y_test, verbose=0)\n",
                "print(f\"\\n載入模型的測試準確率: {loaded_test_accuracy:.4f}\")\n",
                "print(f\"原始模型的測試準確率: {test_accuracy:.4f}\")\n",
                "print(f\"\\n兩者是否一致: {np.isclose(loaded_test_accuracy, test_accuracy)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 載入權重到新模型\n",
                "new_model = create_cnn_model()\n",
                "new_model.load_weights('mnist_cnn_weights.h5')\n",
                "print(\"權重載入完成!\")\n",
                "\n",
                "# 注意: 載入權重後需要重新編譯模型\n",
                "new_model.compile(\n",
                "    optimizer='adam',\n",
                "    loss='sparse_categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "# 驗證\n",
                "new_test_loss, new_test_accuracy = new_model.evaluate(x_test_reshaped, y_test, verbose=0)\n",
                "print(f\"\\n新模型的測試準確率: {new_test_accuracy:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 載入架構並載入權重\n",
                "from tensorflow.keras.models import model_from_json\n",
                "\n",
                "# 載入架構\n",
                "with open('mnist_cnn_architecture.json', 'r') as json_file:\n",
                "    loaded_model_json = json_file.read()\n",
                "\n",
                "reconstructed_model = model_from_json(loaded_model_json)\n",
                "print(\"模型架構載入完成!\")\n",
                "\n",
                "# 載入權重\n",
                "reconstructed_model.load_weights('mnist_cnn_weights.h5')\n",
                "print(\"權重載入完成!\")\n",
                "\n",
                "# 編譯模型\n",
                "reconstructed_model.compile(\n",
                "    optimizer='adam',\n",
                "    loss='sparse_categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "# 驗證\n",
                "reconstructed_test_loss, reconstructed_test_accuracy = reconstructed_model.evaluate(\n",
                "    x_test_reshaped, y_test, verbose=0\n",
                ")\n",
                "print(f\"\\n重建模型的測試準確率: {reconstructed_test_accuracy:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 15. 使用載入的模型進行預測"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 使用載入的模型進行預測\n",
                "sample_indices = [0, 100, 200, 300, 400]\n",
                "sample_images = x_test_reshaped[sample_indices]\n",
                "\n",
                "# 預測\n",
                "predictions = loaded_model.predict(sample_images, verbose=0)\n",
                "predicted_classes = np.argmax(predictions, axis=1)\n",
                "\n",
                "# 視覺化\n",
                "plt.figure(figsize=(15, 3))\n",
                "for i, idx in enumerate(sample_indices):\n",
                "    plt.subplot(1, 5, i + 1)\n",
                "    plt.imshow(x_test[idx], cmap='gray')\n",
                "    pred_class = predicted_classes[i]\n",
                "    true_class = y_test[idx]\n",
                "    confidence = predictions[i][pred_class]\n",
                "    \n",
                "    color = 'green' if pred_class == true_class else 'red'\n",
                "    plt.title(f'Pred: {pred_class}\\nTrue: {true_class}\\nConf: {confidence:.2f}', \n",
                "              fontsize=10, color=color)\n",
                "    plt.axis('off')\n",
                "\n",
                "plt.suptitle('Predictions Using Loaded Model', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 16. 總結\n",
                "\n",
                "### 本次實作完成的內容:\n",
                "\n",
                "1. ✅ **資料載入與探索**: 載入 MNIST 資料集並進行視覺化分析\n",
                "2. ✅ **資料預處理**: 正規化和重塑資料以符合 CNN 輸入要求\n",
                "3. ✅ **模型建立**: 使用 Keras Sequential API 建立 CNN 模型\n",
                "4. ✅ **模型編譯**: 配置優化器、損失函數和評估指標\n",
                "5. ✅ **模型訓練**: 使用 callbacks 控制訓練過程\n",
                "6. ✅ **訓練視覺化**: 繪製訓練歷史曲線\n",
                "7. ✅ **模型評估**: 在測試集上評估模型性能\n",
                "8. ✅ **模型預測**: 對新數據進行預測並視覺化結果\n",
                "9. ✅ **詳細評估**: 使用混淆矩陣和分類報告進行深入分析\n",
                "10. ✅ **模型保存與載入**: 學習三種保存模型的方式\n",
                "\n",
                "### 模型性能:\n",
                "- 測試集準確率: **>98%** (典型結果)\n",
                "- 訓練時間: 約 2-5 分鐘 (取決於硬體)\n",
                "\n",
                "### 關鍵學習點:\n",
                "1. CNN 透過卷積層自動學習影像特徵\n",
                "2. 池化層降低維度並提高模型的平移不變性\n",
                "3. Dropout 和 Early Stopping 有效防止過擬合\n",
                "4. 訓練曲線可以幫助診斷模型性能\n",
                "5. 混淆矩陣提供詳細的分類性能分析\n",
                "\n",
                "### 下一步建議:\n",
                "- 嘗試調整模型架構 (增加/減少層數、改變濾波器數量)\n",
                "- 嘗試不同的優化器和學習率\n",
                "- 使用數據增強 (Data Augmentation) 提高模型泛化能力\n",
                "- 嘗試其他 CNN 架構 (如 VGG、ResNet)\n",
                "- 應用到其他影像分類問題\n",
                "\n",
                "---\n",
                "\n",
                "**恭喜你完成 CNN 實作演練!** 🎉"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}