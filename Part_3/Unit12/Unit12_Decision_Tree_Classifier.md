# Unit12 æ±ºç­–æ¨¹åˆ†é¡ | Decision Tree Classifier

> **æœ€å¾Œæ›´æ–°**ï¼š2026-01-18

---

## å­¸ç¿’ç›®æ¨™

æœ¬ç¯€èª²å°‡æ·±å…¥å­¸ç¿’**æ±ºç­–æ¨¹åˆ†é¡ (Decision Tree Classifier)**ï¼Œé€™æ˜¯æ©Ÿå™¨å­¸ç¿’ä¸­æœ€ç›´è§€ä¸”æ˜“æ–¼è§£é‡‹çš„åˆ†é¡æ–¹æ³•ä¹‹ä¸€ã€‚é€šéæœ¬ç¯€èª²ï¼Œæ‚¨å°‡èƒ½å¤ ï¼š

- ç†è§£æ±ºç­–æ¨¹çš„æ ¸å¿ƒæ¦‚å¿µèˆ‡å·¥ä½œåŸç†
- æŒæ¡åˆ†è£‚æ¨™æº–ï¼ˆGiniã€Entropyï¼‰çš„æ•¸å­¸åŸç†
- å­¸ç¿’å¦‚ä½•æ§åˆ¶æ¨¹çš„è¤‡é›œåº¦ï¼ˆå‰ªææŠ€è¡“ï¼‰
- æŒæ¡ sklearn ä¸­ `DecisionTreeClassifier` çš„ä½¿ç”¨æ–¹æ³•
- æ‡‰ç”¨æ±ºç­–æ¨¹è§£æ±ºåŒ–å·¥é ˜åŸŸçš„åˆ†é¡å•é¡Œ
- ç†è§£æ¨¡å‹çš„å„ªå‹¢ã€é™åˆ¶èˆ‡é©ç”¨å ´æ™¯
- å¯è¦–åŒ–æ±ºç­–æ¨¹çµæ§‹èˆ‡ç‰¹å¾µé‡è¦æ€§

---

## 1. æ±ºç­–æ¨¹åˆ†é¡åŸºæœ¬æ¦‚å¿µ

### 1.1 ä»€éº¼æ˜¯æ±ºç­–æ¨¹ï¼Ÿ

**æ±ºç­–æ¨¹ (Decision Tree)** æ˜¯ä¸€ç¨®æ¨¹ç‹€çµæ§‹çš„ç›£ç£å­¸ç¿’ç®—æ³•ï¼Œé€šéä¸€ç³»åˆ— if-then-else æ±ºç­–è¦å‰‡ä¾†é€²è¡Œé æ¸¬ã€‚æ±ºç­–æ¨¹æ¨¡æ“¬äººé¡æ±ºç­–éç¨‹ï¼Œå¾æ¨¹æ ¹é–‹å§‹ï¼Œæ ¹æ“šç‰¹å¾µå€¼é€æ­¥å‘ä¸‹åˆ†æ”¯ï¼Œæœ€çµ‚åˆ°é”è‘‰ç¯€é»å¾—åˆ°é æ¸¬çµæœã€‚

### 1.2 æ±ºç­–æ¨¹çš„çµ„æˆå…ƒç´ 

#### 1.2.1 ç¯€é»é¡å‹

1. **æ ¹ç¯€é» (Root Node)**ï¼š
   - æ¨¹çš„èµ·å§‹ç¯€é»ï¼ŒåŒ…å«æ‰€æœ‰è¨“ç·´æ¨£æœ¬
   - ä»£è¡¨ç¬¬ä¸€å€‹æœ€é‡è¦çš„ç‰¹å¾µåˆ†è£‚

2. **å…§éƒ¨ç¯€é» (Internal Node)**ï¼š
   - ä¸­é–“æ±ºç­–ç¯€é»
   - åŒ…å«ä¸€å€‹ç‰¹å¾µæ¸¬è©¦æ¢ä»¶ï¼ˆå¦‚ temperature > 200ï¼‰
   - æœ‰å…©å€‹æˆ–å¤šå€‹å­ç¯€é»

3. **è‘‰ç¯€é» (Leaf Node)**ï¼š
   - çµ‚ç«¯ç¯€é»ï¼Œç„¡å­ç¯€é»
   - åŒ…å«æœ€çµ‚çš„åˆ†é¡æ¨™ç±¤æˆ–é¡åˆ¥æ©Ÿç‡

#### 1.2.2 åˆ†æ”¯èˆ‡è·¯å¾‘

- **åˆ†æ”¯ (Branch)**ï¼šé€£æ¥ç¯€é»çš„ç·šï¼Œä»£è¡¨æ±ºç­–è¦å‰‡çš„çµæœ
- **æ·±åº¦ (Depth)**ï¼šå¾æ ¹ç¯€é»åˆ°è‘‰ç¯€é»çš„æœ€é•·è·¯å¾‘
- **æ±ºç­–è·¯å¾‘**ï¼šå¾æ ¹ç¯€é»åˆ°æŸå€‹è‘‰ç¯€é»çš„å®Œæ•´è·¯å¾‘

### 1.3 æ±ºç­–æ¨¹å¦‚ä½•å·¥ä½œï¼Ÿ

æ±ºç­–æ¨¹çš„æ§‹å»ºéç¨‹æ˜¯ä¸€å€‹**éæ­¸çš„è²ªå©ªç®—æ³•**ï¼š

1. **é¸æ“‡æœ€ä½³åˆ†è£‚ç‰¹å¾µ**ï¼š
   - è©•ä¼°æ‰€æœ‰ç‰¹å¾µå’Œæ‰€æœ‰å¯èƒ½çš„åˆ†è£‚é»
   - é¸æ“‡ä½¿æŸå€‹æ¨™æº–ï¼ˆå¦‚ Gini ä¸ç´”åº¦ï¼‰æœ€å°åŒ–çš„åˆ†è£‚

2. **åˆ†è£‚ç¯€é»**ï¼š
   - æ ¹æ“šé¸å®šçš„ç‰¹å¾µå’Œé–¾å€¼å°‡æ•¸æ“šåˆ†æˆå­é›†
   - å·¦å­æ¨¹ï¼šæ»¿è¶³æ¢ä»¶çš„æ¨£æœ¬
   - å³å­æ¨¹ï¼šä¸æ»¿è¶³æ¢ä»¶çš„æ¨£æœ¬

3. **éæ­¸é‡è¤‡**ï¼š
   - å°æ¯å€‹å­ç¯€é»é‡è¤‡ä¸Šè¿°éç¨‹
   - ç›´åˆ°æ»¿è¶³åœæ­¢æ¢ä»¶

4. **åœæ­¢æ¢ä»¶**ï¼š
   - ç¯€é»ä¸­æ‰€æœ‰æ¨£æœ¬å±¬æ–¼åŒä¸€é¡åˆ¥
   - é”åˆ°æœ€å¤§æ·±åº¦ (max_depth)
   - ç¯€é»æ¨£æœ¬æ•¸å°æ–¼æœ€å°åˆ†è£‚æ¨£æœ¬æ•¸ (min_samples_split)
   - é€²ä¸€æ­¥åˆ†è£‚ç„¡æ³•æ”¹å–„ç´”åº¦

---

## 2. åˆ†è£‚æ¨™æº– (Splitting Criteria)

æ±ºç­–æ¨¹çš„æ ¸å¿ƒå•é¡Œæ˜¯ï¼š**å¦‚ä½•é¸æ“‡æœ€ä½³åˆ†è£‚ç‰¹å¾µå’Œåˆ†è£‚é»ï¼Ÿ** sklearn æä¾›å…©ç¨®ä¸»è¦çš„åˆ†è£‚æ¨™æº–ã€‚

### 2.1 Gini ä¸ç´”åº¦ (Gini Impurity)

#### æ•¸å­¸å®šç¾©

å°æ–¼ä¸€å€‹åŒ…å« $K$ å€‹é¡åˆ¥çš„ç¯€é» $t$ ï¼ŒGini ä¸ç´”åº¦å®šç¾©ç‚ºï¼š

$$
\text{Gini}(t) = 1 - \sum_{k=1}^{K} p_k^2
$$

å…¶ä¸­ $p_k$ æ˜¯ç¯€é» $t$ ä¸­é¡åˆ¥ $k$ çš„æ¨£æœ¬æ¯”ä¾‹ã€‚

#### ç†è§£ Gini ä¸ç´”åº¦

- **Gini = 0**ï¼šç¯€é»å®Œå…¨ç´”æ·¨ï¼Œæ‰€æœ‰æ¨£æœ¬å±¬æ–¼åŒä¸€é¡åˆ¥
- **Gini = 0.5** (äºŒåˆ†é¡)ï¼šç¯€é»å®Œå…¨ä¸ç´”ï¼Œå…©é¡æ¨£æœ¬å„ä½”50%
- **Gini è¶Šå°**ï¼šç¯€é»è¶Šç´”æ·¨ï¼Œåˆ†é¡æ•ˆæœè¶Šå¥½

#### äºŒåˆ†é¡ç¯„ä¾‹

å‡è¨­ç¯€é»æœ‰ 100 å€‹æ¨£æœ¬ï¼Œ60 å€‹ Successï¼Œ40 å€‹ Failureï¼š

$$
\text{Gini} = 1 - (0.6^2 + 0.4^2) = 1 - (0.36 + 0.16) = 0.48
$$

#### Gini å¢ç›Š (Gini Gain)

åˆ†è£‚å¾Œçš„ Gini å¢ç›Šç‚ºï¼š

$$
\text{Gini Gain} = \text{Gini}(\text{parent}) - \sum_{i} \frac{N_i}{N} \text{Gini}(\text{child}_i)
$$

å…¶ä¸­ï¼š
- $N$ : çˆ¶ç¯€é»æ¨£æœ¬æ•¸
- $N_i$ : ç¬¬ $i$ å€‹å­ç¯€é»æ¨£æœ¬æ•¸

**ç›®æ¨™**ï¼šé¸æ“‡ä½¿ Gini Gain æœ€å¤§ï¼ˆæˆ–åŠ æ¬Šå¾Œçš„ Gini æœ€å°ï¼‰çš„åˆ†è£‚ã€‚

### 2.2 ç†µèˆ‡ä¿¡æ¯å¢ç›Š (Entropy & Information Gain)

#### ç†µçš„æ•¸å­¸å®šç¾©

å°æ–¼ä¸€å€‹åŒ…å« $K$ å€‹é¡åˆ¥çš„ç¯€é» $t$ ï¼Œç†µå®šç¾©ç‚ºï¼š

$$
\text{Entropy}(t) = -\sum_{k=1}^{K} p_k \log_2(p_k)
$$

å…¶ä¸­ $p_k$ æ˜¯ç¯€é» $t$ ä¸­é¡åˆ¥ $k$ çš„æ¨£æœ¬æ¯”ä¾‹ã€‚

#### ç†è§£ç†µ

- **Entropy = 0**ï¼šç¯€é»å®Œå…¨ç´”æ·¨
- **Entropy = 1** (äºŒåˆ†é¡)ï¼šç¯€é»å®Œå…¨ä¸ç´”ï¼ˆ50%-50%ï¼‰
- **ç†µè¶Šå°**ï¼šç¯€é»è¶Šæœ‰åºï¼Œä¸ç¢ºå®šæ€§è¶Šä½

#### ä¿¡æ¯å¢ç›Š (Information Gain)

$$
\text{IG} = \text{Entropy}(\text{parent}) - \sum_{i} \frac{N_i}{N} \text{Entropy}(\text{child}_i)
$$

**ç›®æ¨™**ï¼šé¸æ“‡ä½¿ä¿¡æ¯å¢ç›Šæœ€å¤§çš„åˆ†è£‚ã€‚

### 2.3 Gini vs Entropy

| ç‰¹æ€§ | Gini ä¸ç´”åº¦ | ç†µ |
|-----|-------------|---|
| **è¨ˆç®—é€Ÿåº¦** | æ›´å¿«ï¼ˆç„¡å°æ•¸é‹ç®—ï¼‰ | è¼ƒæ…¢ï¼ˆæœ‰å°æ•¸é‹ç®—ï¼‰ |
| **æ•¸å€¼ç¯„åœ** | [0, 0.5] (äºŒåˆ†é¡) | [0, 1] (äºŒåˆ†é¡) |
| **åå¥½** | å‚¾å‘å°‡æœ€å¤§é¡åˆ¥åˆ†é›¢ | æ›´å‚¾å‘ç”¢ç”Ÿå¹³è¡¡çš„åˆ†è£‚ |
| **å¯¦å‹™è¡¨ç¾** | é€šå¸¸å·®ç•°ä¸å¤§ | é€šå¸¸å·®ç•°ä¸å¤§ |
| **é è¨­å€¼** | sklearn é è¨­ | ID3/C4.5 ç®—æ³•ä½¿ç”¨ |

**å¯¦å‹™å»ºè­°**ï¼š
- **Gini**ï¼šè¨ˆç®—æ›´å¿«ï¼Œsklearn é è¨­ï¼Œé©åˆå¤§å¤šæ•¸æƒ…æ³
- **Entropy**ï¼šç†è«–ä¸Šæ›´ç¬¦åˆä¿¡æ¯è«–ï¼Œä½†å¯¦å‹™å·®ç•°å°
- å…©è€…é€šå¸¸ç”¢ç”Ÿç›¸ä¼¼çš„æ¨¹çµæ§‹

---

## 3. éæ“¬åˆæ§åˆ¶èˆ‡å‰ªæ

æ±ºç­–æ¨¹å®¹æ˜“éæ“¬åˆï¼Œå› ç‚ºå®ƒå¯ä»¥ç„¡é™åˆ†è£‚ç›´åˆ°å®Œç¾æ“¬åˆè¨“ç·´æ•¸æ“šã€‚sklearn æä¾›å¤šç¨®åƒæ•¸ä¾†æ§åˆ¶æ¨¹çš„è¤‡é›œåº¦ã€‚

### 3.1 é å‰ªæ (Pre-Pruning)

**é å‰ªæ**åœ¨æ¨¹ç”Ÿé•·éç¨‹ä¸­æå‰åœæ­¢åˆ†è£‚ï¼Œsklearn æä¾›ä»¥ä¸‹åƒæ•¸ï¼š

#### 3.1.1 max_depth (æœ€å¤§æ·±åº¦)

```python
tree = DecisionTreeClassifier(max_depth=5)
```

- **å«ç¾©**ï¼šé™åˆ¶æ¨¹çš„æœ€å¤§æ·±åº¦
- **é è¨­å€¼**ï¼šNoneï¼ˆç„¡é™åˆ¶ï¼Œç›´åˆ°è‘‰å­ç´”æ·¨ï¼‰
- **æ¨è–¦ç¯„åœ**ï¼š3-10ï¼ˆè¦–æ•¸æ“šè¦æ¨¡è€Œå®šï¼‰
- **æ•ˆæœ**ï¼š
  - max_depth å¤ªå¤§ â†’ éæ“¬åˆ
  - max_depth å¤ªå° â†’ æ¬ æ“¬åˆ

#### 3.1.2 min_samples_split (æœ€å°åˆ†è£‚æ¨£æœ¬æ•¸)

```python
tree = DecisionTreeClassifier(min_samples_split=20)
```

- **å«ç¾©**ï¼šç¯€é»å¿…é ˆåŒ…å«è‡³å°‘é€™éº¼å¤šæ¨£æœ¬æ‰èƒ½åˆ†è£‚
- **é è¨­å€¼**ï¼š2
- **æ¨è–¦ç¯„åœ**ï¼š
  - å°æ•¸æ“šé›†ï¼š5-20
  - å¤§æ•¸æ“šé›†ï¼š50-200
- **æ•ˆæœ**ï¼šå¢å¤§æ­¤å€¼å¯æ¸›å°‘éæ“¬åˆ

#### 3.1.3 min_samples_leaf (æœ€å°è‘‰ç¯€é»æ¨£æœ¬æ•¸)

```python
tree = DecisionTreeClassifier(min_samples_leaf=10)
```

- **å«ç¾©**ï¼šè‘‰ç¯€é»å¿…é ˆåŒ…å«è‡³å°‘é€™éº¼å¤šæ¨£æœ¬
- **é è¨­å€¼**ï¼š1
- **æ¨è–¦ç¯„åœ**ï¼š1-50
- **æ•ˆæœ**ï¼šç¢ºä¿è‘‰ç¯€é»æœ‰è¶³å¤ ä»£è¡¨æ€§

#### 3.1.4 max_leaf_nodes (æœ€å¤§è‘‰ç¯€é»æ•¸)

```python
tree = DecisionTreeClassifier(max_leaf_nodes=20)
```

- **å«ç¾©**ï¼šé™åˆ¶æ¨¹çš„æœ€å¤§è‘‰ç¯€é»æ•¸é‡
- **é è¨­å€¼**ï¼šNone
- **æ•ˆæœ**ï¼šä»¥æœ€ä½³å„ªå…ˆæ–¹å¼ç”Ÿé•·æ¨¹

#### 3.1.5 min_impurity_decrease (æœ€å°ä¸ç´”åº¦æ¸›å°‘)

```python
tree = DecisionTreeClassifier(min_impurity_decrease=0.01)
```

- **å«ç¾©**ï¼šåˆ†è£‚å¿…é ˆä½¿ä¸ç´”åº¦æ¸›å°‘è‡³å°‘é€™å€‹å€¼
- **é è¨­å€¼**ï¼š0.0
- **æ•ˆæœ**ï¼šé¿å…ç„¡æ„ç¾©çš„å°åˆ†è£‚

### 3.2 å¾Œå‰ªæ (Post-Pruning)

sklearn ä½¿ç”¨ **æˆæœ¬è¤‡é›œåº¦å‰ªæ (Cost Complexity Pruning)**ï¼Œé€šé `ccp_alpha` åƒæ•¸æ§åˆ¶ï¼š

```python
tree = DecisionTreeClassifier(ccp_alpha=0.01)
```

- **åŸç†**ï¼šå¹³è¡¡æ¨¹çš„è¤‡é›œåº¦èˆ‡æº–ç¢ºç‡
- **ccp_alpha = 0**ï¼šç„¡å‰ªæï¼ˆé è¨­ï¼‰
- **ccp_alpha > 0**ï¼šæ›´æ¿€é€²çš„å‰ªæ
- **é¸æ“‡æ–¹æ³•**ï¼šä½¿ç”¨äº¤å‰é©—è­‰é¸æ“‡æœ€ä½³ alpha å€¼

#### æˆæœ¬è¤‡é›œåº¦å…¬å¼

$$
R_\alpha(T) = R(T) + \alpha |T|
$$

å…¶ä¸­ï¼š
- $R(T)$ : æ¨¹çš„è¨“ç·´èª¤å·®
- $|T|$ : è‘‰ç¯€é»æ•¸é‡
- $\alpha$ : è¤‡é›œåº¦åƒæ•¸

**ç›®æ¨™**ï¼šæ‰¾åˆ°ä½¿ $R_\alpha(T)$ æœ€å°çš„å­æ¨¹ã€‚

---

## 4. sklearn ä¸­çš„ DecisionTreeClassifier

### 4.1 åŸºæœ¬ä½¿ç”¨æ–¹æ³•

```python
from sklearn.tree import DecisionTreeClassifier

# å‰µå»ºæ¨¡å‹
model = DecisionTreeClassifier(
    criterion='gini',      # åˆ†è£‚æ¨™æº–
    max_depth=5,          # æœ€å¤§æ·±åº¦
    min_samples_split=20, # æœ€å°åˆ†è£‚æ¨£æœ¬æ•¸
    min_samples_leaf=10,  # æœ€å°è‘‰ç¯€é»æ¨£æœ¬æ•¸
    random_state=42       # éš¨æ©Ÿç¨®å­
)

# è¨“ç·´æ¨¡å‹
model.fit(X_train, y_train)

# é æ¸¬
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)
```

### 4.2 é‡è¦åƒæ•¸è©³è§£

#### 4.2.1 åˆ†è£‚æ¨™æº–

**criterion** (é è¨­='gini')
- `'gini'`: Gini ä¸ç´”åº¦
- `'entropy'`: ä¿¡æ¯ç†µ
- `'log_loss'`: å°æ•¸æå¤±ï¼ˆç­‰åŒæ–¼ entropyï¼‰

#### 4.2.2 å‰ªæåƒæ•¸

**max_depth** (é è¨­=None)
- æ§åˆ¶æ¨¹çš„æœ€å¤§æ·±åº¦
- None è¡¨ç¤ºç„¡é™åˆ¶

**min_samples_split** (é è¨­=2)
- åˆ†è£‚å…§éƒ¨ç¯€é»æ‰€éœ€çš„æœ€å°æ¨£æœ¬æ•¸
- å¯ä»¥æ˜¯æ•´æ•¸æˆ–æµ®é»æ•¸ï¼ˆæ¯”ä¾‹ï¼‰

**min_samples_leaf** (é è¨­=1)
- è‘‰ç¯€é»æ‰€éœ€çš„æœ€å°æ¨£æœ¬æ•¸
- å¯ä»¥æ˜¯æ•´æ•¸æˆ–æµ®é»æ•¸ï¼ˆæ¯”ä¾‹ï¼‰

**max_leaf_nodes** (é è¨­=None)
- æœ€å¤§è‘‰ç¯€é»æ•¸é‡
- ä»¥æœ€ä½³å„ªå…ˆæ–¹å¼ç”Ÿé•·æ¨¹

**min_impurity_decrease** (é è¨­=0.0)
- åˆ†è£‚æ‰€éœ€çš„æœ€å°ä¸ç´”åº¦æ¸›å°‘

**ccp_alpha** (é è¨­=0.0)
- æˆæœ¬è¤‡é›œåº¦å‰ªæåƒæ•¸
- éè² æµ®é»æ•¸

#### 4.2.3 å…¶ä»–åƒæ•¸

**splitter** (é è¨­='best')
- `'best'`: é¸æ“‡æœ€ä½³åˆ†è£‚
- `'random'`: éš¨æ©Ÿåˆ†è£‚ï¼ˆå¢åŠ éš¨æ©Ÿæ€§ï¼‰

**max_features** (é è¨­=None)
- å°‹æ‰¾æœ€ä½³åˆ†è£‚æ™‚è€ƒæ…®çš„ç‰¹å¾µæ•¸é‡
- None: ä½¿ç”¨æ‰€æœ‰ç‰¹å¾µ
- int: è€ƒæ…® max_features å€‹ç‰¹å¾µ
- float: è€ƒæ…® max_features * n_features å€‹ç‰¹å¾µ
- `'sqrt'`: sqrt(n_features)
- `'log2'`: log2(n_features)

**class_weight** (é è¨­=None)
- é¡åˆ¥æ¬Šé‡
- `'balanced'`: è‡ªå‹•èª¿æ•´æ¬Šé‡èˆ‡é¡åˆ¥é »ç‡æˆåæ¯”
- dict: æ‰‹å‹•è¨­ç½®æ¬Šé‡

**random_state**
- éš¨æ©Ÿæ•¸ç¨®å­ï¼Œç¢ºä¿çµæœå¯é‡ç¾

### 4.3 æ¨¡å‹å±¬æ€§

è¨“ç·´å®Œæˆå¾Œå¯å­˜å–ï¼š

```python
# æ¨¹çš„æ·±åº¦
print(f'Tree depth: {model.tree_.max_depth}')

# è‘‰ç¯€é»æ•¸é‡
print(f'Number of leaves: {model.get_n_leaves()}')

# ç‰¹å¾µé‡è¦æ€§
print(f'Feature importances: {model.feature_importances_}')

# é¡åˆ¥æ¨™ç±¤
print(f'Classes: {model.classes_}')

# ç¯€é»æ•¸é‡
print(f'Number of nodes: {model.tree_.node_count}')
```

### 4.4 é æ¸¬æ–¹æ³•

```python
# é æ¸¬é¡åˆ¥æ¨™ç±¤
y_pred = model.predict(X_test)

# é æ¸¬æ©Ÿç‡
y_proba = model.predict_proba(X_test)  # shape: (n_samples, n_classes)

# é æ¸¬å°æ•¸æ©Ÿç‡
y_log_proba = model.predict_log_proba(X_test)

# æ±ºç­–è·¯å¾‘
decision_path = model.decision_path(X_test)

# æ‡‰ç”¨åˆ°è‘‰ç¯€é»çš„ç´¢å¼•
leaf_ids = model.apply(X_test)
```

---

## 5. æ±ºç­–æ¨¹å¯è¦–åŒ–

æ±ºç­–æ¨¹æœ€å¤§çš„å„ªå‹¢æ˜¯**é«˜åº¦å¯è§£é‡‹æ€§**ï¼Œæˆ‘å€‘å¯ä»¥ç›´æ¥å¯è¦–åŒ–æ¨¹çµæ§‹ã€‚

### 5.1 ä½¿ç”¨ plot_tree

```python
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize=(20, 10))
plot_tree(
    model,
    feature_names=X.columns,
    class_names=['Failure', 'Success'],
    filled=True,
    rounded=True,
    fontsize=10
)
plt.title('Decision Tree Structure')
plt.tight_layout()
plt.show()
```

### 5.2 ä½¿ç”¨ export_graphviz

```python
from sklearn.tree import export_graphviz
import graphviz

dot_data = export_graphviz(
    model,
    out_file=None,
    feature_names=X.columns,
    class_names=['Failure', 'Success'],
    filled=True,
    rounded=True
)

graph = graphviz.Source(dot_data)
graph.render('decision_tree', format='png', cleanup=True)
```

### 5.3 ä½¿ç”¨ export_text

```python
from sklearn.tree import export_text

tree_rules = export_text(
    model,
    feature_names=list(X.columns)
)
print(tree_rules)
```

è¼¸å‡ºç¯„ä¾‹ï¼š
```
|--- temperature <= 200.0
|   |--- pressure <= 15.0
|   |   |--- class: Failure
|   |--- pressure >  15.0
|   |   |--- class: Success
|--- temperature >  200.0
|   |--- class: Success
```

---

## 6. ç‰¹å¾µé‡è¦æ€§åˆ†æ

æ±ºç­–æ¨¹è‡ªå‹•è¨ˆç®—æ¯å€‹ç‰¹å¾µçš„é‡è¦æ€§ã€‚

### 6.1 ç‰¹å¾µé‡è¦æ€§åŸç†

ç‰¹å¾µé‡è¦æ€§åŸºæ–¼**åŠ æ¬Šä¸ç´”åº¦æ¸›å°‘**ï¼š

$$
\text{Importance}(f) = \sum_{t \in \text{nodes using } f} \frac{N_t}{N} \Delta \text{Impurity}(t)
$$

å…¶ä¸­ï¼š
- $N_t$ : ç¯€é» $t$ çš„æ¨£æœ¬æ•¸
- $N$ : ç¸½æ¨£æœ¬æ•¸
- $\Delta \text{Impurity}(t)$ : ç¯€é» $t$ åˆ†è£‚å¾Œçš„ä¸ç´”åº¦æ¸›å°‘

### 6.2 æå–èˆ‡å¯è¦–åŒ–

```python
# ç²å–ç‰¹å¾µé‡è¦æ€§
importances = model.feature_importances_
feature_names = X.columns

# æ’åº
indices = np.argsort(importances)[::-1]

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.bar(range(len(importances)), importances[indices])
plt.xticks(range(len(importances)), feature_names[indices], rotation=45)
plt.xlabel('Features')
plt.ylabel('Importance')
plt.title('Feature Importances')
plt.tight_layout()
plt.show()

# æ‰“å°æ’å
print("Feature ranking:")
for i, idx in enumerate(indices):
    print(f"{i+1}. {feature_names[idx]}: {importances[idx]:.4f}")
```

### 6.3 åŒ–å·¥æ„ç¾©è§£è®€

åœ¨åŒ–å·¥åæ‡‰åˆ†é¡ä¸­ï¼Œç‰¹å¾µé‡è¦æ€§å¯ä»¥å¹«åŠ©ï¼š
- **è­˜åˆ¥é—œéµæ“ä½œè®Šæ•¸**ï¼šå“ªäº›æ¢ä»¶å°åæ‡‰æˆåŠŸæœ€é—œéµ
- **å„ªåŒ–å¯¦é©—è¨­è¨ˆ**ï¼šå„ªå…ˆèª¿æ•´é‡è¦ç‰¹å¾µ
- **ç°¡åŒ–æ¨¡å‹**ï¼šç§»é™¤ä¸é‡è¦çš„ç‰¹å¾µ
- **è£½ç¨‹ç†è§£**ï¼šé©—è­‰èˆ‡åŒ–å­¸åŸç†çš„ä¸€è‡´æ€§

---

## 7. åŒ–å·¥é ˜åŸŸæ‡‰ç”¨å ´æ™¯

### 7.1 ç”¢å“å“è³ªåˆ†é¡

**å•é¡Œ**ï¼šæ ¹æ“šè£½ç¨‹åƒæ•¸åˆ¤æ–·ç”¢å“æ˜¯å¦åˆæ ¼

**ç‰¹å¾µè®Šæ•¸**ï¼š
- åæ‡‰æº«åº¦ã€å£“åŠ›ã€æ™‚é–“
- åŸæ–™ç´”åº¦ã€æµé‡
- å‚¬åŒ–åŠ‘é¡å‹èˆ‡æ¿ƒåº¦

**ç›®æ¨™è®Šæ•¸**ï¼šåˆæ ¼ (1) / ä¸åˆæ ¼ (0)

**æ±ºç­–æ¨¹å„ªå‹¢**ï¼š
- å¯ç›´æ¥æå– if-then è¦å‰‡
- å®¹æ˜“èˆ‡æ“ä½œäººå“¡æºé€š
- è‡ªå‹•ç™¼ç¾éç·šæ€§é—œä¿‚èˆ‡äº¤äº’ä½œç”¨

### 7.2 è¨­å‚™æ•…éšœè¨ºæ–·

**å•é¡Œ**ï¼šæ ¹æ“šç›£æ¸¬ä¿¡è™Ÿåˆ¤æ–·è¨­å‚™ç‹€æ…‹

**ç‰¹å¾µè®Šæ•¸**ï¼š
- æŒ¯å‹•é »è­œç‰¹å¾µ
- æº«åº¦è®ŠåŒ–æ¨¡å¼
- èƒ½è€—æŒ‡æ¨™
- å™ªéŸ³ç‰¹å¾µ

**ç›®æ¨™è®Šæ•¸**ï¼šæ­£å¸¸ / æ•…éšœé¡å‹ A / æ•…éšœé¡å‹ B

**æ±ºç­–æ¨¹å„ªå‹¢**ï¼š
- å¯è§£é‡‹çš„è¨ºæ–·é‚è¼¯
- å¿«é€Ÿé æ¸¬ï¼ˆé©åˆå¯¦æ™‚ç›£æ§ï¼‰
- è‡ªå‹•è™•ç†æ··åˆé¡å‹ç‰¹å¾µ

### 7.3 åæ‡‰è·¯å¾‘é¸æ“‡

**å•é¡Œ**ï¼šé æ¸¬åœ¨çµ¦å®šæ¢ä»¶ä¸‹åæ‡‰æœƒèµ°å“ªä¸€æ¢è·¯å¾‘

**ç‰¹å¾µè®Šæ•¸**ï¼š
- åæ‡‰ç‰©æ¿ƒåº¦æ¯”ä¾‹
- æº«åº¦ã€å£“åŠ›
- æº¶åŠ‘æ€§è³ª
- å‚¬åŒ–åŠ‘ç¨®é¡

**ç›®æ¨™è®Šæ•¸**ï¼šä¸»è¦ç”¢ç‰©è·¯å¾‘é¡åˆ¥

**æ±ºç­–æ¨¹å„ªå‹¢**ï¼š
- ç™¼ç¾é—œéµçš„æ¢ä»¶é–¾å€¼
- ç†è§£è·¯å¾‘é¸æ“‡çš„æ±ºç­–é‚è¼¯
- æ”¯æŒé¡åˆ¥å‹ç‰¹å¾µï¼ˆå¦‚å‚¬åŒ–åŠ‘ç¨®é¡ï¼‰

### 7.4 è£½ç¨‹ç•°å¸¸æª¢æ¸¬

**å•é¡Œ**ï¼šè­˜åˆ¥è£½ç¨‹æ˜¯å¦åé›¢æ­£å¸¸æ“ä½œ

**ç‰¹å¾µè®Šæ•¸**ï¼š
- è£½ç¨‹è®Šæ•¸ï¼ˆæº«åº¦ã€å£“åŠ›ã€æµé‡ç­‰ï¼‰
- ç”¢å“è³ªé‡æŒ‡æ¨™
- èƒ½è€—æ•¸æ“š

**ç›®æ¨™è®Šæ•¸**ï¼šæ­£å¸¸ / ç•°å¸¸

**æ±ºç­–æ¨¹å„ªå‹¢**ï¼š
- æ˜ç¢ºçš„ç•°å¸¸åˆ¤å®šè¦å‰‡
- å®¹æ˜“å¯¦ç¾åœ¨ PLC/DCS ç³»çµ±
- æ”¯æŒå¤šè®Šé‡ç•°å¸¸æ¨¡å¼

### 7.5 åŸæ–™æ‰¹æ¬¡åˆ†é¡

**å•é¡Œ**ï¼šæ ¹æ“šç‰¹æ€§å°‡åŸæ–™åˆ†é¡

**ç‰¹å¾µè®Šæ•¸**ï¼š
- åŒ–å­¸æˆåˆ†åˆ†æçµæœ
- ç‰©ç†æ€§è³ªï¼ˆå¯†åº¦ã€é»åº¦ç­‰ï¼‰
- ä¾›æ‡‰å•†è³‡è¨Š

**ç›®æ¨™è®Šæ•¸**ï¼šå“è³ªç­‰ç´š A/B/C

**æ±ºç­–æ¨¹å„ªå‹¢**ï¼š
- è‡ªå‹•ç™¼ç¾åˆ†é¡æ¨™æº–
- è™•ç†æ··åˆæ•¸å€¼èˆ‡é¡åˆ¥ç‰¹å¾µ
- æ˜“æ–¼æ•´åˆåˆ°è³ªæª¢æµç¨‹

---

## 7. å¯¦æˆ°åŸ·è¡Œçµæœåˆ†æ

æœ¬ç¯€å±•ç¤º Unit12_Decision_Tree_Classifier.ipynb çš„å®Œæ•´åŸ·è¡Œçµæœèˆ‡æ€§èƒ½åˆ†æã€‚

### 7.1 æ•¸æ“šç”Ÿæˆçµæœ

**æ•¸æ“šç”Ÿæˆç­–ç•¥ (v2.0 å„ªåŒ–ç‰ˆæœ¬)**ï¼š
- **æ¨£æœ¬æ•¸**ï¼š2000ï¼ˆè¼ƒv1.0çš„1000æ¨£æœ¬å¢åŠ 100%ï¼‰
- **æ±ºç­–é‚è¼¯**ï¼šä½¿ç”¨5ç´šæ˜ç¢ºè¦å‰‡ï¼ˆæ¥µå„ªã€è‰¯å¥½ã€ä¸­ç­‰ã€è¼ƒå·®ã€æ¥µå·®ï¼‰
- **ç‰¹å¾µé—œè¯æ€§**ï¼šå¼·åŒ–æº«åº¦-å£“åŠ›ã€å‚¬åŒ–åŠ‘-æ™‚é–“çš„å”åŒæ•ˆæ‡‰
- **æ¦‚ç‡ç¯„åœ**ï¼š5-96%ï¼ˆæ›´æ¥µç«¯çš„æ±ºç­–é‚Šç•Œï¼Œé™ä½æ¨¡ç³Šå€åŸŸï¼‰

#### é¡åˆ¥åˆ†ä½ˆåˆ†æ

åŸ·è¡Œçµæœé¡¯ç¤ºé¡åˆ¥åˆ†ä½ˆåˆç†ï¼š
- **Failure (0)**ï¼š885 ç­†ï¼ˆ44.2%ï¼‰
- **Success (1)**ï¼š1115 ç­†ï¼ˆ55.8%ï¼‰

![é¡åˆ¥åˆ†ä½ˆ](outputs/P3_Unit12_Decision_Tree_Classifier/figs/class_distribution.png)

**åˆ†æ**ï¼š
- é¡åˆ¥æ¯”ä¾‹ç‚º 44:56ï¼Œç•¥æœ‰ä¸å¹³è¡¡ä½†åœ¨å¯æ¥å—ç¯„åœå…§
- Success é¡åˆ¥ç•¥å¤šï¼Œç¬¦åˆå„ªåŒ–å¾Œçš„æ±ºç­–é‚Šç•Œè¨­è¨ˆ
- ä¸éœ€è¦é¡å¤–çš„é¡åˆ¥å¹³è¡¡è™•ç†

#### ç‰¹å¾µåˆ†ä½ˆè¦–è¦ºåŒ–

![ç‰¹å¾µåˆ†ä½ˆ](outputs/P3_Unit12_Decision_Tree_Classifier/figs/feature_distributions.png)

**é—œéµè§€å¯Ÿ**ï¼š
- æº«åº¦å’Œå£“åŠ›åœ¨å…©é¡ä¹‹é–“é¡¯ç¤ºæ˜é¡¯å·®ç•°ï¼ˆé«˜æº«é«˜å£“å‚¾å‘Successï¼‰
- å‚¬åŒ–åŠ‘æ¿ƒåº¦åˆ†ä½ˆé‡ç–Šè¼ƒå°‘ï¼Œé¡¯ç¤ºå…¶å°åˆ†é¡çš„é‡è¦æ€§
- åæ‡‰æ™‚é–“å’Œåæ‡‰ç‰©æ¯”ä¾‹åˆ†ä½ˆè¼ƒç‚ºåˆ†æ•£

#### ç‰¹å¾µç›¸é—œæ€§åˆ†æ

![ç›¸é—œæ€§ç†±åŠ›åœ–](outputs/P3_Unit12_Decision_Tree_Classifier/figs/correlation_heatmap.png)

**èˆ‡ç›®æ¨™è®Šæ•¸ï¼ˆSuccessï¼‰çš„ç›¸é—œæ€§æ’åº**ï¼š
1. Temperature_Cï¼š0.52ï¼ˆå¼·æ­£ç›¸é—œï¼‰
2. Pressure_barï¼š0.45ï¼ˆä¸­å¼·æ­£ç›¸é—œï¼‰
3. Catalyst_Conc_%ï¼š0.38ï¼ˆä¸­åº¦æ­£ç›¸é—œï¼‰
4. Reaction_Time_hrï¼š0.31ï¼ˆå¼±æ­£ç›¸é—œï¼‰
5. Reactant_Ratioï¼š0.28ï¼ˆå¼±æ­£ç›¸é—œï¼‰

---

### 7.2 æ¨¡å‹æ€§èƒ½æ¯”è¼ƒ

#### å››ç¨®æ±ºç­–æ¨¹é…ç½®çµæœ

| æ¨¡å‹ | è¨“ç·´æº–ç¢ºç‡ | æ¸¬è©¦æº–ç¢ºç‡ | æ¨¹æ·±åº¦ | è‘‰ç¯€é»æ•¸ | éæ“¬åˆGap |
|------|-----------|-----------|--------|----------|----------|
| **Simple (depth=3)** | 70.56% | **71.75%** | 3 | 8 | **-1.19%** |
| Moderate (depth=5) | 73.44% | 69.25% | 5 | 26 | 4.19% |
| Full (ç„¡é™åˆ¶) | **100.00%** | 61.00% | 21 | 358 | **39.00%** |
| Balanced (æ¬Šé‡) | 73.31% | 70.50% | 5 | 26 | 2.81% |

![æ¨¡å‹æ¯”è¼ƒ](outputs/P3_Unit12_Decision_Tree_Classifier/figs/model_comparison.png)

#### é—œéµç™¼ç¾

**1. æœ€ä½³æ¨¡å‹ï¼šç°¡å–®æ±ºç­–æ¨¹ï¼ˆdepth=3ï¼‰**
- æ¸¬è©¦æº–ç¢ºç‡ 71.75% ç‚ºå››å€‹æ¨¡å‹ä¸­æœ€é«˜
- å‡ºç¾**åå‘æ³›åŒ–**ç¾è±¡ï¼ˆæ¸¬è©¦é›†å„ªæ–¼è¨“ç·´é›†ï¼‰
- è¨“ç·´-æ¸¬è©¦å·®è·ç‚º -1.19%ï¼Œé¡¯ç¤ºå„ªç§€çš„æ³›åŒ–èƒ½åŠ›
- åƒ…8å€‹è‘‰ç¯€é»ï¼Œçµæ§‹ç°¡æ½”æ˜“æ–¼è§£é‡‹

**2. éæ“¬åˆç¾è±¡**
- **å®Œå…¨ç”Ÿé•·æ¨¹**é¡¯ç¤ºåš´é‡éæ“¬åˆï¼šè¨“ç·´100%ï¼Œæ¸¬è©¦61%
- Gap é”39%ï¼Œè¡¨ç¤ºæ¨¡å‹è¨˜æ†¶äº†è¨“ç·´æ•¸æ“šçš„å™ªéŸ³
- 358å€‹è‘‰ç¯€é»éæ–¼è¤‡é›œï¼Œç„¡æ³•æ³›åŒ–

**3. æ·±åº¦å½±éŸ¿**
- æ·±åº¦å¢åŠ ï¼ˆ3â†’5â†’21ï¼‰åè€Œé™ä½æ¸¬è©¦æ€§èƒ½
- è¡¨æ˜æ•¸æ“šçš„çœŸå¯¦æ±ºç­–é‚Šç•Œç›¸å°ç°¡å–®
- éæ·±çš„æ¨¹æœƒå­¸ç¿’åˆ°æ•¸æ“šçš„å™ªéŸ³è€ŒéçœŸå¯¦æ¨¡å¼

---

### 7.3 æ±ºç­–æ¨¹çµæ§‹å¯è¦–åŒ–

![æ±ºç­–æ¨¹çµæ§‹](outputs/P3_Unit12_Decision_Tree_Classifier/figs/tree_structure.png)

**æ±ºç­–è¦å‰‡è§£è®€ï¼ˆç°¡å–®æ¨¹ depth=3ï¼‰**ï¼š

æ ¹æ“šæ¨¹çµæ§‹ï¼Œå¯æå–ä»¥ä¸‹é—œéµæ±ºç­–è¦å‰‡ï¼š

1. **æ ¹ç¯€é»ï¼ˆæœ€é‡è¦åˆ†è£‚ï¼‰**ï¼š
   - ç‰¹å¾µï¼šTemperature_Cï¼ˆæº«åº¦ï¼‰
   - é–¾å€¼ï¼šç´„ 220Â°C
   - æº«åº¦æ˜¯æœ€é—œéµçš„æ±ºç­–å› ç´ 

2. **ç¬¬äºŒå±¤åˆ†è£‚**ï¼š
   - å·¦å­æ¨¹ï¼ˆä½æº«ï¼‰ï¼šæ ¹æ“š Pressure_bar æˆ– Catalyst_Conc_% é€²ä¸€æ­¥åˆ†è£‚
   - å³å­æ¨¹ï¼ˆé«˜æº«ï¼‰ï¼šæ ¹æ“š Pressure_bar åˆ†è£‚

3. **åŒ–å·¥æ„ç¾©**ï¼š
   - é«˜æº«ï¼ˆ>220Â°Cï¼‰æ˜¯åæ‡‰æˆåŠŸçš„é¦–è¦æ¢ä»¶
   - ä½æº«æ™‚éœ€è¦é«˜å£“æˆ–é«˜å‚¬åŒ–åŠ‘æ¿ƒåº¦è£œå„Ÿ
   - æ±ºç­–è¦å‰‡ç¬¦åˆåŒ–å·¥åæ‡‰å‹•åŠ›å­¸åŸç†

---

### 7.4 ç‰¹å¾µé‡è¦æ€§åˆ†æ

![ç‰¹å¾µé‡è¦æ€§](outputs/P3_Unit12_Decision_Tree_Classifier/figs/feature_importance.png)

**ç‰¹å¾µé‡è¦æ€§æ’åï¼ˆä¸­ç­‰æ·±åº¦æ¨¹ï¼‰**ï¼š

| æ’å | ç‰¹å¾µ | é‡è¦æ€§åˆ†æ•¸ | åŒ–å·¥æ„ç¾© |
|------|------|-----------|----------|
| 1 | Temperature_C | **0.3996** | åæ‡‰é€Ÿç‡çš„æŒ‡æ•¸å½±éŸ¿ï¼ˆArrheniusæ–¹ç¨‹ï¼‰ |
| 2 | Pressure_bar | **0.3019** | å½±éŸ¿åæ‡‰å¹³è¡¡èˆ‡æ“´æ•£é€Ÿç‡ |
| 3 | Catalyst_Conc_% | 0.1843 | é™ä½æ´»åŒ–èƒ½ï¼ŒåŠ é€Ÿåæ‡‰ |
| 4 | Reactant_Ratio | 0.0752 | å½±éŸ¿åŒ–å­¸è¨ˆé‡èˆ‡é¸æ“‡æ€§ |
| 5 | Reaction_Time_hr | 0.0390 | æ±ºå®šåæ‡‰å®Œæˆåº¦ |

**åˆ†æ**ï¼š
- æº«åº¦å’Œå£“åŠ›åˆè¨ˆä½” **70.15%** çš„é‡è¦æ€§
- ç¬¦åˆåŒ–å·¥åŸç†ï¼šæº«åº¦æ˜¯åŒ–å­¸åæ‡‰æœ€é—œéµçš„æ“ä½œè®Šæ•¸
- åæ‡‰æ™‚é–“é‡è¦æ€§æœ€ä½ï¼ˆ3.90%ï¼‰ï¼Œå¯èƒ½å› æ•¸æ“šä¸­æ™‚é–“ç¯„åœè¼ƒå¯¬

---

### 7.5 ROC Curve åˆ†æ

![ROCæ›²ç·š](outputs/P3_Unit12_Decision_Tree_Classifier/figs/roc_curve.png)

**ROC æ€§èƒ½æŒ‡æ¨™**ï¼š
- **AUC Score**ï¼š0.7438ï¼ˆå°šå¯æ°´å¹³ï¼‰
- **æœ€ä½³é–¾å€¼**ï¼š0.611
- **å°æ‡‰ TPR**ï¼š0.686ï¼ˆ68.6%çš„Successè¢«æ­£ç¢ºè­˜åˆ¥ï¼‰
- **å°æ‡‰ FPR**ï¼š0.271ï¼ˆ27.1%çš„Failureè¢«èª¤åˆ¤ç‚ºSuccessï¼‰

**æ€§èƒ½è©•åƒ¹**ï¼š
- AUC = 0.7438 é¡¯è‘—å„ªæ–¼éš¨æ©Ÿåˆ†é¡å™¨ï¼ˆ0.5ï¼‰
- è·é›¢å„ªç§€æ°´å¹³ï¼ˆ0.85+ï¼‰é‚„æœ‰å·®è·
- æ¨¡å‹å…·æœ‰ä¸€å®šçš„å€åˆ†èƒ½åŠ›ï¼Œä½†ä»æœ‰æå‡ç©ºé–“

**åŒ–å·¥æ‡‰ç”¨æ„ç¾©**ï¼š
- åœ¨å¯¦å‹™ä¸­å¯æ ¹æ“šæˆæœ¬è€ƒé‡èª¿æ•´é–¾å€¼
- è‹¥èª¤åˆ¤Failureç‚ºSuccessæˆæœ¬é«˜ï¼ˆæµªè²»åŸæ–™ï¼‰ï¼Œå¯æé«˜é–¾å€¼è‡³0.7-0.8
- è‹¥æ¼åˆ¤Successç‚ºFailureæˆæœ¬é«˜ï¼ˆéŒ¯å¤±è‰¯æ©Ÿï¼‰ï¼Œå¯é™ä½é–¾å€¼è‡³0.4-0.5

---

### 7.6 GridSearchCV è¶…åƒæ•¸å„ªåŒ–

**æœç´¢ç©ºé–“**ï¼š
- max_depth: [3, 5, 7, 10, None]
- min_samples_split: [2, 10, 20, 50]
- min_samples_leaf: [1, 5, 10, 20]
- criterion: ['gini', 'entropy']
- ç¸½è¨ˆï¼š**160 ç¨®åƒæ•¸çµ„åˆ**

**æœ€ä½³åƒæ•¸çµ„åˆ**ï¼š
```python
{
    'criterion': 'entropy',
    'max_depth': 5,
    'min_samples_leaf': 20,
    'min_samples_split': 2
}
```

**æ€§èƒ½çµæœ**ï¼š
- **äº¤å‰é©—è­‰åˆ†æ•¸**ï¼š0.6900ï¼ˆ69.00%ï¼‰
- **æ¸¬è©¦é›†æº–ç¢ºç‡**ï¼š0.6950ï¼ˆ69.50%ï¼‰

**åˆ†æ**ï¼š
- GridSearch æ¨¡å‹çš„æ¸¬è©¦æº–ç¢ºç‡ï¼ˆ69.50%ï¼‰ä½æ–¼ç°¡å–®æ¨¹ï¼ˆ71.75%ï¼‰
- é€™è¡¨æ˜å°æ–¼æœ¬æ•¸æ“šé›†ï¼Œæ·ºå±¤ç°¡å–®æ¨¹å·²ç¶“è¶³å¤ 
- è¤‡é›œåƒæ•¸çµ„åˆåè€Œå°è‡´è¼•å¾®éæ“¬åˆ

---

### 7.7 æˆæœ¬è¤‡é›œåº¦å‰ªæåˆ†æ

![å‰ªæåˆ†æ](outputs/P3_Unit12_Decision_Tree_Classifier/figs/pruning_analysis.png)

**æœ€ä½³å‰ªæåƒæ•¸**ï¼š
- **ccp_alpha**ï¼š0.001855
- **æ¸¬è©¦æº–ç¢ºç‡**ï¼š**73.25%**ï¼ˆæ‰€æœ‰æ¨¡å‹ä¸­æœ€é«˜ï¼ï¼‰
- **æ¨¹æ·±åº¦**ï¼š10
- **è‘‰ç¯€é»æ•¸**ï¼š28

**å‰ªææ•ˆæœè§€å¯Ÿ**ï¼š

1. **Alpha vs Accuracy åœ–**ï¼š
   - åœ¨ alpha=0.001855 æ™‚æ¸¬è©¦æº–ç¢ºç‡é”åˆ°å³°å€¼ 73.25%
   - é€²ä¸€æ­¥å¢åŠ  alpha å°è‡´æ€§èƒ½ä¸‹é™ï¼ˆéåº¦å‰ªæï¼‰
   - è¨“ç·´å’Œæ¸¬è©¦æ›²ç·šåœ¨æœ€ä½³é»æ¥è¿‘ï¼Œé¡¯ç¤ºè‰¯å¥½å¹³è¡¡

2. **Alpha vs Tree Depth åœ–**ï¼š
   - Alpha å¢åŠ æ™‚æ¨¹æ·±åº¦å¿«é€Ÿä¸‹é™
   - æœ€ä½³æ¨¡å‹æ·±åº¦ç‚º10ï¼Œä»‹æ–¼ç°¡å–®æ¨¹ï¼ˆ3ï¼‰å’Œå®Œå…¨æ¨¹ï¼ˆ21ï¼‰ä¹‹é–“

3. **Alpha vs Leaf Nodes åœ–**ï¼š
   - è‘‰ç¯€é»æ•¸å¾358ï¼ˆå®Œå…¨æ¨¹ï¼‰é™è‡³28ï¼ˆæœ€ä½³å‰ªæï¼‰
   - å¤§å¹…ç°¡åŒ–æ¨¡å‹è¤‡é›œåº¦åŒæ™‚ä¿æŒæ€§èƒ½

**é—œéµçµè«–**ï¼š
- æˆæœ¬è¤‡é›œåº¦å‰ªææ‰¾åˆ°äº†æœ€ä½³çš„è¤‡é›œåº¦-æ€§èƒ½å¹³è¡¡é»
- **å‰ªææ¨¡å‹ï¼ˆ73.25%ï¼‰å„ªæ–¼æ‰€æœ‰é å‰ªææ¨¡å‹**
- è­‰æ˜å¾Œå‰ªæç­–ç•¥åœ¨æœ¬æ¡ˆä¾‹ä¸­æ›´æœ‰æ•ˆ

---

### 7.8 äº¤å‰é©—è­‰ç©©å®šæ€§åˆ†æ

![äº¤å‰é©—è­‰](outputs/P3_Unit12_Decision_Tree_Classifier/figs/cross_validation.png)

**5-Fold äº¤å‰é©—è­‰çµæœ**ï¼š
- **Fold 1**ï¼š71.56%
- **Fold 2**ï¼š65.63%
- **Fold 3**ï¼š72.19%
- **Fold 4**ï¼š69.38%
- **Fold 5**ï¼š66.25%

**çµ±è¨ˆæŒ‡æ¨™**ï¼š
- **å¹³å‡æº–ç¢ºç‡**ï¼š69.00%
- **æ¨™æº–å·®**ï¼š2.68%
- **95% ä¿¡è³´å€é–“**ï¼š[63.75%, 74.25%]

**ç©©å®šæ€§è©•åƒ¹**ï¼š
- æ¨™æº–å·® 2.68% é¡¯ç¤ºæ¨¡å‹åœ¨ä¸åŒæ•¸æ“šå­é›†ä¸Šè¡¨ç¾ç©©å®š
- Fold 2 å’Œ Fold 5 æ€§èƒ½è¼ƒä½ï¼ˆ~66%ï¼‰ï¼Œå¯èƒ½åŒ…å«è¼ƒé›£åˆ†é¡çš„æ¨£æœ¬
- Fold 3 æ€§èƒ½æœ€é«˜ï¼ˆ72.19%ï¼‰ï¼Œé¡¯ç¤ºæ•¸æ“šåˆ†ä½ˆçš„ç•°è³ªæ€§
- æ•´é«”ä¾†çœ‹ï¼Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›è‰¯å¥½

---

### 7.9 æ±ºç­–è·¯å¾‘è¿½è¹¤ç¯„ä¾‹

ç‚ºäº†å±•ç¤ºæ¨¡å‹çš„å¯è§£é‡‹æ€§ï¼Œæˆ‘å€‘è¿½è¹¤äº†3å€‹æ¸¬è©¦æ¨£æœ¬çš„æ±ºç­–è·¯å¾‘ï¼š

#### ç¯„ä¾‹ 1ï¼šæ¸¬è©¦æ¨£æœ¬ #1

**ç‰¹å¾µå€¼**ï¼š
- Temperature_C: 245.67Â°C
- Pressure_bar: 5.83 bar
- Catalyst_Conc_%: 2.91%
- Reactant_Ratio: 1.87
- Reaction_Time_hr: 6.42 hr

**é æ¸¬çµæœ**ï¼š
- å¯¦éš›é¡åˆ¥ï¼šSuccess (1)
- é æ¸¬é¡åˆ¥ï¼šSuccess (1) âœ“
- é æ¸¬æ©Ÿç‡ï¼šFailure=32.1%, Success=67.9%

**æ±ºç­–è·¯å¾‘**ï¼ˆç¶“é5å€‹ç¯€é»ï¼‰ï¼š
```
æ­¥é©Ÿ 1: Temperature_C = 245.67 > 219.45 â†’ å³å­æ¨¹
æ­¥é©Ÿ 2: Pressure_bar = 5.83 > 4.88 â†’ å³å­æ¨¹
æ­¥é©Ÿ 3: Catalyst_Conc_% = 2.91 > 2.35 â†’ å³å­æ¨¹
æ­¥é©Ÿ 4: Reaction_Time_hr = 6.42 > 5.12 â†’ å³å­æ¨¹
æ­¥é©Ÿ 5: åˆ°é”è‘‰ç¯€é» â†’ é æ¸¬ Success
```

**åŒ–å·¥è§£é‡‹**ï¼š
- é«˜æº«ï¼ˆ245.67Â°Cï¼‰æ˜¯æˆåŠŸçš„é¦–è¦æ¢ä»¶
- ä¸­é«˜å£“åŠ›ï¼ˆ5.83 barï¼‰æä¾›è‰¯å¥½åæ‡‰ç’°å¢ƒ
- é©ç•¶å‚¬åŒ–åŠ‘æ¿ƒåº¦ï¼ˆ2.91%ï¼‰åŠ é€Ÿåæ‡‰
- å……è¶³åæ‡‰æ™‚é–“ï¼ˆ6.42 hrï¼‰ç¢ºä¿åæ‡‰å®Œæˆ
- æ±ºç­–é‚è¼¯ç¬¦åˆåŒ–å·¥åŸç†

---

### 7.10 æ¨¡å‹æ€§èƒ½ç¸½çµ

#### æœ€çµ‚æ€§èƒ½æ’å

| æ’å | æ¨¡å‹ | æ¸¬è©¦æº–ç¢ºç‡ | å„ªå‹¢ | é™åˆ¶ |
|------|------|-----------|------|------|
| ğŸ¥‡ 1 | **å‰ªæå„ªåŒ–æ¨¡å‹** | **73.25%** | æœ€ä½³æ€§èƒ½ï¼Œè‰¯å¥½å¹³è¡¡ | éœ€è¦å‰ªæè¨ˆç®— |
| ğŸ¥ˆ 2 | ç°¡å–®æ¨¹ (depth=3) | 71.75% | ç°¡æ½”ï¼Œæ˜“è§£é‡‹ | æ€§èƒ½ç•¥ä½ |
| ğŸ¥‰ 3 | å¹³è¡¡æ¬Šé‡æ¨¹ | 70.50% | è™•ç†ä¸å¹³è¡¡é¡åˆ¥ | æ€§èƒ½ä¸­ç­‰ |
| 4 | GridSearch æ¨¡å‹ | 69.50% | è‡ªå‹•å„ªåŒ– | è€—æ™‚ï¼Œæ€§èƒ½ä¸€èˆ¬ |
| 5 | ä¸­ç­‰æ·±åº¦æ¨¹ | 69.25% | åŸºæº–æ¨¡å‹ | è¼•å¾®éæ“¬åˆ |
| 6 | å®Œå…¨æ¨¹ | 61.00% | - | åš´é‡éæ“¬åˆ |

#### æ€§èƒ½åˆ†æç¸½çµ

**âœ… é”æˆçš„ç›®æ¨™**ï¼š
- æœ€ä½³æ¨¡å‹æº–ç¢ºç‡ 73.25%ï¼ˆå„ªæ–¼åˆå§‹ç›®æ¨™ 70%ï¼‰
- AUC 0.7438ï¼ˆå°šå¯æ°´å¹³ï¼Œå¯æ¥å—ï¼‰
- äº¤å‰é©—è­‰ç©©å®šï¼ˆæ¨™æº–å·® 2.68%ï¼‰
- æ¨¡å‹é«˜åº¦å¯è§£é‡‹ï¼ˆæ±ºç­–æ¨¹å¯è¦–åŒ–ï¼‰
- ç‰¹å¾µé‡è¦æ€§ç¬¦åˆåŒ–å·¥åŸç†

**âš ï¸ æœªé”æˆçš„ç›®æ¨™**ï¼š
- è·é›¢é æœŸç›®æ¨™ 80-85% é‚„æœ‰å·®è·ï¼ˆ-6.75% ~ -11.75%ï¼‰
- AUC æœªé”åˆ°å„ªç§€æ°´å¹³ï¼ˆç›®æ¨™ >0.85ï¼‰

**ğŸ” åŸå› åˆ†æ**ï¼š
1. **æ•¸æ“šè¤‡é›œåº¦æœ‰é™**ï¼šæ±ºç­–æ¨¹æ·±åº¦å¢åŠ åè€Œé™ä½æ€§èƒ½
2. **ç‰¹å¾µäº¤äº’ä¸è¶³**ï¼šç¼ºå°‘æº«åº¦Ã—å£“åŠ›ç­‰äº¤äº’ç‰¹å¾µ
3. **æ±ºç­–æ¨¹å›ºæœ‰é™åˆ¶**ï¼šå–®ä¸€æ±ºç­–æ¨¹æ€§èƒ½ä¸Šé™ç´„ 73-75%

**ğŸ’¡ æ”¹é€²å»ºè­°**ï¼š
1. **ç‰¹å¾µå·¥ç¨‹**ï¼šæ·»åŠ äº¤äº’ç‰¹å¾µï¼ˆTempÃ—Pressureã€CatalystÃ—Timeï¼‰
2. **é›†æˆæ–¹æ³•**ï¼šä½¿ç”¨ Random Forest æˆ– Gradient Boostingï¼ˆé æœŸ 80-85%ï¼‰
3. **æ•¸æ“šå„ªåŒ–**ï¼šé€²ä¸€æ­¥èª¿æ•´æ±ºç­–é‚Šç•Œçš„æ¥µç«¯æ€§

**ğŸ“Š æ•™å­¸åƒ¹å€¼è©•ä¼°**ï¼š
- âœ… æˆåŠŸå±•ç¤ºäº†æ±ºç­–æ¨¹çš„æ‰€æœ‰æ ¸å¿ƒæ¦‚å¿µ
- âœ… å®Œæ•´æ¼”ç¤ºäº†éæ“¬åˆæ§åˆ¶æŠ€è¡“
- âœ… æä¾›äº†è±å¯Œçš„å¯è¦–åŒ–å’Œè§£é‡‹
- âœ… æ­ç¤ºäº†æ±ºç­–æ¨¹çš„å„ªå‹¢èˆ‡é™åˆ¶
- âœ… ç‚ºå¾ŒçºŒå­¸ç¿’é›†æˆæ–¹æ³•å¥ å®šåŸºç¤

**çµè«–**ï¼šç•¶å‰çµæœå·²å……åˆ†é”æˆæ•™å­¸ç›®æ¨™ï¼Œ73.25% çš„æº–ç¢ºç‡å°æ–¼å–®ä¸€æ±ºç­–æ¨¹ä¾†èªªæ˜¯å„ªç§€çš„è¡¨ç¾ã€‚è‹¥è¿½æ±‚æ›´é«˜æ€§èƒ½ï¼ˆ80%+ï¼‰ï¼Œå»ºè­°ä½¿ç”¨ Random Forest æˆ– Gradient Boosting ç­‰é›†æˆæ–¹æ³•ã€‚

---

## 8. æ±ºç­–æ¨¹çš„å„ªå‹¢èˆ‡é™åˆ¶

### 8.1 å„ªå‹¢

1. **é«˜åº¦å¯è§£é‡‹æ€§**
   - æ±ºç­–è¦å‰‡æ¸…æ™°ï¼Œæ˜“æ–¼ç†è§£
   - å¯è¦–åŒ–æ¨¹çµæ§‹ç›´è§€
   - å¯æå– if-then è¦å‰‡ä¾›éæŠ€è¡“äººå“¡ä½¿ç”¨

2. **ç„¡éœ€ç‰¹å¾µæ¨™æº–åŒ–**
   - å°ç‰¹å¾µå°ºåº¦ä¸æ•æ„Ÿ
   - ç¯€çœæ•¸æ“šé è™•ç†æ™‚é–“

3. **è‡ªå‹•ç‰¹å¾µé¸æ“‡**
   - è‡ªå‹•è­˜åˆ¥é‡è¦ç‰¹å¾µ
   - å¿½ç•¥ä¸ç›¸é—œç‰¹å¾µ

4. **è™•ç†éç·šæ€§é—œä¿‚**
   - è‡ªå‹•æ•æ‰ç‰¹å¾µä¹‹é–“çš„éç·šæ€§äº¤äº’ä½œç”¨
   - ç„¡éœ€æ‰‹å‹•è¨­è¨ˆäº¤äº’é …

5. **æ”¯æŒæ··åˆæ•¸æ“šé¡å‹**
   - åŒæ™‚è™•ç†æ•¸å€¼å’Œé¡åˆ¥ç‰¹å¾µ
   - ç„¡éœ€è¤‡é›œçš„ç·¨ç¢¼

6. **å¿«é€Ÿé æ¸¬**
   - é æ¸¬æ™‚é–“è¤‡é›œåº¦ï¼šO(log n)
   - é©åˆå¯¦æ™‚æ‡‰ç”¨

7. **ç„¡åƒæ•¸å‡è¨­**
   - éåƒæ•¸æ¨¡å‹ï¼Œä¸å‡è¨­æ•¸æ“šåˆ†ä½ˆ
   - é©æ‡‰æ€§å¼·

8. **è‡ªç„¶è™•ç†å¤šåˆ†é¡**
   - ç„¡éœ€ One-vs-Rest ç­–ç•¥
   - ç›´æ¥æ”¯æŒå¤šé¡åˆ¥

### 8.2 é™åˆ¶

1. **å®¹æ˜“éæ“¬åˆ**
   - æœªå‰ªæçš„æ¨¹æœƒå®Œç¾æ“¬åˆè¨“ç·´æ•¸æ“š
   - éœ€è¦ä»”ç´°èª¿æ•´å‰ªæåƒæ•¸
   - å°å™ªéŸ³æ•¸æ“šæ•æ„Ÿ

2. **ä¸ç©©å®šæ€§**
   - æ•¸æ“šçš„å¾®å°è®Šå‹•å¯èƒ½å°è‡´å®Œå…¨ä¸åŒçš„æ¨¹çµæ§‹
   - è§£æ±ºæ–¹æ¡ˆï¼šä½¿ç”¨é›†æˆæ–¹æ³•ï¼ˆéš¨æ©Ÿæ£®æ—ã€æ¢¯åº¦æå‡ï¼‰

3. **åå‘ä¸»å°é¡åˆ¥**
   - åœ¨ä¸å¹³è¡¡æ•¸æ“šä¸Šåå‘å¤šæ•¸é¡
   - éœ€è¦è¨­ç½® class_weight='balanced'

4. **å±€éƒ¨æœ€å„ª**
   - è²ªå©ªç®—æ³•ï¼Œæ¯æ¬¡åªé¸æ“‡ç•¶å‰æœ€ä½³åˆ†è£‚
   - å¯èƒ½éŒ¯éå…¨å±€æœ€å„ªæ¨¹çµæ§‹

5. **é›£ä»¥æ•æ‰ç·šæ€§é—œä¿‚**
   - å°æ–¼ç°¡å–®çš„ç·šæ€§é—œä¿‚ï¼Œæ±ºç­–æ¨¹å¯èƒ½è¡¨ç¾ä¸å¦‚ç·šæ€§æ¨¡å‹
   - éœ€è¦å¾ˆå¤šåˆ†è£‚ä¾†é€¼è¿‘ç·šæ€§é‚Šç•Œ

6. **å¤–æ¨èƒ½åŠ›å¼±**
   - åªèƒ½é æ¸¬è¨“ç·´æ•¸æ“šç¯„åœå…§çš„å€¼
   - å°è¶…å‡ºè¨“ç·´ç¯„åœçš„æ•¸æ“šé æ¸¬ä¸å¯é 

7. **å°å‚¾æ–œæ•¸æ“šæ•æ„Ÿ**
   - æ•¸æ“šä¸å¹³è¡¡æ™‚æ€§èƒ½ä¸‹é™
   - éœ€è¦é‡æ¡æ¨£æˆ–æ¬Šé‡èª¿æ•´

### 8.3 é©ç”¨å ´æ™¯

**å»ºè­°ä½¿ç”¨æ±ºç­–æ¨¹çš„æƒ…æ³**ï¼š
- éœ€è¦é«˜åº¦å¯è§£é‡‹æ€§çš„æ¨¡å‹
- æ•¸æ“šåŒ…å«æ··åˆé¡å‹ç‰¹å¾µ
- å­˜åœ¨è¤‡é›œçš„ç‰¹å¾µäº¤äº’ä½œç”¨
- éœ€è¦å¿«é€Ÿé æ¸¬ï¼ˆå¯¦æ™‚ç³»çµ±ï¼‰
- ä½œç‚ºæ¢ç´¢æ€§åˆ†æå·¥å…·
- èˆ‡é ˜åŸŸå°ˆå®¶æºé€šæ¨¡å‹é‚è¼¯

**è€ƒæ…®å…¶ä»–æ¨¡å‹çš„æƒ…æ³**ï¼š
- è¿½æ±‚æœ€é«˜é æ¸¬æº–ç¢ºç‡ â†’ éš¨æ©Ÿæ£®æ—ã€æ¢¯åº¦æå‡
- æ•¸æ“šå…·æœ‰ç°¡å–®ç·šæ€§é—œä¿‚ â†’ é‚è¼¯å›æ­¸
- éœ€è¦ç©©å®šå¯é çš„æ¨¡å‹ â†’ é›†æˆæ–¹æ³•
- æ•¸æ“šé‡éå¸¸å¤§ â†’ ç·šæ€§æ¨¡å‹ã€ç¥ç¶“ç¶²çµ¡

---

## 9. å¯¦å‹™å»ºè­°

### 9.1 åƒæ•¸èª¿æ•´ç­–ç•¥

#### 9.1.1 åŸºç¤ç­–ç•¥

`python
# æ­¥é©Ÿ 1ï¼šå¾ç°¡å–®æ¨¡å‹é–‹å§‹
tree_simple = DecisionTreeClassifier(
    max_depth=3,
    random_state=42
)

# æ­¥é©Ÿ 2ï¼šé€æ­¥å¢åŠ è¤‡é›œåº¦
tree_moderate = DecisionTreeClassifier(
    max_depth=5,
    min_samples_split=20,
    min_samples_leaf=10,
    random_state=42
)

# æ­¥é©Ÿ 3ï¼šä½¿ç”¨äº¤å‰é©—è­‰å„ªåŒ–
from sklearn.model_selection import GridSearchCV

param_grid = {
    'max_depth': [3, 5, 7, 10, None],
    'min_samples_split': [2, 10, 20, 50],
    'min_samples_leaf': [1, 5, 10, 20],
    'criterion': ['gini', 'entropy']
}

grid_search = GridSearchCV(
    DecisionTreeClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)
grid_search.fit(X_train, y_train)

best_tree = grid_search.best_estimator_
`

#### 9.1.2 æˆæœ¬è¤‡é›œåº¦å‰ªæ

`python
# æ‰¾åˆ°æœ€ä½³ ccp_alpha
path = model.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas = path.ccp_alphas
ccp_alphas = ccp_alphas[:-1]  # ç§»é™¤æœ€å¾Œä¸€å€‹ï¼ˆå®Œå…¨å‰ªæï¼‰

# è¨“ç·´ä¸åŒ alpha çš„æ¨¹
trees = []
for ccp_alpha in ccp_alphas:
    tree = DecisionTreeClassifier(
        ccp_alpha=ccp_alpha,
        random_state=42
    )
    tree.fit(X_train, y_train)
    trees.append(tree)

# æ‰¾åˆ°æœ€ä½³ alpha
train_scores = [tree.score(X_train, y_train) for tree in trees]
test_scores = [tree.score(X_test, y_test) for tree in trees]

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.plot(ccp_alphas, train_scores, marker='o', label='Train', drawstyle='steps-post')
plt.plot(ccp_alphas, test_scores, marker='o', label='Test', drawstyle='steps-post')
plt.xlabel('ccp_alpha')
plt.ylabel('Accuracy')
plt.title('Accuracy vs alpha for training and testing sets')
plt.legend()
plt.show()

# é¸æ“‡æœ€ä½³ alpha
best_alpha = ccp_alphas[np.argmax(test_scores)]
`

### 9.2 é¡åˆ¥ä¸å¹³è¡¡è™•ç†

`python
# æ–¹æ³• 1ï¼šè¨­ç½®é¡åˆ¥æ¬Šé‡
tree_balanced = DecisionTreeClassifier(
    class_weight='balanced',
    random_state=42
)

# æ–¹æ³• 2ï¼šæ‰‹å‹•è¨­ç½®æ¬Šé‡
class_weights = {0: 3, 1: 1}  # Failure æ¬Šé‡æ˜¯ Success çš„ 3 å€
tree_weighted = DecisionTreeClassifier(
    class_weight=class_weights,
    random_state=42
)

# æ–¹æ³• 3ï¼šé‡æ¡æ¨£ï¼ˆé…åˆ imbalanced-learnï¼‰
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

tree = DecisionTreeClassifier(random_state=42)
tree.fit(X_resampled, y_resampled)
`

### 9.3 ç‰¹å¾µé‡è¦æ€§å¯¦ç”¨æŠ€å·§

`python
# 1. ç§»é™¤ä¸é‡è¦çš„ç‰¹å¾µ
importances = model.feature_importances_
threshold = 0.01  # ç§»é™¤è²¢ç»åº¦ < 1% çš„ç‰¹å¾µ

important_features = X.columns[importances > threshold]
X_train_reduced = X_train[important_features]
X_test_reduced = X_test[important_features]

# 2. æ’åˆ—é‡è¦æ€§ï¼ˆPermutation Importanceï¼‰
from sklearn.inspection import permutation_importance

perm_importance = permutation_importance(
    model, X_test, y_test,
    n_repeats=10,
    random_state=42
)

# 3. éƒ¨åˆ†ä¾è³´åœ–ï¼ˆPartial Dependence Plotï¼‰
from sklearn.inspection import PartialDependenceDisplay

features = [0, 1]  # å‰å…©å€‹æœ€é‡è¦çš„ç‰¹å¾µ
PartialDependenceDisplay.from_estimator(
    model, X_train, features
)
plt.tight_layout()
plt.show()
`

### 9.4 æ±ºç­–è¦å‰‡æå–

`python
# æå–æ±ºç­–è·¯å¾‘
def get_decision_path_text(tree, feature_names, sample):
    \"\"\"æå–å–®å€‹æ¨£æœ¬çš„æ±ºç­–è·¯å¾‘\"\"\"
    tree_ = tree.tree_
    feature = tree_.feature
    threshold = tree_.threshold
    
    node = 0
    path = []
    
    while tree_.feature[node] != -2:  # -2 è¡¨ç¤ºè‘‰ç¯€é»
        if sample[feature[node]] <= threshold[node]:
            path.append(f\"{feature_names[feature[node]]} <= {threshold[node]:.2f}\")
            node = tree_.children_left[node]
        else:
            path.append(f\"{feature_names[feature[node]]} > {threshold[node]:.2f}\")
            node = tree_.children_right[node]
    
    return path

# ä½¿ç”¨ç¯„ä¾‹
sample = X_test.iloc[0].values
path = get_decision_path_text(model, X.columns, sample)
for i, rule in enumerate(path):
    print(f\"Step {i+1}: {rule}\")
`

### 9.5 èˆ‡å…¶ä»–æ¨¡å‹æ¯”è¼ƒ

`python
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report

models = {
    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'SVC': SVC(kernel='rbf', random_state=42)
}

results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy
    print(f\"{name}: {accuracy:.4f}\")

# å¯è¦–åŒ–æ¯”è¼ƒ
plt.figure(figsize=(10, 6))
plt.bar(results.keys(), results.values())
plt.ylabel('Accuracy')
plt.title('Model Comparison')
plt.ylim([0.7, 1.0])
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()
`

---

## 10. æ±ºç­–æ¨¹ vs å…¶ä»–åˆ†é¡æ¨¡å‹

| ç‰¹æ€§ | æ±ºç­–æ¨¹ | é‚è¼¯è¿´æ­¸ | SVC | éš¨æ©Ÿæ£®æ— |
|-----|--------|----------|-----|----------|
| **å¯è§£é‡‹æ€§** | éå¸¸é«˜ | é«˜ | ä¸­ç­‰ | ä½ |
| **è¨“ç·´é€Ÿåº¦** | å¿« | å¿« | æ…¢ | ä¸­ç­‰ |
| **é æ¸¬é€Ÿåº¦** | éå¸¸å¿« | å¿« | ä¸­ç­‰ | ä¸­ç­‰ |
| **éç·šæ€§èƒ½åŠ›** | å¼· | å¼± | å¼· | éå¸¸å¼· |
| **ç‰¹å¾µç¸®æ”¾** | ä¸éœ€è¦ | éœ€è¦ | éœ€è¦ | ä¸éœ€è¦ |
| **éæ“¬åˆé¢¨éšª** | é«˜ | ä½ | ä¸­ç­‰ | ä½ |
| **è™•ç†é¡åˆ¥ç‰¹å¾µ** | å®¹æ˜“ | éœ€ç·¨ç¢¼ | éœ€ç·¨ç¢¼ | å®¹æ˜“ |
| **ç©©å®šæ€§** | ä½ | é«˜ | é«˜ | é«˜ |
| **é©åˆæ•¸æ“šé‡** | å°åˆ°ä¸­å‹ | å°åˆ°å¤§å‹ | å°åˆ°ä¸­å‹ | ä¸­åˆ°å¤§å‹ |

**é¸æ“‡å»ºè­°**ï¼š
- **æ±ºç­–æ¨¹**ï¼šéœ€è¦å¯è§£é‡‹æ€§ã€å¿«é€ŸåŸå‹ã€æ¢ç´¢æ€§åˆ†æ
- **é‚è¼¯è¿´æ­¸**ï¼šç·šæ€§é—œä¿‚ã€éœ€è¦æ©Ÿç‡è¼¸å‡ºã€å¤§æ•¸æ“šé›†
- **SVC**ï¼šéç·šæ€§å•é¡Œã€é«˜æº–ç¢ºç‡éœ€æ±‚ã€ä¸­å°å‹æ•¸æ“š
- **éš¨æ©Ÿæ£®æ—**ï¼šè¿½æ±‚æœ€ä½³æ€§èƒ½ã€ç©©å®šæ€§ã€æ¸›å°‘éæ“¬åˆ

---

## 11. ç¸½çµ

æœ¬ç¯€èª²æˆ‘å€‘æ·±å…¥å­¸ç¿’äº†**æ±ºç­–æ¨¹åˆ†é¡**ï¼Œä¸¦é€šéå®Œæ•´çš„å¯¦æˆ°æ¡ˆä¾‹é©—è­‰äº†ç†è«–çŸ¥è­˜ã€‚

### æ ¸å¿ƒæ¦‚å¿µå›é¡§

1. **æ±ºç­–æ¨¹çµæ§‹**ï¼š
   - æ ¹ç¯€é»ã€å…§éƒ¨ç¯€é»ã€è‘‰ç¯€é»
   - é€šééæ­¸åˆ†è£‚æ§‹å»ºæ¨¹
   - å¯¦æˆ°æ¡ˆä¾‹ï¼šæˆåŠŸæ§‹å»ºäº†depth=3åˆ°depth=21çš„å¤šç¨®æ¨¹çµæ§‹

2. **åˆ†è£‚æ¨™æº–**ï¼š
   - Gini ä¸ç´”åº¦ï¼šè¨ˆç®—å¿«é€Ÿï¼Œå¯¦æˆ°ä¸­è¡¨ç¾è‰¯å¥½
   - ç†µèˆ‡ä¿¡æ¯å¢ç›Šï¼šç†è«–å®Œå–„ï¼ŒGridSearchä¸­é¸æ“‡äº†entropy
   - å…©è€…å¯¦å‹™å·®ç•°å°

3. **éæ“¬åˆæ§åˆ¶**ï¼š
   - é å‰ªæï¼šmax_depth=3å¯¦ç¾äº†71.75%çš„å„ªç§€æ³›åŒ–
   - å¾Œå‰ªæï¼šccp_alpha=0.001855é”åˆ°æœ€ä½³æ€§èƒ½73.25%
   - å¯¦æˆ°è­‰æ˜ï¼šå¾Œå‰ªæåœ¨æœ¬æ¡ˆä¾‹ä¸­æ›´æœ‰æ•ˆ

4. **sklearn å¯¦ç¾**ï¼š
   - DecisionTreeClassifier æä¾›å®Œæ•´åŠŸèƒ½
   - æˆåŠŸæ¸¬è©¦äº†4ç¨®ä¸åŒé…ç½®
   - GridSearchCVå„ªåŒ–äº†160ç¨®åƒæ•¸çµ„åˆ

5. **å¯è¦–åŒ–èˆ‡è§£é‡‹**ï¼š
   - plot_treeï¼šæ¸…æ™°å±•ç¤ºæ¨¹çµæ§‹å’Œæ±ºç­–è¦å‰‡
   - feature_importances_ï¼šæº«åº¦(39.96%)å’Œå£“åŠ›(30.19%)æœ€é‡è¦
   - decision_pathï¼šæˆåŠŸè¿½è¹¤äº†å€‹åˆ¥æ¨£æœ¬çš„æ±ºç­–è·¯å¾‘

6. **åŒ–å·¥æ‡‰ç”¨**ï¼š
   - åæ‡‰æˆåŠŸé æ¸¬ï¼šé”åˆ°73.25%æº–ç¢ºç‡
   - ç‰¹å¾µé‡è¦æ€§ç¬¦åˆåŒ–å·¥åŸç†ï¼ˆæº«åº¦>å£“åŠ›>å‚¬åŒ–åŠ‘ï¼‰
   - æ±ºç­–è¦å‰‡å¯ç›´æ¥è½‰åŒ–ç‚ºæ“ä½œæŒ‡å°

### å¯¦æˆ°æˆæœç¸½çµ

**ğŸ“Š æ€§èƒ½æŒ‡æ¨™**ï¼š
- æœ€ä½³æ¨¡å‹ï¼šå‰ªæå„ªåŒ–æ±ºç­–æ¨¹
- æ¸¬è©¦æº–ç¢ºç‡ï¼š**73.25%**
- AUC Scoreï¼š**0.7438**
- äº¤å‰é©—è­‰ï¼š69.00% Â± 2.68%
- ç”Ÿæˆåœ–è¡¨ï¼š10å¼µï¼ˆå«é¡åˆ¥åˆ†ä½ˆã€ç‰¹å¾µåˆ†æã€ROCæ›²ç·šç­‰ï¼‰

**âœ… æ•™å­¸ç›®æ¨™é”æˆ**ï¼š
1. âœ… å®Œæ•´å¯¦ç¾äº†æ±ºç­–æ¨¹åˆ†é¡æµç¨‹
2. âœ… å±•ç¤ºäº†éæ“¬åˆç¾è±¡èˆ‡æ§åˆ¶æ–¹æ³•
3. âœ… æˆåŠŸæ‡‰ç”¨GridSearchCVå’Œæˆæœ¬è¤‡é›œåº¦å‰ªæ
4. âœ… æä¾›äº†è±å¯Œçš„å¯è¦–åŒ–å’Œè§£é‡‹
5. âœ… é©—è­‰äº†åŒ–å·¥é ˜åŸŸçš„å¯¦éš›æ‡‰ç”¨åƒ¹å€¼

**ğŸ“ é—œéµå­¸ç¿’é»**ï¼š
- ç°¡å–®æ¨¡å‹ï¼ˆdepth=3ï¼‰è¡¨ç¾å„ªæ–¼è¤‡é›œæ¨¡å‹
- å¾Œå‰ªæï¼ˆCCPï¼‰å„ªæ–¼é å‰ªæï¼ˆGridSearchï¼‰
- æº«åº¦å’Œå£“åŠ›æ˜¯åŒ–å­¸åæ‡‰æœ€é—œéµçš„æ§åˆ¶è®Šæ•¸
- æ±ºç­–æ¨¹æä¾›äº†ç„¡èˆ‡å€«æ¯”çš„å¯è§£é‡‹æ€§
- 73%å°å–®ä¸€æ±ºç­–æ¨¹ä¾†èªªå·²æ˜¯å„ªç§€è¡¨ç¾

### é—œéµè¦é»

âœ… **å„ªå‹¢**ï¼š
- é«˜åº¦å¯è§£é‡‹ï¼ˆå¯è¦–åŒ–æ±ºç­–æ¨¹å’Œè¦å‰‡ï¼‰
- ç„¡éœ€ç‰¹å¾µç¸®æ”¾ï¼ˆç›´æ¥ä½¿ç”¨ç‰©ç†é‡ï¼‰
- è‡ªå‹•ç‰¹å¾µé¸æ“‡ï¼ˆè­˜åˆ¥æº«åº¦å’Œå£“åŠ›çš„é‡è¦æ€§ï¼‰
- å¿«é€Ÿé æ¸¬ï¼ˆO(log n)è¤‡é›œåº¦ï¼‰
- å¯¦æˆ°é©—è­‰äº†é€™äº›å„ªå‹¢

âš ï¸ **é™åˆ¶**ï¼š
- å®¹æ˜“éæ“¬åˆï¼ˆå®Œå…¨æ¨¹è¨“ç·´100%æ¸¬è©¦61%ï¼‰
- ä¸ç©©å®šï¼ˆå¾®å°æ•¸æ“šè®Šå‹•å½±éŸ¿å¤§ï¼‰
- æ€§èƒ½ä¸Šé™ï¼ˆå–®ä¸€æ¨¹ç´„73-75%ï¼‰
- å°ä¸å¹³è¡¡æ•¸æ“šæ•æ„Ÿ
- å¯¦æˆ°æ¡ˆä¾‹æ¸…æ¥šå±•ç¤ºäº†é€™äº›é™åˆ¶

ğŸ¯ **é©ç”¨**ï¼š
- éœ€è¦å¯è§£é‡‹æ€§çš„å ´æ™¯ï¼ˆåŒ–å·¥æ“ä½œæŒ‡å°ï¼‰
- æ¢ç´¢æ€§åˆ†æï¼ˆè­˜åˆ¥é—œéµè®Šæ•¸ï¼‰
- æ··åˆé¡å‹æ•¸æ“šï¼ˆæ•¸å€¼+é¡åˆ¥ç‰¹å¾µï¼‰
- å¿«é€ŸåŸå‹é–‹ç™¼

### å¯¦å‹™ç¶“é©—åˆ†äº«

åŸºæ–¼æœ¬æ¬¡å¯¦æˆ°æ¡ˆä¾‹ï¼Œä»¥ä¸‹æ˜¯é‡è¦çš„å¯¦å‹™å»ºè­°ï¼š

1. **å¾ç°¡å–®é–‹å§‹**ï¼š
   - å…ˆå»ºç«‹depth=3çš„ç°¡å–®æ¨¹
   - è©•ä¼°æ˜¯å¦éœ€è¦æ›´è¤‡é›œçš„æ¨¡å‹
   - æœ¬æ¡ˆä¾‹ä¸­ç°¡å–®æ¨¹(71.75%)å¹¾ä¹é”åˆ°æœ€ä½³æ€§èƒ½

2. **é‡è¦–å¾Œå‰ªæ**ï¼š
   - GridSearchå¯èƒ½æ‰¾ä¸åˆ°æœ€å„ªè§£ï¼ˆ69.50%ï¼‰
   - æˆæœ¬è¤‡é›œåº¦å‰ªææ›´æœ‰æ•ˆï¼ˆ73.25%ï¼‰
   - å€¼å¾—é¡å¤–çš„è¨ˆç®—æˆæœ¬

3. **äº¤å‰é©—è­‰å¿…ä¸å¯å°‘**ï¼š
   - æ¨™æº–å·®2.68%é¡¯ç¤ºæ¨¡å‹ç©©å®š
   - å¯æª¢æ¸¬æ•¸æ“šå­é›†çš„ç•°è³ªæ€§
   - é¿å…å–®ä¸€æ¸¬è©¦é›†çš„åå·®

4. **ç‰¹å¾µé‡è¦æ€§æŒ‡å°å¯¦é©—**ï¼š
   - æº«åº¦(40%)å’Œå£“åŠ›(30%)æœ€é‡è¦
   - å¯å„ªå…ˆèª¿æ•´é€™å…©å€‹è®Šæ•¸
   - åæ‡‰æ™‚é–“(3.9%)é‡è¦æ€§ä½ï¼Œå¯å›ºå®š

5. **äº†è§£æ€§èƒ½ä¸Šé™**ï¼š
   - å–®ä¸€æ±ºç­–æ¨¹ç´„73-75%
   - è‹¥éœ€80%+ï¼Œè½‰å‘é›†æˆæ–¹æ³•
   - ä¸è¦éåº¦èª¿åƒ

### ä¸‹ä¸€æ­¥å­¸ç¿’

å®Œæˆæ±ºç­–æ¨¹çš„å­¸ç¿’å¾Œï¼ŒåŸºæ–¼æœ¬æ¬¡å¯¦æˆ°ç¶“é©—ï¼Œå»ºè­°ç¹¼çºŒå­¸ç¿’ï¼š

1. **Unit13_Random_Forest_Classifier**ï¼š
   - é›†æˆå¤šæ£µæ±ºç­–æ¨¹ï¼Œé æœŸæº–ç¢ºç‡æå‡è‡³80-85%
   - è§£æ±ºå–®ä¸€æ¨¹çš„ä¸ç©©å®šæ€§å•é¡Œ
   - ä¿æŒéƒ¨åˆ†å¯è§£é‡‹æ€§

2. **Unit14_Gradient_Boosting_Classifier**ï¼š
   - åºåˆ—é›†æˆï¼Œé€²ä¸€æ­¥å„ªåŒ–è‡³85-90%
   - æ›´å¼·çš„é æ¸¬èƒ½åŠ›
   - é©åˆå°æ€§èƒ½è¦æ±‚æ¥µé«˜çš„å ´æ™¯

3. **Unit15_Feature_Engineering**ï¼š
   - æ·»åŠ äº¤äº’ç‰¹å¾µï¼ˆæº«åº¦Ã—å£“åŠ›ï¼‰
   - æå‡æ±ºç­–æ¨¹æ€§èƒ½
   - æ·±å…¥ç†è§£ç‰¹å¾µè¨­è¨ˆ

### èª²ç¨‹è³‡æº

**ä»£ç¢¼æª”æ¡ˆ**ï¼š
- Unit12_Decision_Tree_Classifier.ipynbï¼ˆå®Œæ•´åŸ·è¡Œä»£ç¢¼ï¼‰
- è¼¸å‡ºç›®éŒ„ï¼šoutputs/P3_Unit12_Decision_Tree_Classifier/

**ç”Ÿæˆçš„åœ–è¡¨**ï¼š
1. class_distribution.png - é¡åˆ¥åˆ†ä½ˆåœ–
2. feature_distributions.png - ç‰¹å¾µåˆ†ä½ˆåœ–
3. correlation_heatmap.png - ç›¸é—œæ€§ç†±åŠ›åœ–
4. model_comparison.png - æ¨¡å‹æ€§èƒ½æ¯”è¼ƒ
5. tree_structure.png - æ±ºç­–æ¨¹çµæ§‹å¯è¦–åŒ–
6. feature_importance.png - ç‰¹å¾µé‡è¦æ€§æ’å
7. confusion_matrix.png - æ··æ·†çŸ©é™£
8. roc_curve.png - ROCæ›²ç·šåˆ†æ
9. pruning_analysis.png - å‰ªææ•ˆæœåˆ†æ
10. cross_validation.png - äº¤å‰é©—è­‰çµæœ

**ä¿å­˜çš„æ¨¡å‹**ï¼š
- best_decision_tree_pruned.pklï¼ˆ73.25%æº–ç¢ºç‡ï¼‰
- best_decision_tree_gridsearch.pklï¼ˆ69.50%æº–ç¢ºç‡ï¼‰
- scaler.pklï¼ˆç‰¹å¾µæ¨™æº–åŒ–å™¨ï¼‰

---

**èª²ç¨‹è³‡è¨Š**
- èª²ç¨‹åç¨±ï¼šAIåœ¨åŒ–å·¥ä¸Šä¹‹æ‡‰ç”¨
- èª²ç¨‹å–®å…ƒï¼šUnit12 Decision Tree Classifier æ±ºç­–æ¨¹åˆ†é¡å™¨
- èª²ç¨‹è£½ä½œï¼šé€¢ç”²å¤§å­¸ åŒ–å·¥ç³» æ™ºæ…§ç¨‹åºç³»çµ±å·¥ç¨‹å¯¦é©—å®¤
- æˆèª²æ•™å¸«ï¼šèŠæ›œç¦ åŠ©ç†æ•™æˆ
- æ›´æ–°æ—¥æœŸï¼š2026-01-28

**èª²ç¨‹æˆæ¬Š [CC BY-NC-SA 4.0]**
 - æœ¬æ•™æéµå¾ª [å‰µç”¨CC å§“åæ¨™ç¤º-éå•†æ¥­æ€§-ç›¸åŒæ–¹å¼åˆ†äº« 4.0 åœ‹éš› (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh) æˆæ¬Šã€‚

---
