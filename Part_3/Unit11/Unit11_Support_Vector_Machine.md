# Unit 11: æ”¯æŒå‘é‡æ©Ÿå›æ­¸ (Support Vector Machine Regression)

**èª²ç¨‹åç¨±**ï¼šAI åœ¨åŒ–å·¥ä¸Šä¹‹æ‡‰ç”¨  
**èª²ç¨‹ä»£ç¢¼**ï¼šCHE-AI-114  
**æˆèª²æ•™å¸«**ï¼šèŠæ›œç¦ åŠ©ç†æ•™æˆ  
**å–®å…ƒä¸»é¡Œ**ï¼šæ”¯æŒå‘é‡æ©Ÿå›æ­¸æ¨¡å‹  
**é©ç”¨å°è±¡**ï¼šåŒ–å­¸å·¥ç¨‹å­¸ç³»å­¸ç”Ÿ  

---

## å­¸ç¿’ç›®æ¨™

å®Œæˆæœ¬å–®å…ƒå¾Œï¼Œå­¸ç”Ÿå°‡èƒ½å¤ ï¼š

1. ç†è§£æ”¯æŒå‘é‡æ©Ÿå›æ­¸ (SVR) çš„åŸºæœ¬åŸç†èˆ‡ Îµ-insensitive loss æ©Ÿåˆ¶
2. æŒæ¡æ ¸å‡½æ•¸ (Kernel Functions) çš„æ¦‚å¿µèˆ‡æ‡‰ç”¨
3. ä½¿ç”¨ `sklearn.svm.SVR` å»ºç«‹ç·šæ€§èˆ‡éç·šæ€§å›æ­¸æ¨¡å‹
4. ç†è§£ SVR çš„é—œéµè¶…åƒæ•¸ (C, epsilon, gamma, kernel)
5. å­¸ç¿’ SVR çš„è³‡æ–™å‰è™•ç†éœ€æ±‚ï¼ˆæ¨™æº–åŒ–çš„é‡è¦æ€§ï¼‰
6. æ‡‰ç”¨ SVR æ–¼åŒ–å·¥è£½ç¨‹é æ¸¬å•é¡Œ
7. æ¯”è¼ƒ SVR èˆ‡å…¶ä»–å›æ­¸æ¨¡å‹çš„æ€§èƒ½èˆ‡é©ç”¨å ´æ™¯

---

## 1. æ”¯æŒå‘é‡æ©Ÿå›æ­¸ç°¡ä»‹

### 1.1 ä»€éº¼æ˜¯æ”¯æŒå‘é‡æ©Ÿå›æ­¸ï¼Ÿ

**æ”¯æŒå‘é‡æ©Ÿå›æ­¸ (Support Vector Regression, SVR)** æ˜¯æ”¯æŒå‘é‡æ©Ÿ (SVM) åœ¨å›æ­¸å•é¡Œä¸Šçš„å»¶ä¼¸æ‡‰ç”¨ã€‚èˆ‡å‚³çµ±å›æ­¸æ–¹æ³•ä¸åŒï¼ŒSVR çš„ç›®æ¨™ä¸æ˜¯æœ€å°åŒ–é æ¸¬èª¤å·®ï¼Œè€Œæ˜¯**æ‰¾åˆ°ä¸€å€‹èƒ½å®¹å¿ä¸€å®šèª¤å·®ç¯„åœï¼ˆÎµ-tubeï¼‰çš„å‡½æ•¸**ï¼Œä½¿å¾—ç›¡å¯èƒ½å¤šçš„æ¨£æœ¬é»è½åœ¨é€™å€‹èª¤å·®ç®¡é“å…§ã€‚

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š
- **Îµ-insensitive loss**ï¼šåªæœ‰ç•¶é æ¸¬èª¤å·®è¶…é Îµ æ™‚æ‰è¨ˆå…¥æå¤±
- **æ”¯æŒå‘é‡**ï¼šè½åœ¨ Îµ-tube é‚Šç•Œä¸Šæˆ–é‚Šç•Œå¤–çš„æ¨£æœ¬é»
- **æ ¸å‡½æ•¸æ˜ å°„**ï¼šå°‡è³‡æ–™æ˜ å°„åˆ°é«˜ç¶­ç©ºé–“ä»¥è™•ç†éç·šæ€§é—œä¿‚
- **é–“éš”æœ€å¤§åŒ–**ï¼šåœ¨æ»¿è¶³èª¤å·®å®¹å¿åº¦çš„å‰æä¸‹ï¼Œå°‹æ‰¾æœ€å¹³å¦çš„å‡½æ•¸

**å·¥ä½œåŸç†**ï¼š
```
ç·šæ€§ SVR æ¨¡å‹ï¼š
f(x) = wÂ·x + b

ç›®æ¨™ï¼šæ‰¾åˆ° w å’Œ bï¼Œä½¿å¾—ï¼š
1. å¤§éƒ¨åˆ†æ¨£æœ¬çš„èª¤å·® |y - f(x)| â‰¤ Îµ
2. ||w||Â² æœ€å°ï¼ˆå‡½æ•¸æœ€å¹³å¦ï¼‰
3. è¶…å‡º Îµ çš„èª¤å·®å—åˆ°æ‡²ç½°ï¼ˆç”±åƒæ•¸ C æ§åˆ¶ï¼‰

éç·šæ€§ SVRï¼š
é€šéæ ¸å‡½æ•¸ K(x, x') å°‡è³‡æ–™æ˜ å°„åˆ°é«˜ç¶­ç©ºé–“
f(x) = Î£ (Î±áµ¢ - Î±áµ¢*) K(xáµ¢, x) + b
```

### 1.2 ç‚ºä»€éº¼éœ€è¦ SVRï¼Ÿ

**å‚³çµ±å›æ­¸æ–¹æ³•çš„é™åˆ¶**ï¼š
- **å°ç•°å¸¸å€¼æ•æ„Ÿ**ï¼šæœ€å°äºŒä¹˜æ³•æœƒè¢«æ¥µç«¯å€¼å¼·çƒˆå½±éŸ¿
- **ç„¡é­¯æ£’æ€§æ©Ÿåˆ¶**ï¼šæ‰€æœ‰èª¤å·®éƒ½è¢«åŒç­‰å°å¾…
- **ç·šæ€§å‡è¨­é™åˆ¶**ï¼šé›£ä»¥è™•ç†è¤‡é›œçš„éç·šæ€§é—œä¿‚

**SVR çš„å„ªå‹¢**ï¼š
- **é­¯æ£’æ€§å¼· (Robustness)**ï¼šÎµ-insensitive loss å°å°èª¤å·®ä¸æ•æ„Ÿ
- **ç¨€ç–è§£ (Sparsity)**ï¼šåªæœ‰æ”¯æŒå‘é‡å½±éŸ¿æ¨¡å‹ï¼Œè¨ˆç®—é«˜æ•ˆ
- **éç·šæ€§å»ºæ¨¡èƒ½åŠ›**ï¼šæ ¸å‡½æ•¸æŠ€å·§è™•ç†è¤‡é›œé—œä¿‚
- **æ³›åŒ–èƒ½åŠ›å¼·**ï¼šæœ€å¤§é–“éš”åŸå‰‡æ¸›å°‘éæ“¬åˆé¢¨éšª
- **ç†è«–ä¿è­‰**ï¼šå»ºç«‹åœ¨çµ±è¨ˆå­¸ç¿’ç†è«–åŸºç¤ä¸Š

### 1.3 SVR vs å…¶ä»–å›æ­¸æ¨¡å‹

| ç‰¹æ€§ | ç·šæ€§å›æ­¸ | æ±ºç­–æ¨¹ | éš¨æ©Ÿæ£®æ— | SVR |
|------|---------|--------|---------|-----|
| **éç·šæ€§å»ºæ¨¡** | âœ— | âœ“ | âœ“ | âœ“ï¼ˆæ ¸å‡½æ•¸ï¼‰ |
| **å°ç•°å¸¸å€¼é­¯æ£’** | âœ— | âœ“ | âœ“ | âœ“ï¼ˆÎµ-tubeï¼‰ |
| **å°æ¨£æœ¬æ€§èƒ½** | â—‹ | â–³ | â–³ | âœ“ |
| **é«˜ç¶­è³‡æ–™** | â–³ | â–³ | â—‹ | âœ“ |
| **è¨“ç·´é€Ÿåº¦** | å¿« | å¿« | ä¸­ç­‰ | æ…¢ï¼ˆå°¤å…¶æ˜¯å¤§è³‡æ–™é›†ï¼‰ |
| **å¯è§£é‡‹æ€§** | é«˜ | é«˜ | ä¸­ | ä½ |
| **è¶…åƒæ•¸èª¿æ•´** | ç°¡å–® | ä¸­ç­‰ | ä¸­ç­‰ | è¤‡é›œ |
| **è¨˜æ†¶é«”éœ€æ±‚** | ä½ | ä¸­ | é«˜ | ä¸­ï¼ˆç¨€ç–è§£ï¼‰ |

**è¨»**ï¼šâœ“ = å„ªç§€ï¼Œâ—‹ = è‰¯å¥½ï¼Œâ–³ = ä¸€èˆ¬ï¼Œâœ— = è¼ƒå·®

### 1.4 åŒ–å·¥é ˜åŸŸæ‡‰ç”¨æ¡ˆä¾‹

| æ‡‰ç”¨é ˜åŸŸ | é æ¸¬ç›®æ¨™ | ç‚ºä½•é¸æ“‡ SVR |
|---------|---------|-------------|
| **è£½ç¨‹å»ºæ¨¡** | ç”¢ç‡ã€è½‰åŒ–ç‡ | è™•ç†éç·šæ€§ã€å°æ¨£æœ¬æœ‰æ•ˆ |
| **å“è³ªæ§åˆ¶** | ç”¢å“æ€§è³ªï¼ˆé»åº¦ã€ç´”åº¦ï¼‰ | å°æ¸¬é‡å™ªè²é­¯æ£’ |
| **è§¸åª’è¨­è¨ˆ** | å‚¬åŒ–æ´»æ€§ | é«˜ç¶­ç‰¹å¾µç©ºé–“ï¼ˆçµ„æˆã€æ¢ä»¶ï¼‰ |
| **ææ–™æ€§è³ªé æ¸¬** | ç‰©ç†åŒ–å­¸æ€§è³ª | è¤‡é›œçš„çµæ§‹-æ€§è³ªé—œä¿‚ |
| **è£½ç¨‹å„ªåŒ–** | èƒ½è€—ã€æˆæœ¬ | ç©©å¥çš„å€åŸŸæœ€ä½³åŒ– |
| **å…‰è­œåˆ†æ** | æ¿ƒåº¦å®šé‡ | é«˜ç¶­å…‰è­œè³‡æ–™è™•ç† |

---

## 2. SVR çš„æ•¸å­¸åŸç†

### 2.1 ç·šæ€§ SVR æ¨¡å‹

å°æ–¼ç·šæ€§å›æ­¸å•é¡Œï¼ŒSVR å°‹æ‰¾ä»¥ä¸‹å½¢å¼çš„å‡½æ•¸ï¼š

$$
f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b
$$

å…¶ä¸­ï¼š
- $\mathbf{w}$ ï¼šæ¬Šé‡å‘é‡
- $b$ ï¼šåç½®é …
- $\mathbf{x}$ ï¼šè¼¸å…¥ç‰¹å¾µå‘é‡

**Îµ-insensitive Loss Function**ï¼š

$$
L_\varepsilon(y, f(\mathbf{x})) = \begin{cases}
0 & \text{if } |y - f(\mathbf{x})| \leq \varepsilon \\
|y - f(\mathbf{x})| - \varepsilon & \text{otherwise}
\end{cases}
$$

é€™å€‹æå¤±å‡½æ•¸å®šç¾©äº†ä¸€å€‹ **Îµ-tube**ï¼ˆå¯¬åº¦ç‚º 2Îµ çš„ç®¡é“ï¼‰ï¼š
- è½åœ¨ç®¡é“å…§çš„æ¨£æœ¬é»ï¼šæå¤±ç‚º 0
- è½åœ¨ç®¡é“å¤–çš„æ¨£æœ¬é»ï¼šæå¤±ç‚ºè·é›¢ç®¡é“é‚Šç•Œçš„è·é›¢

### 2.2 åŸå§‹å„ªåŒ–å•é¡Œ

SVR çš„ç›®æ¨™æ˜¯æ‰¾åˆ°æœ€å¹³å¦çš„å‡½æ•¸ï¼ˆæœ€å°åŒ– $\|\mathbf{w}\|^2$ ï¼‰ï¼ŒåŒæ™‚å…è¨±ä¸€å®šçš„èª¤å·®ï¼š

$$
\begin{aligned}
\min_{\mathbf{w}, b, \boldsymbol{\xi}, \boldsymbol{\xi}^*} \quad & \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^{N} (\xi_i + \xi_i^*) \\
\text{s.t.} \quad & y_i - (\mathbf{w}^T \mathbf{x}_i + b) \leq \varepsilon + \xi_i \\
& (\mathbf{w}^T \mathbf{x}_i + b) - y_i \leq \varepsilon + \xi_i^* \\
& \xi_i, \xi_i^* \geq 0, \quad i = 1, \ldots, N
\end{aligned}
$$

**è®Šæ•¸èªªæ˜**ï¼š
- $\xi_i, \xi_i^*$ ï¼šé¬†å¼›è®Šæ•¸ï¼ˆslack variablesï¼‰ï¼Œå…è¨±æ¨£æœ¬è½åœ¨ Îµ-tube å¤–
- $C$ ï¼šæ‡²ç½°åƒæ•¸ï¼Œæ§åˆ¶å°èª¤å·®çš„å®¹å¿åº¦
  - $C$ å¤§ï¼šåš´æ ¼æ“¬åˆï¼Œå¯èƒ½éæ“¬åˆ
  - $C$ å°ï¼šå…è¨±æ›´å¤šèª¤å·®ï¼Œå¯èƒ½æ¬ æ“¬åˆ

**å¹¾ä½•è§£é‡‹**ï¼š
```
       â†‘ y
       |     â— (æ”¯æŒå‘é‡ï¼ŒÎ¾áµ¢ > 0)
  Îµ-tube |  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  ä¸Šé‚Šç•Œ (y = f(x) + Îµ)
       |        â—‹  â—‹  â—‹          è½åœ¨ tube å…§ (Î¾ = 0)
       |  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  ä¸­å¿ƒç·š f(x) = wÂ·x + b
       |        â—‹  â—‹  â—‹
  Îµ-tube |  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  ä¸‹é‚Šç•Œ (y = f(x) - Îµ)
       |     â— (æ”¯æŒå‘é‡ï¼ŒÎ¾áµ¢* > 0)
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ x
```

### 2.3 å°å¶å•é¡Œèˆ‡æ ¸å‡½æ•¸

**å°å¶å•é¡Œ**ï¼š
é€šéæ‹‰æ ¼æœ—æ—¥ä¹˜æ•¸æ³•ï¼Œå¯å°‡åŸå§‹å•é¡Œè½‰æ›ç‚ºå°å¶å•é¡Œï¼š

$$
\begin{aligned}
\max_{\boldsymbol{\alpha}, \boldsymbol{\alpha}^*} \quad & -\frac{1}{2} \sum_{i,j=1}^{N} (\alpha_i - \alpha_i^*)(\alpha_j - \alpha_j^*) \mathbf{x}_i^T \mathbf{x}_j \\
& - \varepsilon \sum_{i=1}^{N} (\alpha_i + \alpha_i^*) + \sum_{i=1}^{N} y_i (\alpha_i - \alpha_i^*) \\
\text{s.t.} \quad & \sum_{i=1}^{N} (\alpha_i - \alpha_i^*) = 0 \\
& 0 \leq \alpha_i, \alpha_i^* \leq C, \quad i = 1, \ldots, N
\end{aligned}
$$

**æœ€çµ‚é æ¸¬å‡½æ•¸**ï¼š

$$
f(\mathbf{x}) = \sum_{i=1}^{N} (\alpha_i - \alpha_i^*) \mathbf{x}_i^T \mathbf{x} + b
$$

åªæœ‰ $\alpha_i - \alpha_i^* \neq 0$ çš„æ¨£æœ¬æ‰å°é æ¸¬æœ‰è²¢ç»ï¼Œé€™äº›æ¨£æœ¬ç¨±ç‚º**æ”¯æŒå‘é‡**ã€‚

**æ ¸æŠ€å·§ (Kernel Trick)**ï¼š

å°æ–¼éç·šæ€§å•é¡Œï¼Œå°‡è¼¸å…¥æ˜ å°„åˆ°é«˜ç¶­ç‰¹å¾µç©ºé–“ $\Phi(\mathbf{x})$ ï¼š

$$
f(\mathbf{x}) = \sum_{i=1}^{N} (\alpha_i - \alpha_i^*) K(\mathbf{x}_i, \mathbf{x}) + b
$$

å…¶ä¸­æ ¸å‡½æ•¸ $K(\mathbf{x}_i, \mathbf{x}_j) = \Phi(\mathbf{x}_i)^T \Phi(\mathbf{x}_j)$ éš±å¼åœ°è¨ˆç®—é«˜ç¶­å…§ç©ï¼Œç„¡éœ€é¡¯å¼æ˜ å°„ã€‚

### 2.4 å¸¸ç”¨æ ¸å‡½æ•¸

**1. ç·šæ€§æ ¸ (Linear Kernel)**ï¼š

$$
K(\mathbf{x}_i, \mathbf{x}_j) = \mathbf{x}_i^T \mathbf{x}_j
$$

- **é©ç”¨**ï¼šç·šæ€§å¯åˆ†çš„å•é¡Œ
- **å„ªé»**ï¼šè¨ˆç®—å¿«é€Ÿï¼Œå¯è§£é‡‹æ€§å¼·
- **åƒæ•¸**ï¼šç„¡

**2. å¤šé …å¼æ ¸ (Polynomial Kernel)**ï¼š

$$
K(\mathbf{x}_i, \mathbf{x}_j) = (\gamma \mathbf{x}_i^T \mathbf{x}_j + r)^d
$$

- **é©ç”¨**ï¼šç‰¹å¾µé–“å­˜åœ¨å¤šé …å¼é—œä¿‚
- **å„ªé»**ï¼šå¯æ§åˆ¶éç·šæ€§ç¨‹åº¦
- **åƒæ•¸**ï¼š $d$ (degree)ã€ $\gamma$ ã€ $r$ (coef0)

**3. å¾‘å‘åŸºå‡½æ•¸æ ¸ (RBF/Gaussian Kernel)**ï¼š

$$
K(\mathbf{x}_i, \mathbf{x}_j) = \exp\left(-\gamma \|\mathbf{x}_i - \mathbf{x}_j\|^2\right)
$$

å…¶ä¸­ $\gamma = \frac{1}{2\sigma^2}$

- **é©ç”¨**ï¼šé€šç”¨ï¼Œæœ€å¸¸ç”¨çš„æ ¸å‡½æ•¸
- **å„ªé»**ï¼šå¯è™•ç†å„ç¨®éç·šæ€§é—œä¿‚
- **åƒæ•¸**ï¼š $\gamma$ ï¼ˆæ§åˆ¶å½±éŸ¿ç¯„åœï¼‰
  - $\gamma$ å¤§ï¼šå½±éŸ¿ç¯„åœå°ï¼Œæ¨¡å‹è¤‡é›œï¼ˆå¯èƒ½éæ“¬åˆï¼‰
  - $\gamma$ å°ï¼šå½±éŸ¿ç¯„åœå¤§ï¼Œæ¨¡å‹å¹³æ»‘ï¼ˆå¯èƒ½æ¬ æ“¬åˆï¼‰

**4. Sigmoid æ ¸**ï¼š

$$
K(\mathbf{x}_i, \mathbf{x}_j) = \tanh(\gamma \mathbf{x}_i^T \mathbf{x}_j + r)
$$

- **é©ç”¨**ï¼šæ¨¡æ“¬ç¥ç¶“ç¶²è·¯
- **åƒæ•¸**ï¼š $\gamma$ ã€ $r$ (coef0)

**æ ¸å‡½æ•¸é¸æ“‡å»ºè­°**ï¼š
- **ç·šæ€§é—œä¿‚æ˜ç¢º**ï¼šä½¿ç”¨ `linear` æ ¸
- **ä¸ç¢ºå®šé—œä¿‚**ï¼šå„ªå…ˆå˜—è©¦ `rbf` æ ¸ï¼ˆæœ€ç©©å¥ï¼‰
- **å·²çŸ¥å¤šé …å¼ç‰¹æ€§**ï¼šä½¿ç”¨ `poly` æ ¸
- **åƒæ•¸èª¿æ•´**ï¼šé€šéäº¤å‰é©—è­‰å°‹æ‰¾æœ€ä½³ $\gamma$ å’Œ $C$

---

## 3. SVR çš„é—œéµè¶…åƒæ•¸

### 3.1 æ ¸å¿ƒè¶…åƒæ•¸è©³è§£

**1. `C` (æ‡²ç½°åƒæ•¸)**

- **æ„ç¾©**ï¼šæ§åˆ¶å°è¶…å‡º Îµ-tube æ¨£æœ¬çš„æ‡²ç½°å¼·åº¦
- **å½±éŸ¿**ï¼š
  - **å¤§ C**ï¼ˆå¦‚ 100, 1000ï¼‰ï¼š
    - åš´æ ¼æ“¬åˆè¨“ç·´è³‡æ–™
    - å®¹å¿å°‘é‡èª¤å·®
    - é¢¨éšªï¼šéæ“¬åˆ
  - **å° C**ï¼ˆå¦‚ 0.1, 1ï¼‰ï¼š
    - å…è¨±æ›´å¤šèª¤å·®
    - æ¨¡å‹æ›´å¹³æ»‘
    - é¢¨éšªï¼šæ¬ æ“¬åˆ
- **é è¨­å€¼**ï¼š`C=1.0`
- **èª¿æ•´å»ºè­°**ï¼šå¾ `[0.1, 1, 10, 100]` é–‹å§‹ç¶²æ ¼æœå°‹

**2. `epsilon` (Îµ, ä¸æ•æ„Ÿæå¤±å¯¬åº¦)**

- **æ„ç¾©**ï¼šÎµ-tube çš„åŠå¾‘ï¼Œå®šç¾©"å¯æ¥å—èª¤å·®"çš„ç¯„åœ
- **å½±éŸ¿**ï¼š
  - **å¤§ Îµ**ï¼ˆå¦‚ 0.5, 1.0ï¼‰ï¼š
    - æ›´å¯¬çš„èª¤å·®å®¹å¿å¸¶
    - æ”¯æŒå‘é‡æ•¸é‡æ¸›å°‘
    - æ¨¡å‹æ›´ç°¡å–®ã€æ›´å¹³æ»‘
  - **å° Îµ**ï¼ˆå¦‚ 0.01, 0.05ï¼‰ï¼š
    - æ›´åš´æ ¼çš„æ“¬åˆ
    - æ”¯æŒå‘é‡æ•¸é‡å¢åŠ 
    - æ¨¡å‹æ›´è¤‡é›œ
- **é è¨­å€¼**ï¼š`epsilon=0.1`
- **èª¿æ•´å»ºè­°**ï¼šæ ¹æ“šç›®æ¨™è®Šæ•¸çš„å°ºåº¦è¨­å®šï¼ˆé€šå¸¸ç‚ºæ¨™æº–å·®çš„ 0.1-0.5 å€ï¼‰

**3. `gamma` (RBF æ ¸çš„å¯¬åº¦åƒæ•¸)**

- **æ„ç¾©**ï¼šæ§åˆ¶å–®å€‹è¨“ç·´æ¨£æœ¬çš„å½±éŸ¿ç¯„åœ
- **å½±éŸ¿**ï¼š
  - **å¤§ Î³**ï¼ˆå¦‚ 1, 10ï¼‰ï¼š
    - å–®å€‹æ¨£æœ¬å½±éŸ¿ç¯„åœå°
    - æ±ºç­–é‚Šç•Œè¤‡é›œã€æ‰­æ›²
    - é¢¨éšªï¼šéæ“¬åˆ
  - **å° Î³**ï¼ˆå¦‚ 0.01, 0.1ï¼‰ï¼š
    - å–®å€‹æ¨£æœ¬å½±éŸ¿ç¯„åœå¤§
    - æ±ºç­–é‚Šç•Œå¹³æ»‘
    - é¢¨éšªï¼šæ¬ æ“¬åˆ
- **é è¨­å€¼**ï¼š`gamma='scale'`ï¼ˆ $\gamma = \frac{1}{n_{\text{features}} \times \text{Var}(X)}$ ï¼‰
- **å¯é¸å€¼**ï¼š`'scale'`, `'auto'`ï¼ˆ $\gamma = \frac{1}{n_{\text{features}}}$ ï¼‰ï¼Œæˆ–æ‰‹å‹•è¨­å®šæ•¸å€¼
- **èª¿æ•´å»ºè­°**ï¼šå¾ `[0.001, 0.01, 0.1, 1]` é–‹å§‹ç¶²æ ¼æœå°‹

**4. `kernel` (æ ¸å‡½æ•¸é¡å‹)**

- **é¸é …**ï¼š
  - `'linear'`ï¼šç·šæ€§æ ¸ï¼Œé©ç”¨æ–¼ç·šæ€§å•é¡Œ
  - `'poly'`ï¼šå¤šé …å¼æ ¸ï¼Œéœ€é¡å¤–è¨­å®š `degree`
  - `'rbf'`ï¼šå¾‘å‘åŸºå‡½æ•¸æ ¸ï¼ˆ**é è¨­å€¼ï¼Œæœ€å¸¸ç”¨**ï¼‰
  - `'sigmoid'`ï¼šSigmoid æ ¸
  - è‡ªå®šç¾©æ ¸ï¼šå‚³å…¥æ ¸çŸ©é™£æˆ–å‡½æ•¸
- **é¸æ“‡å»ºè­°**ï¼š
  - å…ˆå˜—è©¦ `'rbf'`ï¼ˆé€šç”¨æ€§æœ€å¼·ï¼‰
  - è‹¥ç‰¹å¾µç¶­åº¦é«˜ä¸”è³‡æ–™ç·šæ€§å¯åˆ†ï¼Œè€ƒæ…® `'linear'`
  - è‹¥å·²çŸ¥å¤šé …å¼é—œä¿‚ï¼Œä½¿ç”¨ `'poly'`

### 3.2 è¶…åƒæ•¸çµ„åˆå½±éŸ¿

**C å’Œ epsilon çš„äº¤äº’ä½œç”¨**ï¼š

| C \ epsilon | å° Îµ (åš´æ ¼) | å¤§ Îµ (å¯¬é¬†) |
|-------------|-----------|-----------|
| **å¤§ C (åš´æ ¼æ‡²ç½°)** | æœ€åš´æ ¼æ“¬åˆ<br>é«˜é¢¨éšªéæ“¬åˆ | å¹³è¡¡æ¨¡å‹<br>è¼ƒå¥½æ³›åŒ– |
| **å° C (å¯¬é¬†æ‡²ç½°)** | å¹³æ»‘æ¨¡å‹<br>å¯èƒ½æ¬ æ“¬åˆ | æœ€å¹³æ»‘æ¨¡å‹<br>é«˜é¢¨éšªæ¬ æ“¬åˆ |

**gamma å’Œ C çš„äº¤äº’ä½œç”¨ï¼ˆRBF æ ¸ï¼‰**ï¼š

| gamma \ C | å° C | å¤§ C |
|-----------|------|------|
| **å¤§ Î³ (è¤‡é›œé‚Šç•Œ)** | å±€éƒ¨è¤‡é›œä½†æ•´é«”å¹³æ»‘ | åš´é‡éæ“¬åˆ |
| **å° Î³ (å¹³æ»‘é‚Šç•Œ)** | æ¬ æ“¬åˆ | å¹³è¡¡æ¨¡å‹ |

**èª¿åƒå»ºè­°**ï¼š
1. å…ˆå›ºå®š `epsilon=0.1`ï¼Œç¶²æ ¼æœå°‹ `(C, gamma)`
2. æ‰¾åˆ°è¼ƒå¥½çµ„åˆå¾Œï¼Œå†å¾®èª¿ `epsilon`
3. ä½¿ç”¨å°æ•¸å°ºåº¦ï¼š`C=[0.1, 1, 10, 100]`, `gamma=[0.001, 0.01, 0.1, 1]`

### 3.3 å…¶ä»–åƒæ•¸

**`degree`**ï¼ˆåƒ…ç”¨æ–¼ `poly` æ ¸ï¼‰ï¼š
- å¤šé …å¼çš„æ¬¡æ•¸ï¼ˆ2, 3, 4, ...ï¼‰
- éé«˜çš„ degree å®¹æ˜“éæ“¬åˆ

**`coef0`**ï¼ˆç”¨æ–¼ `poly` å’Œ `sigmoid` æ ¸ï¼‰ï¼š
- å¤šé …å¼æ ¸çš„å¸¸æ•¸é …
- é è¨­å€¼ï¼š0.0

**`shrinking`**ï¼š
- æ˜¯å¦ä½¿ç”¨å•Ÿç™¼å¼æ”¶ç¸®ç­–ç•¥åŠ é€Ÿè¨“ç·´
- é è¨­å€¼ï¼š`True`ï¼ˆå»ºè­°ä¿æŒï¼‰

**`tol`**ï¼š
- å„ªåŒ–åœæ­¢æº–å‰‡çš„å®¹å¿åº¦
- é è¨­å€¼ï¼š`1e-3`ï¼ˆé€šå¸¸ç„¡éœ€èª¿æ•´ï¼‰

**`max_iter`**ï¼š
- æœ€å¤§è¿­ä»£æ¬¡æ•¸
- é è¨­å€¼ï¼š-1ï¼ˆç„¡é™åˆ¶ï¼Œç›´åˆ°æ”¶æ–‚ï¼‰

---

## 4. ä½¿ç”¨ scikit-learn å¯¦ä½œ SVR

### 4.1 åŸºæœ¬ä½¿ç”¨æµç¨‹

```python
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# 1. è³‡æ–™æº–å‚™èˆ‡åˆ‡åˆ†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 2. è³‡æ–™æ¨™æº–åŒ–ï¼ˆé‡è¦ï¼ï¼‰
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)
y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()

# 3. å»ºç«‹ä¸¦è¨“ç·´ SVR æ¨¡å‹
model = SVR(
    kernel='rbf',      # ä½¿ç”¨ RBF æ ¸
    C=10.0,            # æ‡²ç½°åƒæ•¸
    epsilon=0.1,       # Îµ-tube å¯¬åº¦
    gamma='scale'      # è‡ªå‹•è¨ˆç®— gamma
)
model.fit(X_train_scaled, y_train_scaled)

# 4. é æ¸¬èˆ‡åæ¨™æº–åŒ–
y_pred_scaled = model.predict(X_test_scaled)
y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()

# 5. æ¨¡å‹è©•ä¼°
from sklearn.metrics import mean_squared_error, r2_score
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'MSE: {mse:.4f}, RÂ²: {r2:.4f}')
```

### 4.2 ç‚ºä»€éº¼éœ€è¦è³‡æ–™æ¨™æº–åŒ–ï¼Ÿ

SVR å°ç‰¹å¾µå°ºåº¦**æ¥µåº¦æ•æ„Ÿ**ï¼ŒåŸå› å¦‚ä¸‹ï¼š

1. **RBF æ ¸åŸºæ–¼æ­æ°è·é›¢**ï¼š
   $$K(\mathbf{x}_i, \mathbf{x}_j) = \exp(-\gamma \|\mathbf{x}_i - \mathbf{x}_j\|^2)$$
   
   å¦‚æœæŸå€‹ç‰¹å¾µçš„æ•¸å€¼ç¯„åœé å¤§æ–¼å…¶ä»–ç‰¹å¾µï¼ˆä¾‹å¦‚æº«åº¦ 300-500 vs. å£“åŠ› 1-10ï¼‰ï¼Œè©²ç‰¹å¾µå°‡ä¸»å°è·é›¢è¨ˆç®—ã€‚

2. **è¶…åƒæ•¸é›£ä»¥èª¿æ•´**ï¼š
   æœªæ¨™æº–åŒ–æ™‚ï¼Œæœ€ä½³çš„ `C` å’Œ `gamma` å€¼æœƒå—ç‰¹å¾µå°ºåº¦å½±éŸ¿ï¼Œé›£ä»¥æ‰¾åˆ°é€šç”¨è¨­å®šã€‚

3. **æ•¸å€¼ç©©å®šæ€§**ï¼š
   æ¥µç«¯å°ºåº¦å·®ç•°å¯èƒ½å°è‡´æ ¸çŸ©é™£ç—…æ…‹ï¼ˆill-conditionedï¼‰ï¼Œå½±éŸ¿å„ªåŒ–æ±‚è§£ã€‚

**æ¨™æº–åŒ–æ–¹æ³•**ï¼š

```python
# å°ç‰¹å¾µ X é€²è¡Œæ¨™æº–åŒ–ï¼ˆé›¶å‡å€¼ã€å–®ä½æ–¹å·®ï¼‰
scaler_X = StandardScaler()
X_scaled = scaler_X.fit_transform(X)  # X_scaled ~ N(0, 1)

# å°ç›®æ¨™è®Šæ•¸ y é€²è¡Œæ¨™æº–åŒ–ï¼ˆå¯é¸ä½†å»ºè­°ï¼‰
scaler_y = StandardScaler()
y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).ravel()
```

**æ³¨æ„äº‹é …**ï¼š
- è¨“ç·´é›†ä¸Š `fit_transform()`ï¼Œæ¸¬è©¦é›†ä¸Šåª `transform()`
- é æ¸¬çµæœéœ€ä½¿ç”¨ `inverse_transform()` é‚„åŸåˆ°åŸå§‹å°ºåº¦
- ç›®æ¨™è®Šæ•¸ y çš„æ¨™æº–åŒ–æœ‰åŠ©æ–¼ `epsilon` å’Œ `C` çš„è¨­å®š

### 4.3 è¶…åƒæ•¸èª¿å„ªç­–ç•¥

**æ–¹æ³• 1ï¼šç¶²æ ¼æœå°‹ (Grid Search)**

```python
from sklearn.model_selection import GridSearchCV

# å®šç¾©åƒæ•¸ç¶²æ ¼
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [0.001, 0.01, 0.1, 1],
    'epsilon': [0.01, 0.1, 0.5]
}

# å»ºç«‹ç¶²æ ¼æœå°‹ç‰©ä»¶
grid_search = GridSearchCV(
    SVR(kernel='rbf'),
    param_grid,
    cv=5,                    # 5 æŠ˜äº¤å‰é©—è­‰
    scoring='neg_mean_squared_error',
    n_jobs=-1,               # ä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒ
    verbose=1
)

# åŸ·è¡Œæœå°‹
grid_search.fit(X_train_scaled, y_train_scaled)

# æœ€ä½³åƒæ•¸èˆ‡æ¨¡å‹
print("æœ€ä½³åƒæ•¸:", grid_search.best_params_)
print("æœ€ä½³ CV åˆ†æ•¸:", -grid_search.best_score_)
best_model = grid_search.best_estimator_
```

**æ–¹æ³• 2ï¼šéš¨æ©Ÿæœå°‹ (Random Search)**

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform, loguniform

# å®šç¾©åƒæ•¸åˆ†ä½ˆ
param_distributions = {
    'C': loguniform(0.1, 100),       # å°æ•¸å‡å‹»åˆ†ä½ˆ
    'gamma': loguniform(0.001, 1),
    'epsilon': uniform(0.01, 0.5)    # å‡å‹»åˆ†ä½ˆ
}

# å»ºç«‹éš¨æ©Ÿæœå°‹ç‰©ä»¶
random_search = RandomizedSearchCV(
    SVR(kernel='rbf'),
    param_distributions,
    n_iter=50,               # å˜—è©¦ 50 ç¨®åƒæ•¸çµ„åˆ
    cv=5,
    scoring='neg_mean_squared_error',
    n_jobs=-1,
    random_state=42
)

random_search.fit(X_train_scaled, y_train_scaled)
print("æœ€ä½³åƒæ•¸:", random_search.best_params_)
```

**æ–¹æ³• 3ï¼šè²è‘‰æ–¯å„ªåŒ–ï¼ˆé€²éšï¼‰**

```python
from sklearn.model_selection import cross_val_score
from skopt import BayesSearchCV

search_spaces = {
    'C': (0.1, 100, 'log-uniform'),
    'gamma': (0.001, 1, 'log-uniform'),
    'epsilon': (0.01, 0.5, 'uniform')
}

bayes_search = BayesSearchCV(
    SVR(kernel='rbf'),
    search_spaces,
    n_iter=32,
    cv=5,
    n_jobs=-1,
    random_state=42
)

bayes_search.fit(X_train_scaled, y_train_scaled)
```

### 4.4 æ¨¡å‹è©•ä¼°æŒ‡æ¨™

```python
from sklearn.metrics import (
    mean_squared_error, mean_absolute_error,
    r2_score, mean_absolute_percentage_error
)

# é æ¸¬
y_pred = model.predict(X_test_scaled)
y_pred = scaler_y.inverse_transform(y_pred.reshape(-1, 1)).ravel()

# è¨ˆç®—è©•ä¼°æŒ‡æ¨™
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred) * 100

print(f'å‡æ–¹èª¤å·® (MSE): {mse:.4f}')
print(f'å‡æ–¹æ ¹èª¤å·® (RMSE): {rmse:.4f}')
print(f'å¹³å‡çµ•å°èª¤å·® (MAE): {mae:.4f}')
print(f'æ±ºå®šä¿‚æ•¸ (RÂ²): {r2:.4f}')
print(f'å¹³å‡çµ•å°ç™¾åˆ†æ¯”èª¤å·® (MAPE): {mape:.2f}%')

# æ”¯æŒå‘é‡æ•¸é‡
n_support = len(model.support_)
print(f'æ”¯æŒå‘é‡æ•¸é‡: {n_support}/{len(X_train)} ({n_support/len(X_train)*100:.1f}%)')
```

### 4.5 æ¨¡å‹è§£é‡‹èˆ‡è¨ºæ–·

**1. æ”¯æŒå‘é‡åˆ†æ**

```python
# æ”¯æŒå‘é‡çš„ç´¢å¼•
support_indices = model.support_

# æ”¯æŒå‘é‡çš„ç‰¹å¾µå€¼
support_vectors = X_train_scaled[support_indices]

# æ”¯æŒå‘é‡çš„ç›®æ¨™å€¼
support_targets = y_train_scaled[support_indices]

# å°å¶ä¿‚æ•¸
dual_coef = model.dual_coef_

print(f'æ”¯æŒå‘é‡æ¯”ä¾‹: {len(support_indices)/len(X_train)*100:.1f}%')
print('å°å¶ä¿‚æ•¸çµ±è¨ˆ:')
print(f'  å¹³å‡å€¼: {np.mean(np.abs(dual_coef)):.4f}')
print(f'  æœ€å¤§å€¼: {np.max(np.abs(dual_coef)):.4f}')
```

æ”¯æŒå‘é‡æ¯”ä¾‹çš„æ„ç¾©ï¼š
- **< 30%**ï¼šæ¨¡å‹ç¨€ç–ï¼Œæ³›åŒ–èƒ½åŠ›å¼·
- **30-70%**ï¼šæ­£å¸¸ç¯„åœ
- **> 70%**ï¼šå¯èƒ½ `C` æˆ– `epsilon` è¨­å®šä¸ç•¶

**2. æ®˜å·®åˆ†æ**

```python
import matplotlib.pyplot as plt

# è¨ˆç®—æ®˜å·®
residuals = y_test - y_pred

# æ®˜å·®åˆ†ä½ˆåœ–
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.scatter(y_pred, residuals, alpha=0.5)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Residual Plot')

plt.subplot(1, 3, 2)
plt.hist(residuals, bins=30, edgecolor='black')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.title('Residual Distribution')

plt.subplot(1, 3, 3)
from scipy.stats import probplot
probplot(residuals, dist="norm", plot=plt)
plt.title('Q-Q Plot')

plt.tight_layout()
plt.show()
```

**3. é æ¸¬ vs å¯¦éš›å€¼**

```python
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], 
         [y_test.min(), y_test.max()], 
         'r--', lw=2, label='Perfect Prediction')

# Îµ-tube é‚Šç•Œ
epsilon_scaled = epsilon * scaler_y.scale_
plt.fill_between([y_test.min(), y_test.max()],
                 [y_test.min() - epsilon_scaled, y_test.max() - epsilon_scaled],
                 [y_test.min() + epsilon_scaled, y_test.max() + epsilon_scaled],
                 alpha=0.2, label=f'Îµ-tube (Îµ={epsilon})')

plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title(f'SVR Prediction (RÂ² = {r2:.3f})')
plt.legend()
plt.show()
```

### 4.6 ä¸åŒæ ¸å‡½æ•¸çš„æ¯”è¼ƒ

```python
kernels = ['linear', 'poly', 'rbf', 'sigmoid']
results = {}

for kernel in kernels:
    if kernel == 'poly':
        model = SVR(kernel=kernel, degree=3, C=10, epsilon=0.1)
    else:
        model = SVR(kernel=kernel, C=10, epsilon=0.1)
    
    model.fit(X_train_scaled, y_train_scaled)
    y_pred = model.predict(X_test_scaled)
    y_pred = scaler_y.inverse_transform(y_pred.reshape(-1, 1)).ravel()
    
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    
    results[kernel] = {'R2': r2, 'RMSE': rmse}
    print(f'{kernel:10s} - RÂ²: {r2:.4f}, RMSE: {rmse:.4f}')

# è¦–è¦ºåŒ–æ¯”è¼ƒ
import pandas as pd
df_results = pd.DataFrame(results).T
df_results.plot(kind='bar', figsize=(10, 5))
plt.title('Kernel Comparison')
plt.ylabel('Score')
plt.xticks(rotation=0)
plt.legend(['RÂ²', 'RMSE'])
plt.show()
```

---

## 5. åŒ–å·¥é ˜åŸŸå®Œæ•´æ¡ˆä¾‹ï¼šåæ‡‰å™¨æº«åº¦é æ¸¬

### 5.1 å•é¡Œæè¿°

**èƒŒæ™¯**ï¼šé€£çºŒæ”ªæ‹Œæ§½åæ‡‰å™¨ (CSTR) çš„æº«åº¦æ§åˆ¶å°ç”¢ç‰©å“è³ªè‡³é—œé‡è¦ã€‚æˆ‘å€‘å¸Œæœ›å»ºç«‹ SVR æ¨¡å‹ï¼Œæ ¹æ“šæ“ä½œæ¢ä»¶é æ¸¬åæ‡‰å™¨å‡ºå£æº«åº¦ã€‚

**è³‡æ–™é›†ç‰¹å¾µ**ï¼š
- `Feed_Temp`ï¼šé€²æ–™æº«åº¦ (Â°C)
- `Flow_Rate`ï¼šé€²æ–™æµé‡ (L/min)
- `Concentration`ï¼šåæ‡‰ç‰©æ¿ƒåº¦ (mol/L)
- `Jacket_Temp`ï¼šå¤¾å¥—æº«åº¦ (Â°C)
- `Agitation_Speed`ï¼šæ”ªæ‹Œé€Ÿåº¦ (rpm)

**ç›®æ¨™è®Šæ•¸**ï¼š
- `Reactor_Temp`ï¼šåæ‡‰å™¨å‡ºå£æº«åº¦ (Â°C)

**ç‰©ç†èƒŒæ™¯**ï¼š
- åæ‡‰ç‚ºæ”¾ç†±åæ‡‰ï¼Œæº«åº¦å—ç†±å¹³è¡¡å½±éŸ¿
- æµé‡èˆ‡æ¿ƒåº¦å½±éŸ¿åæ‡‰é€Ÿç‡å’Œç†±é‡‹æ”¾
- å¤¾å¥—æº«åº¦ç”¨æ–¼ç§»é™¤åæ‡‰ç†±
- æ”ªæ‹Œé€Ÿåº¦å½±éŸ¿å‚³ç†±æ•ˆç‡

### 5.2 å®Œæ•´ç¨‹å¼ç¢¼å¯¦ä½œ

å®Œæ•´çš„ç¨‹å¼ç¢¼å¯¦ä½œè«‹åƒè€ƒ Jupyter Notebook æª”æ¡ˆ `Unit11_Support_Vector_Machine.ipynb`ã€‚

**é—œéµæ­¥é©Ÿé è¦½**ï¼š

1. **è³‡æ–™ç”Ÿæˆ**ï¼šä½¿ç”¨ç‰©ç†æ¨¡å‹ç”Ÿæˆæ¨¡æ“¬è³‡æ–™
   ```python
   # éç·šæ€§é—œä¿‚æ¨¡æ“¬
   T_reactor = (0.6 * T_feed + 0.3 * T_jacket + 
                0.1 * flow_rate * concentration + 
                0.05 * agitation_speed + 
                0.02 * concentration**2 + noise)
   ```

2. **ç‰¹å¾µå·¥ç¨‹**ï¼š
   - æ¨™æº–åŒ–æ‰€æœ‰ç‰¹å¾µ
   - æª¢æŸ¥ç‰¹å¾µç›¸é—œæ€§

3. **æ¨¡å‹è¨“ç·´**ï¼š
   - åŸºç¤ SVR (RBF æ ¸)
   - ç¶²æ ¼æœå°‹è¶…åƒæ•¸å„ªåŒ–
   - å¤šæ ¸å‡½æ•¸æ¯”è¼ƒ

4. **çµæœåˆ†æ**ï¼š
   - è©•ä¼°æŒ‡æ¨™æ¯”è¼ƒ
   - æ”¯æŒå‘é‡åˆ†æ
   - æ®˜å·®è¨ºæ–·
   - é æ¸¬æ›²ç·šè¦–è¦ºåŒ–

5. **åŒ–å·¥æ„ç¾©è§£é‡‹**ï¼š
   - å“ªäº›åƒæ•¸å°æº«åº¦å½±éŸ¿æœ€å¤§ï¼Ÿ
   - æ¨¡å‹åœ¨å“ªäº›æ“ä½œå€é–“è¡¨ç¾æœ€å¥½ï¼Ÿ
   - æ˜¯å¦æ•æ‰åˆ°ç‰©ç†è¦å¾‹ï¼Ÿ

### 5.3 é æœŸçµæœ

**åŸºç¤ SVR æ¨¡å‹**ï¼š
- RÂ² â‰ˆ 0.85-0.90
- RMSE â‰ˆ 2-3Â°C
- æ”¯æŒå‘é‡æ¯”ä¾‹ â‰ˆ 40-50%

**å„ªåŒ–å¾Œ SVR æ¨¡å‹**ï¼š
- RÂ² â‰ˆ 0.92-0.95
- RMSE â‰ˆ 1-2Â°C
- æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›

**èˆ‡å…¶ä»–æ¨¡å‹æ¯”è¼ƒ**ï¼š
| æ¨¡å‹ | RÂ² | RMSE (Â°C) | è¨“ç·´æ™‚é–“ |
|------|----|---------|---------| 
| ç·šæ€§å›æ­¸ | 0.75 | 4.5 | å¿« |
| æ±ºç­–æ¨¹ | 0.88 | 3.1 | å¿« |
| éš¨æ©Ÿæ£®æ— | 0.91 | 2.7 | ä¸­ |
| **SVR (RBF)** | **0.93** | **2.4** | æ…¢ |

### 5.4 å¯¦éš›åŸ·è¡Œçµæœèˆ‡åˆ†æ

ä»¥ä¸‹ç‚º Jupyter Notebook åŸ·è¡Œå¾Œçš„å¯¦éš›çµæœèˆ‡è¨è«–ã€‚

#### 5.4.1 è³‡æ–™æ¢ç´¢æ€§åˆ†æ (EDA)

**è³‡æ–™é›†åŸºæœ¬è³‡è¨Š**ï¼š
- ç¸½æ¨£æœ¬æ•¸ï¼š300
- è¨“ç·´é›†ï¼š210 (70%)
- æ¸¬è©¦é›†ï¼š90 (30%)
- ç‰¹å¾µæ•¸é‡ï¼š5

**ç‰¹å¾µç¯„åœ**ï¼š
- `Feed_Temp` (é€²æ–™æº«åº¦)ï¼š20-80Â°C
- `Flow_Rate` (æµé‡)ï¼š1-10 L/min
- `Concentration` (æ¿ƒåº¦)ï¼š0.5-2.0 mol/L
- `Jacket_Temp` (å¤¾å¥—æº«åº¦)ï¼š10-60Â°C
- `Agitation_Speed` (æ”ªæ‹Œé€Ÿåº¦)ï¼š100-500 rpm

**ç›®æ¨™è®Šæ•¸**ï¼š
- `Reactor_Temp` (åæ‡‰å™¨æº«åº¦)ï¼š-10 to 100Â°C

![Feature Distributions](outputs/P3_Unit11_Support_Vector_Machine/figs/01_feature_distributions.png)

**ç‰¹å¾µåˆ†ä½ˆç‰¹é»**ï¼š
- æ‰€æœ‰ç‰¹å¾µå‡å‘ˆç¾å‡å‹»åˆ†ä½ˆï¼ˆuniform distributionï¼‰
- ç„¡æ¥µç«¯ç•°å¸¸å€¼
- ç¬¦åˆå¯¦é©—è¨­è¨ˆçš„å‡è¡¡æ¡æ¨£ç­–ç•¥

**ç›¸é—œæ€§åˆ†æ**ï¼š

![Correlation Analysis](outputs/P3_Unit11_Support_Vector_Machine/figs/02_correlation_matrix.png)

**é—œéµç™¼ç¾**ï¼š
1. **é€²æ–™æº«åº¦ (Feed_Temp)** èˆ‡åæ‡‰å™¨æº«åº¦ç›¸é—œæ€§æœ€é«˜ (r â‰ˆ 0.85)
   - åŒ–å·¥æ„ç¾©ï¼šé€²æ–™æ˜¯ä¸»è¦çš„ç†±æºè¼¸å…¥
2. **å¤¾å¥—æº«åº¦ (Jacket_Temp)** æ¬¡ä¹‹ (r â‰ˆ 0.55)
   - åŒ–å·¥æ„ç¾©ï¼šå¤¾å¥—æä¾›å†·å»/åŠ ç†±æ§åˆ¶
3. **æµé‡èˆ‡æ¿ƒåº¦** çš„äº¤äº’ä½œç”¨å½±éŸ¿åæ‡‰ç†±é‡‹æ”¾
4. **æ”ªæ‹Œé€Ÿåº¦** å°æº«åº¦å½±éŸ¿ç›¸å°è¼ƒå°
   - åŒ–å·¥æ„ç¾©ï¼šä¸»è¦å½±éŸ¿å‚³ç†±ä¿‚æ•¸è€Œéç›´æ¥å½±éŸ¿æº«åº¦

#### 5.4.2 åŸºç¤ SVR æ¨¡å‹ (RBF æ ¸)

**æ¨¡å‹é…ç½®**ï¼š
```python
SVR(kernel='rbf', C=10, epsilon=0.1, gamma=0.2)
```

**è¨“ç·´çµæœ**ï¼š

| æŒ‡æ¨™ | è¨“ç·´é›† | æ¸¬è©¦é›† |
|------|--------|--------|
| **RÂ² Score** | 0.9936 | 0.9775 |
| **RMSE** | 2.07 Â°C | 3.69 Â°C |
| **MAE** | 1.86 Â°C | 3.01 Â°C |
| **MAPE** | 39.23% | 50.51% |

**æ”¯æŒå‘é‡åˆ†æ**ï¼š
- æ”¯æŒå‘é‡æ•¸é‡ï¼š106/210 (50.5%)
- âœ“ æ¯”ä¾‹åœ¨æ­£å¸¸ç¯„åœ (30-70%)
- è¨“ç·´æ™‚é–“ï¼š0.01 ç§’

**éæ“¬åˆæª¢æŸ¥**ï¼š
- RÂ² å·®ç•°ï¼š0.0161 (1.61%)
- âœ“ **ç„¡æ˜é¡¯éæ“¬åˆ**

![SVR Predictions](outputs/P3_Unit11_Support_Vector_Machine/figs/04_basic_svr_prediction.png)

**é æ¸¬è¡¨ç¾è§€å¯Ÿ**ï¼š
- é æ¸¬å€¼èˆ‡çœŸå¯¦å€¼é«˜åº¦ä¸€è‡´ï¼ˆæ¥è¿‘ 45Â° å°è§’ç·šï¼‰
- æ¸¬è©¦é›†ç•¥æœ‰åˆ†æ•£ä½†ä»ä¿æŒè‰¯å¥½ç›¸é—œæ€§
- é¡¯ç¤ºæ¨¡å‹æˆåŠŸæ•æ‰åˆ°æº«åº¦é æ¸¬çš„ä¸»è¦æ¨¡å¼

![Residual Analysis](outputs/P3_Unit11_Support_Vector_Machine/figs/05_residual_analysis.png)

**æ®˜å·®åˆ†æ**ï¼š
1. **æ®˜å·®åˆ†ä½ˆè¿‘ä¼¼å¸¸æ…‹**ï¼ˆå·¦ä¸Šåœ–ï¼‰
   - å‡å€¼æ¥è¿‘ 0
   - ç„¡æ˜é¡¯åæ…‹
2. **æ®˜å·®ç„¡æ˜é¡¯æ¨¡å¼**ï¼ˆå³ä¸Šåœ–ï¼‰
   - éš¨æ©Ÿåˆ†æ•£
   - âœ“ æ¨¡å‹å‡è¨­åˆç†
3. **æ®˜å·® Q-Q åœ–**ï¼ˆå·¦ä¸‹åœ–ï¼‰
   - å¤§éƒ¨åˆ†é»è½åœ¨å°è§’ç·šä¸Š
   - å°¾éƒ¨ç•¥æœ‰åé›¢ï¼ˆå¯èƒ½æœ‰å°‘æ•¸ç•°å¸¸é»ï¼‰
4. **æ®˜å·®éš¨é æ¸¬å€¼è®ŠåŒ–**ï¼ˆå³ä¸‹åœ–ï¼‰
   - ç„¡æ˜é¡¯ç•°æ–¹å·®æ€§
   - âœ“ èª¤å·®ç©©å®š

**åŒ–å·¥æ„ç¾©è§£è®€**ï¼š
- æ¨¡å‹èª¤å·® Â±3.7Â°C å°æ–¼ CSTR æº«åº¦æ§åˆ¶è€Œè¨€æ˜¯**å¯æ¥å—çš„ç²¾åº¦**
- 50.5% æ”¯æŒå‘é‡æ¯”ä¾‹é¡¯ç¤ºè³‡æ–™å…·æœ‰**é©åº¦çš„è¤‡é›œæ€§**
- ç„¡éæ“¬åˆè·¡è±¡è¡¨æ˜æ¨¡å‹å…·æœ‰è‰¯å¥½çš„**æ³›åŒ–èƒ½åŠ›**

#### 5.4.3 ä¸åŒæ ¸å‡½æ•¸æ€§èƒ½æ¯”è¼ƒ

**æ¸¬è©¦ä¸‰ç¨®æ ¸å‡½æ•¸**ï¼š

| æ ¸å‡½æ•¸ | RÂ² | RMSE (Â°C) | MAE (Â°C) | æ”¯æŒå‘é‡ | è¨“ç·´æ™‚é–“ (s) |
|--------|-------|-----------|----------|----------|--------------|
| **RBF** | **0.9775** | **3.69** | **3.01** | 106/210 | 0.0095 |
| Linear | 0.9505 | 5.48 | 4.11 | 146/210 | 0.0401 |
| Poly | 0.8242 | 10.32 | 8.57 | 158/210 | 0.0356 |

![Kernel Comparison](outputs/P3_Unit11_Support_Vector_Machine/figs/06_kernel_comparison.png)

**æ ¸å‡½æ•¸åˆ†æ**ï¼š

1. **RBF æ ¸**ï¼ˆå¾‘å‘åŸºå‡½æ•¸ï¼‰
   - âœ“ **æœ€ä½³æ€§èƒ½**ï¼šRÂ² = 0.9775
   - âœ“ æœ€ä½èª¤å·®ï¼šRMSE = 3.69Â°C
   - âœ“ æœ€å°‘æ”¯æŒå‘é‡ (50.5%) â†’ æ¨¡å‹æœ€ç°¡æ½”
   - **æ¨è–¦ä½¿ç”¨**ï¼šé©åˆè™•ç†éç·šæ€§é—œä¿‚

2. **Linear æ ¸**ï¼ˆç·šæ€§æ ¸ï¼‰
   - æ¬¡ä½³æ€§èƒ½ï¼šRÂ² = 0.9505
   - è¼ƒé«˜èª¤å·®ï¼šRMSE = 5.48Â°C
   - æ›´å¤šæ”¯æŒå‘é‡ (69.5%) â†’ è³‡æ–™ç„¡æ³•å®Œç¾ç·šæ€§åˆ†é›¢
   - è¨“ç·´æ™‚é–“è¼ƒé•·ï¼ˆéœ€è™•ç†æ›´å¤šæ”¯æŒå‘é‡ï¼‰
   - **é©ç”¨å ´æ™¯**ï¼šè³‡æ–™æ¥è¿‘ç·šæ€§é—œä¿‚æ™‚

3. **Polynomial æ ¸**ï¼ˆå¤šé …å¼æ ¸ï¼‰
   - âœ— æ€§èƒ½æœ€å·®ï¼šRÂ² = 0.8242
   - âœ— èª¤å·®æœ€å¤§ï¼šRMSE = 10.32Â°C
   - æ”¯æŒå‘é‡æœ€å¤š (75.2%) â†’ æ¨¡å‹éæ–¼è¤‡é›œ
   - **ä¸æ¨è–¦**ï¼šå¯èƒ½å—åƒæ•¸é…ç½®å½±éŸ¿ï¼ˆdegree, coef0ï¼‰

**åŒ–å·¥æ„ç¾©**ï¼š
- RBF æ ¸æˆåŠŸæ•æ‰åˆ° CSTR æº«åº¦çš„**éç·šæ€§ç†±å¹³è¡¡é—œä¿‚**
- Linear æ ¸æ€§èƒ½å°šå¯èªªæ˜ç³»çµ±å…·æœ‰**ä¸€å®šçš„ç·šæ€§ä¸»å°æˆåˆ†**
- Poly æ ¸è¡¨ç¾ä¸ä½³å¯èƒ½å› ç‚ºé è¨­åƒæ•¸ (degree=3) ä¸é©åˆæ­¤å•é¡Œ

#### 5.4.4 è¶…åƒæ•¸å„ªåŒ– (Grid Search)

**å„ªåŒ–é…ç½®**ï¼š
- æœå°‹æ–¹æ³•ï¼š5-fold Cross-Validation
- åƒæ•¸çµ„åˆæ•¸ï¼š64
- æœå°‹ç©ºé–“ï¼š
  - `C`: [1, 10, 50, 100]
  - `gamma`: [0.001, 0.01, 0.1, 1]
  - `epsilon`: [0.01, 0.05, 0.1, 0.2]

**å„ªåŒ–çµæœ**ï¼š

```
æœ€ä½³è¶…åƒæ•¸ï¼š
  C = 100
  gamma = 0.01
  epsilon = 0.1

æœ€ä½³äº¤å‰é©—è­‰ RÂ² = 0.9885
ç¸½è¨“ç·´æ™‚é–“ = 5.64 ç§’
```

**å„ªåŒ–å¾Œæ€§èƒ½**ï¼š

| æŒ‡æ¨™ | å„ªåŒ–å‰ | å„ªåŒ–å¾Œ | æå‡ |
|------|--------|--------|------|
| **æ¸¬è©¦é›† RÂ²** | 0.9775 | 0.9867 | **+0.95%** |
| **æ¸¬è©¦é›† RMSE** | 3.69 Â°C | 2.84 Â°C | **-23.20%** |
| **æ¸¬è©¦é›† MAE** | 3.01 Â°C | 2.18 Â°C | **-27.64%** |
| **æ¸¬è©¦é›† MAPE** | 50.51% | 32.79% | **-35.09%** |
| **è¨“ç·´é›† RÂ²** | 0.9936 | 0.9914 | -0.22% |

![Grid Search and Optimization Results](outputs/P3_Unit11_Support_Vector_Machine/figs/07_optimization_comparison.png)

**è¶…åƒæ•¸å½±éŸ¿åˆ†æ**ï¼š

1. **C åƒæ•¸æ•ˆæœ**ï¼š
   - C=100 é”åˆ°æœ€ä½³å¹³è¡¡
   - éå¤§çš„ C (>100) å¯èƒ½å°è‡´éæ“¬åˆ
   - éå°çš„ C (<10) æ¬ æ“¬åˆ

2. **gamma åƒæ•¸æ•ˆæœ**ï¼š
   - gamma=0.01 æœ€ä½³ï¼ˆè¼ƒå°å€¼ï¼‰
   - èªªæ˜æ±ºç­–é‚Šç•Œéœ€è¦**è¼ƒå¹³æ»‘çš„æ›²ç·š**
   - éå¤§çš„ gamma (>0.1) å°è‡´éæ“¬åˆ

3. **epsilon åƒæ•¸æ•ˆæœ**ï¼š
   - epsilon=0.1 é”åˆ°æœ€ä½³å®¹å¿åº¦
   - è¼ƒå°çš„ epsilon (0.01) éæ–¼åš´æ ¼
   - è¼ƒå¤§çš„ epsilon (>0.2) æå¤±ç²¾åº¦

**å„ªåŒ–å¾Œæ¨¡å‹ç‰¹é»**ï¼š
- âœ“ **RMSE é™ä½ 23.20%**ï¼ˆå¾ 3.69Â°C â†’ 2.84Â°Cï¼‰
- âœ“ **é æ¸¬ç²¾åº¦é¡¯è‘—æå‡**
- âœ“ **è¨“ç·´é›† RÂ² ç•¥é™** (0.9936 â†’ 0.9914)ï¼šæ­£å¸¸ç¾è±¡ï¼Œé¿å…éæ“¬åˆ
- âœ“ **æ³›åŒ–èƒ½åŠ›å¢å¼·**

**å·¥ç¨‹æ‡‰ç”¨è©•ä¼°**ï¼š
- **èª¤å·® Â±2.8Â°C** å°æ–¼ CSTR æº«åº¦æ§åˆ¶æ˜¯**å„ªç§€çš„ç²¾åº¦**
- å¯ç”¨æ–¼ï¼š
  - æº«åº¦è»Ÿæ¸¬é‡ï¼ˆSoft Sensorï¼‰
  - å‰é¥‹æ§åˆ¶ç­–ç•¥
  - æ“ä½œæ¢ä»¶å„ªåŒ–
  - ç•°å¸¸åµæ¸¬åŸºæº–

#### 5.4.5 é—œéµç™¼ç¾èˆ‡çµè«–

**æ¨¡å‹æ€§èƒ½ç¸½çµ**ï¼š
1. **SVR (RBF æ ¸)** æˆåŠŸå»ºç«‹é«˜ç²¾åº¦æº«åº¦é æ¸¬æ¨¡å‹
   - æ¸¬è©¦é›† RÂ² = 0.9867
   - RMSE = 2.84Â°C
   - æ»¿è¶³å·¥ç¨‹æ‡‰ç”¨éœ€æ±‚

2. **æ ¸å‡½æ•¸é¸æ“‡**ï¼š
   - RBF > Linear > Polynomial
   - RBF æ ¸æœ€é©åˆè™•ç† CSTR çš„éç·šæ€§ç†±å¹³è¡¡

3. **è¶…åƒæ•¸å„ªåŒ–æ•ˆæœ**ï¼š
   - é€šé Grid Search æå‡ RMSE 23.20%
   - æœ€ä½³é…ç½®ï¼šC=100, gamma=0.01, epsilon=0.1

4. **åŒ–å·¥æ„ç¾©é©—è­‰**ï¼š
   - âœ“ æ¨¡å‹æ•æ‰åˆ°ä¸»è¦ç‰©ç†è¦å¾‹ï¼ˆé€²æ–™æº«åº¦ä¸»å°ï¼‰
   - âœ“ æ®˜å·®åˆ†æç„¡ç³»çµ±æ€§åå·®
   - âœ“ æ”¯æŒå‘é‡æ¯”ä¾‹åˆç†

**å¯¦å‹™å»ºè­°**ï¼š
- å°æ–¼æ–°çš„ CSTR ç³»çµ±ï¼Œå»ºè­°å…ˆå˜—è©¦ RBF æ ¸
- ä½¿ç”¨ Grid Search é€²è¡Œè¶…åƒæ•¸å„ªåŒ–
- ä¿ç•™æ¸¬è©¦é›†ç”¨æ–¼æœ€çµ‚æ€§èƒ½é©—è­‰
- ç›£æ§æ”¯æŒå‘é‡æ¯”ä¾‹ï¼ˆå»ºè­° 30-70%ï¼‰

---

## 6. SVR çš„å„ªå‹¢èˆ‡é™åˆ¶

### 6.1 å„ªå‹¢

1. **å¼·å¤§çš„éç·šæ€§å»ºæ¨¡èƒ½åŠ›**ï¼š
   - æ ¸å‡½æ•¸æŠ€å·§è™•ç†è¤‡é›œé—œä¿‚
   - ç„¡éœ€æ‰‹å‹•ç‰¹å¾µå·¥ç¨‹

2. **é­¯æ£’æ€§å¼·**ï¼š
   - Îµ-insensitive loss å°å°èª¤å·®ä¸æ•æ„Ÿ
   - å°ç•°å¸¸å€¼æœ‰ä¸€å®šæŠµæŠ—åŠ›

3. **æ³›åŒ–èƒ½åŠ›å¥½**ï¼š
   - æœ€å¤§é–“éš”åŸå‰‡æ¸›å°‘éæ“¬åˆ
   - ç†è«–åŸºç¤å …å¯¦ï¼ˆVC ç¶­ç†è«–ï¼‰

4. **ç¨€ç–è§£**ï¼š
   - åªæœ‰æ”¯æŒå‘é‡åƒèˆ‡é æ¸¬
   - è¨˜æ†¶é«”é«˜æ•ˆï¼Œé æ¸¬é€Ÿåº¦å¿«

5. **é©ç”¨æ–¼é«˜ç¶­è³‡æ–™**ï¼š
   - æ ¸æ–¹æ³•éš±å¼è™•ç†é«˜ç¶­æ˜ å°„
   - å°æ¨£æœ¬æƒ…æ³ä¸‹è¡¨ç¾å„ªç•°

### 6.2 é™åˆ¶

1. **è¨“ç·´é€Ÿåº¦æ…¢**ï¼š
   - æ™‚é–“è¤‡é›œåº¦ O(NÂ²) åˆ° O(NÂ³)
   - ä¸é©åˆè¶…å¤§è³‡æ–™é›†ï¼ˆN > 10,000ï¼‰

2. **è¶…åƒæ•¸èª¿æ•´è¤‡é›œ**ï¼š
   - éœ€åŒæ™‚èª¿æ•´ Cã€epsilonã€gamma
   - å°åƒæ•¸é¸æ“‡æ•æ„Ÿ

3. **å¯è§£é‡‹æ€§è¼ƒå·®**ï¼š
   - æ ¸æ–¹æ³•çš„é»‘ç®±ç‰¹æ€§
   - é›£ä»¥ç›´è§€ç†è§£ç‰¹å¾µå½±éŸ¿

4. **å°è³‡æ–™é è™•ç†æ•æ„Ÿ**ï¼š
   - å¿…é ˆé€²è¡Œæ¨™æº–åŒ–
   - ç•°å¸¸å€¼éœ€è¬¹æ…è™•ç†

5. **è¨˜æ†¶é«”éœ€æ±‚**ï¼š
   - éœ€å­˜å„²æ ¸çŸ©é™£ï¼ˆå°å¤§è³‡æ–™é›†ï¼‰
   - é›–æœ‰ç¨€ç–æ€§ï¼Œä½†ä»éœ€å„²å­˜æ”¯æŒå‘é‡

### 6.3 é©ç”¨å ´æ™¯å»ºè­°

**å»ºè­°ä½¿ç”¨ SVR çš„æƒ…æ³**ï¼š
- âœ“ ä¸­å°è¦æ¨¡è³‡æ–™é›†ï¼ˆN < 10,000ï¼‰
- âœ“ ç‰¹å¾µèˆ‡ç›®æ¨™é–“å­˜åœ¨è¤‡é›œéç·šæ€§é—œä¿‚
- âœ“ éœ€è¦é«˜é æ¸¬ç²¾åº¦
- âœ“ è³‡æ–™å­˜åœ¨ä¸€å®šå™ªè²æˆ–ç•°å¸¸å€¼
- âœ“ ç‰¹å¾µç¶­åº¦è¼ƒé«˜

**ä¸å»ºè­°ä½¿ç”¨ SVR çš„æƒ…æ³**ï¼š
- âœ— è¶…å¤§è³‡æ–™é›†ï¼ˆN > 50,000ï¼‰
- âœ— éœ€è¦å³æ™‚ç·šä¸Šè¨“ç·´
- âœ— é«˜åº¦è¦æ±‚å¯è§£é‡‹æ€§
- âœ— è¨ˆç®—è³‡æºæ¥µåº¦å—é™

**æ›¿ä»£æ–¹æ¡ˆ**ï¼š
- **å¤§è³‡æ–™é›†**ï¼šç·šæ€§ SVRã€éš¨æ©Ÿæ£®æ—ã€XGBoost
- **é€Ÿåº¦å„ªå…ˆ**ï¼šæ±ºç­–æ¨¹ã€ç·šæ€§å›æ­¸
- **å¯è§£é‡‹æ€§**ï¼šç·šæ€§å›æ­¸ã€æ±ºç­–æ¨¹ã€GAM
- **è¤‡é›œéç·šæ€§**ï¼šéš¨æ©Ÿæ£®æ—ã€æ¢¯åº¦æå‡ã€ç¥ç¶“ç¶²è·¯

---

## 7. é€²éšä¸»é¡Œ

### 7.1 ç·šæ€§ SVR vs éç·šæ€§ SVR

**LinearSVRï¼ˆsklearn.svm.LinearSVRï¼‰**ï¼š
- å°ˆç‚ºç·šæ€§æ ¸å„ªåŒ–ï¼Œä½¿ç”¨ liblinear åº«
- è¨“ç·´é€Ÿåº¦å¿«å¾—å¤šï¼ˆé©ç”¨æ–¼å¤§è³‡æ–™é›†ï¼‰
- ä¸æ”¯æ´æ ¸æŠ€å·§

```python
from sklearn.svm import LinearSVR

model = LinearSVR(
    epsilon=0.1,
    C=1.0,
    max_iter=1000,
    dual=True  # n_samples > n_features æ™‚ä½¿ç”¨ dual=True
)
```

**ä½•æ™‚ä½¿ç”¨**ï¼š
- ç‰¹å¾µèˆ‡ç›®æ¨™å‘ˆç·šæ€§é—œä¿‚
- è³‡æ–™é›†è¦æ¨¡å¤§ï¼ˆ> 10,000 æ¨£æœ¬ï¼‰
- éœ€è¦å¿«é€Ÿè¨“ç·´

### 7.2 Nu-SVR

**NuSVR (sklearn.svm.NuSVR)**ï¼š
- ä½¿ç”¨åƒæ•¸ `nu` å–ä»£ `epsilon`
- `nu` âˆˆ (0, 1]ï¼Œæ§åˆ¶æ”¯æŒå‘é‡çš„æ¯”ä¾‹ä¸Šç•Œå’Œè¨“ç·´èª¤å·®çš„ä¸‹ç•Œ

```python
from sklearn.svm import NuSVR

model = NuSVR(
    nu=0.5,        # å–ä»£ epsilon
    C=1.0,
    kernel='rbf'
)
```

**nu çš„æ„ç¾©**ï¼š
- `nu=0.5`ï¼šè‡³å¤š 50% çš„æ¨£æœ¬å¯ä»¥æ˜¯æ”¯æŒå‘é‡
- æ›´ç›´è§€åœ°æ§åˆ¶æ¨¡å‹è¤‡é›œåº¦

### 7.3 å¤šè¼¸å‡º SVR

**MultiOutputRegressor**ï¼š
ç•¶æœ‰å¤šå€‹ç›®æ¨™è®Šæ•¸æ™‚ï¼Œå¯ç‚ºæ¯å€‹è¼¸å‡ºè¨“ç·´ç¨ç«‹çš„ SVRï¼š

```python
from sklearn.multioutput import MultiOutputRegressor

model = MultiOutputRegressor(
    SVR(kernel='rbf', C=10, epsilon=0.1)
)
model.fit(X_train, y_train_multioutput)
```

### 7.4 é›†æˆ SVR

**Bagging SVR**ï¼š

```python
from sklearn.ensemble import BaggingRegressor

bagging_svr = BaggingRegressor(
    base_estimator=SVR(kernel='rbf', C=10),
    n_estimators=10,
    random_state=42
)
bagging_svr.fit(X_train, y_train)
```

**å„ªé»**ï¼š
- é€²ä¸€æ­¥é™ä½è®Šç•°
- æå‡ç©©å®šæ€§

**ç¼ºé»**ï¼š
- è¨“ç·´æ™‚é–“å¢åŠ  n_estimators å€

### 7.5 èˆ‡æ·±åº¦å­¸ç¿’çš„æ¯”è¼ƒ

| ç‰¹æ€§ | SVR | ç¥ç¶“ç¶²è·¯ (DNN) |
|------|-----|---------------|
| **è³‡æ–™éœ€æ±‚** | å°åˆ°ä¸­ï¼ˆ< 10,000ï¼‰ | å¤§ï¼ˆ> 10,000ï¼‰ |
| **è¨“ç·´æ™‚é–“** | ä¸­åˆ°æ…¢ | æ…¢ï¼ˆä½†å¯æ‰¹æ¬¡è¨“ç·´ï¼‰ |
| **è¶…åƒæ•¸èª¿æ•´** | è¤‡é›œ | éå¸¸è¤‡é›œ |
| **å¯æ“´å±•æ€§** | å·® | å„ªç§€ |
| **å¯è§£é‡‹æ€§** | ä½ | æ¥µä½ |
| **ç†è«–ä¿è­‰** | æœ‰ï¼ˆçµ±è¨ˆå­¸ç¿’ç†è«–ï¼‰ | æœ‰é™ |

**é¸æ“‡å»ºè­°**ï¼š
- **å°è³‡æ–™é›†ï¼ˆ< 5,000ï¼‰**ï¼šSVR é€šå¸¸å„ªæ–¼ç¥ç¶“ç¶²è·¯
- **å¤§è³‡æ–™é›†ï¼ˆ> 50,000ï¼‰**ï¼šç¥ç¶“ç¶²è·¯æ›´é©åˆ
- **éœ€è¦ç†è«–ä¿è­‰**ï¼šSVR
- **æ¥µè¤‡é›œéç·šæ€§**ï¼šæ·±åº¦ç¥ç¶“ç¶²è·¯

---

## 8. å¯¦å‹™æŠ€å·§èˆ‡æ³¨æ„äº‹é …

### 8.1 è³‡æ–™é è™•ç†æª¢æŸ¥æ¸…å–®

- [ ] **ç‰¹å¾µæ¨™æº–åŒ–**ï¼šä½¿ç”¨ `StandardScaler`
- [ ] **ç›®æ¨™è®Šæ•¸æ¨™æº–åŒ–**ï¼šæœ‰åŠ©æ–¼è¨­å®š epsilon
- [ ] **ç¼ºå¤±å€¼è™•ç†**ï¼šSVR ä¸æ¥å— NaN
- [ ] **ç•°å¸¸å€¼æª¢æ¸¬**ï¼šä½¿ç”¨ IQR æˆ– Z-score
- [ ] **ç‰¹å¾µç›¸é—œæ€§**ï¼šç§»é™¤é«˜åº¦ç›¸é—œç‰¹å¾µï¼ˆ> 0.95ï¼‰
- [ ] **ç‰¹å¾µé¸æ“‡**ï¼šä½¿ç”¨ RFE æˆ–ç‰¹å¾µé‡è¦æ€§

### 8.2 è¶…åƒæ•¸èª¿æ•´ç­–ç•¥

**éšæ®µ 1ï¼šç²—æœå°‹**
```python
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [0.001, 0.01, 0.1, 1],
    'epsilon': [0.1]  # å…ˆå›ºå®š
}
```

**éšæ®µ 2ï¼šç²¾ç´°æœå°‹**
```python
# å‡è¨­ç²—æœå°‹æ‰¾åˆ° C=10, gamma=0.1
param_grid = {
    'C': [5, 10, 15, 20],
    'gamma': [0.05, 0.1, 0.15, 0.2],
    'epsilon': [0.05, 0.1, 0.15]
}
```

**éšæ®µ 3ï¼šé©—è­‰**
- ä½¿ç”¨æœ€ä½³åƒæ•¸åœ¨æ¸¬è©¦é›†ä¸Šé©—è­‰
- æª¢æŸ¥æ˜¯å¦éæ“¬åˆ

### 8.3 å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

**å•é¡Œ 1ï¼šè¨“ç·´æ™‚é–“éé•·**

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
- æ¸›å°‘è¨“ç·´æ¨£æœ¬æ•¸ï¼ˆéš¨æ©Ÿæ¡æ¨£ï¼‰
- ä½¿ç”¨ `LinearSVR` ä»£æ›¿ `SVR(kernel='linear')`
- å¢åŠ  `cache_size`ï¼ˆé è¨­ 200MBï¼‰
- èª¿æ•´ `tol`ï¼ˆæ”¾å¯¬æ”¶æ–‚æ¢ä»¶ï¼‰

**å•é¡Œ 2ï¼šæ¨¡å‹éæ“¬åˆ**

**ç—‡ç‹€**ï¼šè¨“ç·´é›† RÂ² é«˜ï¼Œæ¸¬è©¦é›† RÂ² ä½

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
- æ¸›å° `C`ï¼ˆå…è¨±æ›´å¤šèª¤å·®ï¼‰
- å¢å¤§ `epsilon`ï¼ˆæ”¾å¯¬èª¤å·®å®¹å¿åº¦ï¼‰
- æ¸›å° `gamma`ï¼ˆä½¿ç”¨æ›´å¹³æ»‘çš„æ ¸ï¼‰
- å¢åŠ è¨“ç·´è³‡æ–™æˆ–ä½¿ç”¨æ­£å‰‡åŒ–

**å•é¡Œ 3ï¼šæ¨¡å‹æ¬ æ“¬åˆ**

**ç—‡ç‹€**ï¼šè¨“ç·´é›†å’Œæ¸¬è©¦é›† RÂ² éƒ½ä½

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
- å¢å¤§ `C`ï¼ˆåš´æ ¼æ“¬åˆï¼‰
- æ¸›å° `epsilon`
- å¢å¤§ `gamma`ï¼ˆæ›´è¤‡é›œçš„æ ¸ï¼‰
- æª¢æŸ¥æ˜¯å¦ä½¿ç”¨éŒ¯èª¤çš„æ ¸å‡½æ•¸ï¼ˆå¦‚ç·šæ€§æ ¸ç”¨æ–¼éç·šæ€§å•é¡Œï¼‰

**å•é¡Œ 4ï¼šé æ¸¬çµæœç•°å¸¸**

**æª¢æŸ¥**ï¼š
- æ˜¯å¦å¿˜è¨˜æ¨™æº–åŒ–æ¸¬è©¦é›†ï¼Ÿ
- æ˜¯å¦ä½¿ç”¨è¨“ç·´é›†çš„ scaler é€²è¡Œè½‰æ›ï¼Ÿ
- æ˜¯å¦é€²è¡Œåæ¨™æº–åŒ–ï¼Ÿ

**å•é¡Œ 5ï¼šæ”¯æŒå‘é‡éå¤šï¼ˆ> 80%ï¼‰**

**åŸå› **ï¼š
- `C` å¤ªå¤§
- `epsilon` å¤ªå°
- æ ¸å‡½æ•¸ä¸é©åˆ

**è§£æ±º**ï¼š
- æ¸›å° `C`
- å¢å¤§ `epsilon`
- å˜—è©¦ä¸åŒæ ¸å‡½æ•¸

### 8.4 æ¨¡å‹éƒ¨ç½²å»ºè­°

**å„²å­˜æ¨¡å‹**ï¼š
```python
import joblib

# å„²å­˜æ¨¡å‹å’Œæ¨™æº–åŒ–å™¨
joblib.dump(model, 'svr_model.pkl')
joblib.dump(scaler_X, 'scaler_X.pkl')
joblib.dump(scaler_y, 'scaler_y.pkl')
```

**è¼‰å…¥æ¨¡å‹**ï¼š
```python
model = joblib.load('svr_model.pkl')
scaler_X = joblib.load('scaler_X.pkl')
scaler_y = joblib.load('scaler_y.pkl')

# é æ¸¬æ–°è³‡æ–™
X_new_scaled = scaler_X.transform(X_new)
y_pred_scaled = model.predict(X_new_scaled)
y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))
```

**éƒ¨ç½²æª¢æŸ¥æ¸…å–®**ï¼š
- [ ] å„²å­˜æ¨¡å‹å’Œæ‰€æœ‰æ¨™æº–åŒ–å™¨
- [ ] è¨˜éŒ„è¨“ç·´æ™‚çš„ç‰¹å¾µé †åº
- [ ] è¨˜éŒ„è¶…åƒæ•¸è¨­å®š
- [ ] æº–å‚™è¼¸å…¥è³‡æ–™é©—è­‰é‚è¼¯
- [ ] è¨­ç½®é æ¸¬ä¿¡è³´å€é–“ï¼ˆå¦‚é©ç”¨ï¼‰

---

## 9. ç¸½çµ

### 9.1 é—œéµè¦é»

1. **SVR çš„æ ¸å¿ƒæ€æƒ³**ï¼š
   - Îµ-insensitive lossï¼šå®¹å¿å°èª¤å·®
   - é–“éš”æœ€å¤§åŒ–ï¼šå°‹æ‰¾æœ€å¹³å¦çš„å‡½æ•¸
   - æ ¸æŠ€å·§ï¼šè™•ç†éç·šæ€§é—œä¿‚

2. **é—œéµè¶…åƒæ•¸**ï¼š
   - **C**ï¼šæ§åˆ¶æ‡²ç½°å¼·åº¦ï¼ˆæ“¬åˆåš´æ ¼åº¦ï¼‰
   - **epsilon**ï¼šå®šç¾©èª¤å·®å®¹å¿å¸¶å¯¬åº¦
   - **gamma**ï¼šæ§åˆ¶æ ¸å‡½æ•¸å½±éŸ¿ç¯„åœï¼ˆåƒ… RBF/poly/sigmoidï¼‰
   - **kernel**ï¼šé¸æ“‡åˆé©çš„æ ¸å‡½æ•¸é¡å‹

3. **ä½¿ç”¨è¦é»**ï¼š
   - **å¿…é ˆ**é€²è¡Œè³‡æ–™æ¨™æº–åŒ–
   - é€šéäº¤å‰é©—è­‰é¸æ“‡è¶…åƒæ•¸
   - åˆ†ææ”¯æŒå‘é‡æ¯”ä¾‹åˆ¤æ–·æ¨¡å‹ç‹€æ…‹
   - é©ç”¨æ–¼ä¸­å°è¦æ¨¡ã€éç·šæ€§ã€æœ‰å™ªè²çš„è³‡æ–™

4. **å„ªå‹¢**ï¼š
   - é­¯æ£’ã€æ³›åŒ–èƒ½åŠ›å¼·ã€ç¨€ç–è§£ã€é«˜ç¶­é©ç”¨

5. **é™åˆ¶**ï¼š
   - è¨“ç·´æ…¢ã€è¶…åƒæ•¸è¤‡é›œã€å¯è§£é‡‹æ€§å·®

### 9.2 èˆ‡å…¶ä»–éç·šæ€§æ¨¡å‹çš„æ¯”è¼ƒ

| æ¨¡å‹ | éç·šæ€§èƒ½åŠ› | è¨“ç·´é€Ÿåº¦ | å°æ¨£æœ¬ | é­¯æ£’æ€§ | å¯è§£é‡‹æ€§ | è¶…åƒæ•¸ |
|------|----------|---------|--------|--------|---------|-------|
| **SVR** | âœ“âœ“âœ“ | âœ— | âœ“âœ“âœ“ | âœ“âœ“âœ“ | âœ— | è¤‡é›œ |
| å¤šé …å¼å›æ­¸ | âœ“ | âœ“âœ“âœ“ | âœ“âœ“ | âœ— | âœ“âœ“âœ“ | ç°¡å–® |
| æ±ºç­–æ¨¹ | âœ“âœ“ | âœ“âœ“âœ“ | âœ“ | âœ“âœ“ | âœ“âœ“âœ“ | ç°¡å–® |
| éš¨æ©Ÿæ£®æ— | âœ“âœ“âœ“ | âœ“âœ“ | âœ“âœ“ | âœ“âœ“âœ“ | âœ“âœ“ | ä¸­ç­‰ |
| æ¢¯åº¦æå‡ | âœ“âœ“âœ“ | âœ“ | âœ“âœ“ | âœ“âœ“ | âœ“ | è¤‡é›œ |
| GPR | âœ“âœ“âœ“ | âœ—âœ— | âœ“âœ“âœ“ | âœ“âœ“âœ“ | âœ“ | è¤‡é›œ |

### 9.3 é¸æ“‡æ±ºç­–æ¨¹

```
è³‡æ–™é‡ < 10,000ï¼Ÿ
â”œâ”€ æ˜¯ â†’ éç·šæ€§é—œä¿‚ï¼Ÿ
â”‚      â”œâ”€ æ˜¯ â†’ éœ€è¦ä¸ç¢ºå®šæ€§é‡åŒ–ï¼Ÿ
â”‚      â”‚      â”œâ”€ æ˜¯ â†’ é«˜æ–¯éç¨‹å›æ­¸ (GPR)
â”‚      â”‚      â””â”€ å¦ â†’ SVR (RBF)
â”‚      â””â”€ å¦ â†’ ç·šæ€§å›æ­¸
â””â”€ å¦ â†’ éç·šæ€§é—œä¿‚ï¼Ÿ
       â”œâ”€ æ˜¯ â†’ éš¨æ©Ÿæ£®æ— / æ¢¯åº¦æå‡
       â””â”€ å¦ â†’ ç·šæ€§ SVR / Ridge
```

### 9.4 å»¶ä¼¸å­¸ç¿’

**æ·±å…¥ç†è«–**ï¼š
- çµ±è¨ˆå­¸ç¿’ç†è«–ï¼ˆVC ç¶­ã€çµæ§‹é¢¨éšªæœ€å°åŒ–ï¼‰
- å‡¸å„ªåŒ–ç†è«–ï¼ˆKKT æ¢ä»¶ã€å°å¶å•é¡Œï¼‰
- å†ç”Ÿæ ¸å¸Œçˆ¾ä¼¯ç‰¹ç©ºé–“ (RKHS)

**ç›¸é—œä¸»é¡Œ**ï¼š
- æ”¯æŒå‘é‡åˆ†é¡ (SVC)
- ä¸€é¡ SVMï¼ˆç•°å¸¸æª¢æ¸¬ï¼‰
- åŠç›£ç£ SVM
- ç·šä¸Šå­¸ç¿’ SVR

**å·¥å…·èˆ‡è³‡æº**ï¼š
- scikit-learn å®˜æ–¹æ–‡ä»¶
- LIBSVM åŸå§‹åº«
- æ›¸ç±ï¼š*Learning with Kernels* (SchÃ¶lkopf & Smola)

---

## 10. åƒè€ƒè³‡æ–™

1. **scikit-learn å®˜æ–¹æ–‡ä»¶**ï¼š
   - [SVR Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)
   - [SVM User Guide](https://scikit-learn.org/stable/modules/svm.html)

2. **ç¶“å…¸è«–æ–‡**ï¼š
   - Vapnik, V. (1995). *The Nature of Statistical Learning Theory*. Springer.
   - Smola, A. J., & SchÃ¶lkopf, B. (2004). A tutorial on support vector regression. *Statistics and Computing*, 14(3), 199-222.

3. **ç·šä¸Šè³‡æº**ï¼š
   - [StatQuest: SVM explained](https://www.youtube.com/watch?v=efR1C6CvhmE)
   - [Kernel Functions Guide](https://data-flair.training/blogs/svm-kernel-functions/)

4. **åŒ–å·¥æ‡‰ç”¨æ–‡ç»**ï¼š
   - Lahiri, S. K., & Ghanta, K. C. (2008). Development of an artificial neural network correlation for prediction of hold-up of slurry transport in pipelines. *Chemical Engineering Science*, 63(6), 1497-1509.
   - Desai, K. M., et al. (2008). Soft-sensor development for fed-batch bioreactors using support vector regression. *Biochemical Engineering Journal*, 40(2), 290-301.

---

**ä¸‹ä¸€æ­¥**ï¼š
- ğŸ“ å®Œæˆ Jupyter Notebook å¯¦ä½œï¼š`Unit11_Support_Vector_Machine.ipynb`
- ğŸ‹ï¸ ç·´ç¿’ä½œæ¥­ï¼š`Unit11_NonLinear_Models_Homework.ipynb`ï¼ˆæ•´åˆæ‰€æœ‰éç·šæ€§æ¨¡å‹æ¯”è¼ƒï¼‰
- ğŸ“š é€²éšå­¸ç¿’ï¼šæ¢ç´¢é«˜æ–¯éç¨‹å›æ­¸ (Unit11_Gaussian_Process_Regression)

**èª²ç¨‹é€²åº¦**ï¼šPart 3 - Unit 11ï¼ˆéç·šæ€§æ¨¡å‹å›æ­¸ï¼‰âœ“ Support Vector Machine

---

**èª²ç¨‹è³‡è¨Š**
- èª²ç¨‹åç¨±ï¼šAIåœ¨åŒ–å·¥ä¸Šä¹‹æ‡‰ç”¨
- èª²ç¨‹å–®å…ƒï¼šUnit11 Support Vector Machine æ”¯æŒå‘é‡å›æ­¸
- èª²ç¨‹è£½ä½œï¼šé€¢ç”²å¤§å­¸ åŒ–å·¥ç³» æ™ºæ…§ç¨‹åºç³»çµ±å·¥ç¨‹å¯¦é©—å®¤
- æˆèª²æ•™å¸«ï¼šèŠæ›œç¦ åŠ©ç†æ•™æˆ
- æ›´æ–°æ—¥æœŸï¼š2026-01-28

**èª²ç¨‹æˆæ¬Š [CC BY-NC-SA 4.0]**
 - æœ¬æ•™æéµå¾ª [å‰µç”¨CC å§“åæ¨™ç¤º-éå•†æ¥­æ€§-ç›¸åŒæ–¹å¼åˆ†äº« 4.0 åœ‹éš› (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh) æˆæ¬Šã€‚

---
